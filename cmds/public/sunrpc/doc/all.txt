





_R_e_m_o_t_e _P_r_o_c_e_d_u_r_e _C_a_l_l _P_r_o_g_r_a_m_m_i_n_g _G_u_i_d_e

This document is intended for programmers who wish to  write
network applications using remote procedure calls (explained
below), thus avoiding low-level system primitives  based  on
sockets.  The reader must be familiar with the C programming
language, and should have a  working  knowledge  of  network
theory.

_N_O_T_E: _B_e_f_o_r_e _a_t_t_e_m_p_t_i_n_g _t_o _w_r_i_t_e _a _n_e_t_w_o_r_k  _a_p_p_l_i_c_a_t_i_o_n,  _o_r
_t_o  _c_o_n_v_e_r_t  _a_n _e_x_i_s_t_i_n_g _n_o_n-_n_e_t_w_o_r_k _a_p_p_l_i_c_a_t_i_o_n _t_o _r_u_n _o_v_e_r
_t_h_e _n_e_t_w_o_r_k, _y_o_u _s_h_o_u_l_d _b_e _f_a_m_i_l_i_a_r  _w_i_t_h  _t_h_e  _m_a_t_e_r_i_a_l  _i_n
_t_h_i_s  _c_h_a_p_t_e_r.  _H_o_w_e_v_e_r, _f_o_r _m_o_s_t _a_p_p_l_i_c_a_t_i_o_n_s, _y_o_u _c_a_n _c_i_r_-
_c_u_m_v_e_n_t _t_h_e _n_e_e_d _t_o _c_o_p_e _w_i_t_h _t_h_e _k_i_n_d_s _o_f _d_e_t_a_i_l_s _p_r_e_s_e_n_t_e_d
_h_e_r_e  _b_y  _u_s_i_n_g  _t_h_e  _r_p_c_g_e_n  protocol  compiler,  which  is
described in detail in the next chapter, the rpcgen Program-
ming  Guide.   The  Generating  XDR Routines section of that
chapter contains the  complete  source  for  a  working  RPC
service-a remote directory listing service which uses _r_p_c_g_e_n
to generate XDR routines as well as client and server stubs.


What are remote procedure calls?  Simply put, they  are  the
high-level  communications  paradigm  used  in the operating
system.  RPC presumes the existence of low-level  networking
mechanisms  (such  as  TCP/IP  and UDP/IP), and upon them it
implements a logical client to server communications  system
designed  specifically  for  the support of network applica-
tions.  With RPC, the client makes a procedure call to  send
a  data  packet to the server.  When the packet arrives, the
server calls a dispatch routine, performs  whatever  service
is  requested,  sends back the reply, and the procedure call
returns to the client.

_1.  _L_a_y_e_r_s _o_f _R_P_C

The RPC interface can be seen as being  divided  into  three
layers.

_T_h_e _H_i_g_h_e_s_t _L_a_y_e_r: The highest layer is totally  transparent
to  the  operating system, machine and network upon which is
is run.  It's probably best to think of this level as a  way
of using RPC, rather than as a part of RPC proper.  Program-
mers who write RPC routines should (almost) always make this
layer  available to others by way of a simple C front end to
that entirely hides the networking.

To illustrate, at this level a program  can  simply  make  a
call  to  _r_n_u_s_e_r_s,  a  C routine which returns the number of
__________________________
For a complete specification of the routines in the re-
mote  procedure  call  Library,  see the _r_p_c(3N) manual
page.




                           - 1 -





                           - 2 -


users on a remote machine.  The user is not explicitly aware
of  using  RPC  - they simply call a procedure, just as they
would call _m_a_l_l_o_c

_T_h_e _M_i_d_d_l_e _L_a_y_e_r: The middle layer is really  "RPC  proper."
Here,  the user doesn't need to consider details about sock-
ets, the UNIX  system,  or  other  low-level  implementation
mechanisms.  They simple make remote procedure calls to rou-
tines on other machines.  The selling point here is  simpli-
city.  It's  this  layer  that allows RPC to pass the "hello
world" test - simple things should be simple.   The  middle-
layer routines are used for most applications.

RPC calls are made  with  the  system  routines  _r_e_g_i_s_t_e_r_r_p_c
_c_a_l_l_r_p_c  and  _s_v_c__r_u_n.   The first two of these are the most
fundamental:  _r_e_g_i_s_t_e_r_r_p_c  obtains  a   unique   system-wide
procedure-identification  number,  and _c_a_l_l_r_p_c actually exe-
cutes a remote procedure call.  At the middle level, a  call
to _r_n_u_s_e_r_s is implemented by way of these two routines.

The middle layer is unfortunately  rarely  used  in  serious
programming  due to its inflexibility (simplicity).  It does
not allow timeout specifications or the choice of transport.
It  allows no UNIX process control or flexibility in case of
errors.  It doesn't support multiple kinds of call authenti-
cation.  The programmer rarely needs all these kinds of con-
trol, but one or two of them is often necessary.

_T_h_e _L_o_w_e_s_t _L_a_y_e_r: The lowest layer does allow these  details
to  be  controlled by the programmer, and for that reason it
is often necessary.  Programs written at this level are also
most  efficient, but this is rarely a real issue - since RPC
clients and servers rarely generate heavy network loads.

Although this document only discusses the  interface  to  C,
remote  procedure calls can be made from any language.  Even
though this document discusses RPC when it is used  to  com-
municate  between  processes on different machines, it works
just as well for communication between  different  processes
on the same machine.

_1._1.  _T_h_e _R_P_C _P_a_r_a_d_i_g_m

Here is a diagram of the RPC paradigm:

L1: arrow down 1i "client " rjust "program " rjust L2:  line
right  1i  "callrpc()"  "function" move up 1.5i; line dotted
down 6i; move up 4.5i arrow right 1i L3: arrow down 1i "exe-
cute  "  rjust  "request " rjust L4: arrow right 1.5i "call"
"service" L5: arrow down 1i "  service"  ljust  "  executes"
ljust  L6:  arrow left 1.5i "return" "answer" L7: arrow down
1i "request " rjust "completed "  rjust  L8:  line  left  1i
arrow  left 1i "return" "reply" L9: arrow down 1i "program "
rjust "continues " rjust line dashed down from L2 to L9 line









                           - 3 -


dashed down from L4 to L7 line dashed up 1i from L3 "service
" rjust "daemon " rjust arrow dashed down 1i  from  L8  move
right  1i  from L3 box invis "Machine B" move left 0.7i from
L2; move down box invis "Machine A"

_2.  _H_i_g_h_e_r _L_a_y_e_r_s _o_f _R_P_C

_2._1.  _H_i_g_h_e_s_t _L_a_y_e_r

Imagine you're writing a program that needs to know how many
users  are logged into a remote machine.  You can do this by
calling the RPC  library  routine  _r_n_u_s_e_r_s,  as  illustrated
below:

#include <stdio.h>

main(argc, argv)
     int argc;
     char **argv;
{
     int num;

     if (argc < 2) {
          fprintf(stderr, "usage: rnusers hostname\n");
          exit(1);
     }
     if ((num = rnusers(argv[1])) < 0) {
          fprintf(stderr, "error: rnusers\n");
          exit(-1);
     }
     printf("%d users on %s\n", num, argv[1]);
     exit(0);
}

RPC library routines such as _r_n_u_s_e_r_s are in the RPC services
library  _l_i_b_r_p_c_s_v_c._a  Thus, the program above should be com-
piled with

        % cc program.c -lrpcsvc

_r_n_u_s_e_r_s, like the other RPC library routines, is  documented
in  section  3R  of  the _S_y_s_t_e_m _I_n_t_e_r_f_a_c_e _M_a_n_u_a_l _f_o_r _t_h_e _S_u_n
_W_o_r_k_s_t_a_t_i_o_n, the same section which documents  the  standard
Sun  RPC  services.  See  the  _i_n_t_r_o(3R)  manual page for an
explanation of the documentation strategy for these services
and their RPC protocols.

Here are some of the RPC service library routines  available
to the C programmer:














                           - 4 -


_____________________________________________________________
 Routine                      Description
_____________________________________________________________
 rnusers    Return number of users on remote machine
 rusers     Return information about users on remote machine
 havedisk   Determine if remote machine has disk
 rstats     Get performance data from remote kernel
 rwall      Write to specified remote machines
 yppasswd   Update user password in Yellow Pages
_____________________________________________________________
|||||||||






                                                            |||||||||









Other RPC services - for  example  _e_t_h_e_r  _m_o_u_n_t  _r_q_u_o_t_a  and
_s_p_r_a_y  -  are  not  available to the C programmer as library
routines.  They do, however, have  RPC  program  numbers  so
they  can be invoked with _c_a_l_l_r_p_c which will be discussed in
the  next  section.   Most  of  them  also  have  compilable
_r_p_c_g_e_n(1)  protocol description files.  (The _r_p_c_g_e_n protocol
compiler radically simplifies the process of developing net-
work applications.  See the rpcgen Programming Guide chapter
for detailed information about _r_p_c_g_e_n  and  _r_p_c_g_e_n  protocol
description files).

_2._2.  _I_n_t_e_r_m_e_d_i_a_t_e _L_a_y_e_r

The simplest interface, which explicitly  makes  RPC  calls,
uses  the  functions  _c_a_l_l_r_p_c  and  _r_e_g_i_s_t_e_r_r_p_c  Using  this
method, the number of remote users can be gotten as follows:

#include <stdio.h>
#include <rpc/rpc.h>
#include <utmp.h>
#include <rpcsvc/rusers.h>

main(argc, argv)
     int argc;
     char **argv;
{
     unsigned long nusers;
     int stat;

     if (argc < 2) {
          fprintf(stderr, "usage: nusers hostname\n");
          exit(-1);
     }
     if (stat = callrpc(argv[1],
       RUSERSPROG, RUSERSVERS, RUSERSPROC_NUM,
       xdr_void, 0, xdr_u_long, &nusers) != 0) {
          clnt_perrno(stat);
          exit(1);
     }
     printf("%d users on %s\n", nusers, argv[1]);
     exit(0);
}










                           - 5 -


Each RPC procedure is uniquely defined by a program  number,
version  number,  and  procedure number.  The program number
specifies a group of  related  remote  procedures,  each  of
which  has  a different procedure number.  Each program also
has a version number, so when a minor change is  made  to  a
remote  service (adding a new procedure, for example), a new
program number doesn't have to be assigned.  When  you  want
to  call a procedure to find the number of remote users, you
look up  the  appropriate  program,  version  and  procedure
numbers  in  a  manual,  just  as  you look up the name of a
memory allocator when you want to allocate memory.

The simplest way of making remote procedure  calls  is  with
the the RPC library routine _c_a_l_l_r_p_c It has eight parameters.
The first is the name of the  remote  server  machine.   The
next  three  parameters  are  the program, version, and pro-
cedure numbers-together they identify the  procedure  to  be
called.   The  fifth  and sixth parameters are an XDR filter
and an argument to be encoded and passed to the remote  pro-
cedure.  The  final two parameters are a filter for decoding
the results returned by the remote procedure and  a  pointer
to the place where the procedure's results are to be stored.
Multiple arguments and results are handled by embedding them
in   structures.   If  _c_a_l_l_r_p_c  completes  successfully,  it
returns zero; else it returns a nonzero value.   The  return
codes  (of  type  _e_n_u_m  cast  into  an integer) are found in
<_r_p_c/_c_l_n_t._h>.

Since data types may be represented differently on different
machines,  _c_a_l_l_r_p_c  needs both the type of the RPC argument,
as well as a pointer to the argument itself  (and  similarly
for the result).  For _R_U_S_E_R_S_P_R_O_C__N_U_M, the return value is an
_u_n_s_i_g_n_e_d _l_o_n_g so _c_a_l_l_r_p_c has _x_d_r__u__l_o_n_g as its first  return
parameter,  which  says  that the result is of type _u_n_s_i_g_n_e_d
_l_o_n_g and &_n_u_s_e_r_s as its second return parameter, which is  a
pointer  to  where  the  long  result will be placed.  Since
_R_U_S_E_R_S_P_R_O_C__N_U_M takes no argument, the argument parameter  of
_c_a_l_l_r_p_c is _x_d_r__v_o_i_d.

After trying several times to deliver a message, if  _c_a_l_l_r_p_c
gets no answer, it returns with an error code.  The delivery
mechanism is UDP, which stands for User  Datagram  Protocol.
Methods  for  adjusting the number of retries or for using a
different protocol require you to use the lower layer of the
RPC  library,  discussed later in this document.  The remote
server procedure corresponding to the above might look  like
this:
















                           - 6 -


char *
nuser(indata)
     char *indata;
{
     static int nusers;

     /*
      * Code here to compute the number of users
      * and place result in variable nusers.
      */
     return((char *)&nusers);
}


It takes one argument, which is a pointer to  the  input  of
the  remote  procedure call (ignored in our example), and it
returns a pointer to the result.  In the current version  of
C,  character pointers are the generic pointers, so both the
input argument and the return value are cast to _c_h_a_r *

Normally, a server registers all of the RPC calls  it  plans
to  handle,  and  then goes into an infinite loop waiting to
service requests.  In this example, there is only  a  single
procedure  to register, so the main body of the server would
look like this:

#include <stdio.h>
#include <rpc/rpc.h>
#include <utmp.h>
#include <rpcsvc/rusers.h>

char *nuser();

main()
{
     registerrpc(RUSERSPROG, RUSERSVERS, RUSERSPROC_NUM,
          nuser, xdr_void, xdr_u_long);
     svc_run();          /* Never returns */
     fprintf(stderr, "Error: svc_run returned!\n");
     exit(1);
}


The  _r_e_g_i_s_t_e_r_r_p_c  routine  registers  a   C   procedure   as
corresponding  to  a  given RPC procedure number.  The first
three parameters, _R_U_S_E_R_P_R_O_G, _R_U_S_E_R_S_V_E_R_S, and  _R_U_S_E_R_S_P_R_O_C__N_U_M
are  the  program,  version,  and  procedure  numbers of the
remote procedure to be registered; _n_u_s_e_r is the name of  the
local  procedure  that  implements the remote procedure; and
_x_d_r__v_o_i_d and _x_d_r__u__l_o_n_g are the XDR filters for  the  remote
procedure's  arguments and results, respectively.  (Multiple
arguments or multiple results are passed as structures).

Only the UDP transport mechanism can use  _r_e_g_i_s_t_e_r_r_p_c  thus,









                           - 7 -


it  is  always  safe  in conjunction with calls generated by
_c_a_l_l_r_p_c.

_W_A_R_N_I_N_G: _T_h_e _U_D_P _t_r_a_n_s_p_o_r_t  _m_e_c_h_a_n_i_s_m  _c_a_n  _o_n_l_y  _d_e_a_l  _w_i_t_h
_a_r_g_u_m_e_n_t_s _a_n_d _r_e_s_u_l_t_s _l_e_s_s _t_h_a_n _8_K _b_y_t_e_s _i_n _l_e_n_g_t_h.


After registering the local procedure, the server  program's
main  procedure calls _s_v_c__r_u_n, the RPC library's remote pro-
cedure dispatcher.  It  is  this  function  that  calls  the
remote  procedures  in  response to RPC call messages.  Note
that the dispatcher takes care of decoding remote  procedure
arguments and encoding results, using the XDR filters speci-
fied when the remote procedure was registered.

_2._3.  _A_s_s_i_g_n_i_n_g _P_r_o_g_r_a_m _N_u_m_b_e_r_s

Program numbers are assigned in groups of _0_x_2_0_0_0_0_0_0_0 accord-
ing to the following chart:

               0x0 - 0x1fffffff  Defined by Sun
        0x20000000 - 0x3fffffff  Defined by user
        0x40000000 - 0x5fffffff  Transient
        0x60000000 - 0x7fffffff  Reserved
        0x80000000 - 0x9fffffff  Reserved
        0xa0000000 - 0xbfffffff  Reserved
        0xc0000000 - 0xdfffffff  Reserved
        0xe0000000 - 0xffffffff  Reserved

Sun Microsystems administers the  first  group  of  numbers,
which  should be identical for all Sun customers.  If a cus-
tomer develops an  application  that  might  be  of  general
interest,  that  application  should  be  given  an assigned
number in the first range.  The second group of  numbers  is
reserved  for specific customer applications.  This range is
intended primarily for debugging new  programs.   The  third
group  is  reserved  for  applications that generate program
numbers dynamically.  The  final  groups  are  reserved  for
future use, and should not be used.

To register a protocol specification, send a request by net-
work mail to _r_p_c@_s_u_n or write to:

        RPC Administrator
        Sun Microsystems
        2550 Garcia Ave.
        Mountain View, CA 94043

Please include a compilable _r_p_c_g_e_n  ``.x''  file  describing
your protocol.  You will be given a unique program number in
return.

The RPC program numbers and protocol specifications of stan-
dard  Sun  RPC services can be found in the include files in









                           - 8 -


/_u_s_r/_i_n_c_l_u_d_e/_r_p_c_s_v_c.  These  services,  however,  constitute
only  a  small  subset  of those which have been registered.
The complete list of registered programs,  as  of  the  time
when this manual was printed, is:

_____________________________________________________________
 RPC Number   Program              Description
_____________________________________________________________
||
                                                            ||

 100000       PMAPPROG             portmapper
 100001       RSTATPROG            remote stats
 100002       RUSERSPROG           remote users
 100003       NFSPROG              nfs
 100004       YPPROG               Yellow Pages
 100005       MOUNTPROG            mount demon
 100006       DBXPROG              remote dbx
 100007       YPBINDPROG           yp binder
 100008       WALLPROG             shutdown msg
 100009       YPPASSWDPROG         yppasswd server
 100010       ETHERSTATPROG        ether stats
 100011       RQUOTAPROG           disk quotas
 100012       SPRAYPROG            spray packets
 100013       IBM3270PROG          3270 mapper
 100014       IBMRJEPROG           RJE mapper
 100015       SELNSVCPROG          selection service
 100016       RDATABASEPROG        remote database access
 100017       REXECPROG            remote execution
 100018       ALICEPROG            Alice Office Automation
 100019       SCHEDPROG            scheduling service
 100020       LOCKPROG             local lock manager
 100021       NETLOCKPROG          network lock manager
 100022       X25PROG              x.25 inr protocol
 100023       STATMON1PROG         status monitor 1
 100024       STATMON2PROG         status monitor 2
 100025       SELNLIBPROG          selection library
 100026       BOOTPARAMPROG        boot parameters service
 100027       MAZEPROG             mazewars game
 100028       YPUPDATEPROG         yp update
 100029       KEYSERVEPROG         key server
 100030       SECURECMDPROG        secure login
 100031       NETFWDIPROG          nfs net forwarder init
 100032       NETFWDTPROG          nfs net forwarder trans
 100033       SUNLINKMAP_PROG      sunlink MAP
 100034       NETMONPROG           network monitor
 100035       DBASEPROG            lightweight database
 100036       PWDAUTHPROG          password authorization
 100037       TFSPROG              translucent file svc
 100038       NSEPROG              nse server
 100039       NSE_ACTIVATE_PROG    nse activate daemon

 150001       PCNFSDPROG           pc passwd authorization

 200000       PYRAMIDLOCKINGPROG   Pyramid-locking
 200001       PYRAMIDSYS5          Pyramid-sys5
 200002       CADDS_IMAGE          CV cadds_image
_____________________________________________________________
||||||||||||||||||||||||||||||||||||||||||||||||













































                                                            ||||||||||||||||||||||||||||||||||||||||||||||||























































                           - 9 -


_____________________________________________________________
 RPC Number   Program              Description
_____________________________________________________________
||
                                                            ||
 300001       ADT_RFLOCKPROG       ADT file locking
_____________________________________________________________
||
                                                            ||


_2._4.  _P_a_s_s_i_n_g _A_r_b_i_t_r_a_r_y _D_a_t_a _T_y_p_e_s

In the previous  example,  the  RPC  call  passes  a  single
_u_n_s_i_g_n_e_d  _l_o_n_g  RPC  can  handle  arbitrary data structures,
regardless of different machines' byte orders  or  structure
layout  conventions,  by always converting them to a network
standard called _e_X_t_e_r_n_a_l _D_a_t_a  _R_e_p_r_e_s_e_n_t_a_t_i_o_n  (XDR)  before
sending  them over the wire.  The process of converting from
a particular machine representation to XDR format is  called
_s_e_r_i_a_l_i_z_i_n_g,  and  the reverse process is called _d_e_s_e_r_i_a_l_i_z_-
_i_n_g.  The type field parameters of _c_a_l_l_r_p_c  and  _r_e_g_i_s_t_e_r_r_p_c
can  be a built-in procedure like _x_d_r__u__l_o_n_g in the previous
example, or a user supplied one.  DR has these built-in type
routines:

        xdr_int()      xdr_u_int()      xdr_enum()
        xdr_long()     xdr_u_long()     xdr_bool()
        xdr_short()    xdr_u_short()    xdr_wrapstring()
        xdr_char()     xdr_u_char()

Note that the routine _x_d_r__s_t_r_i_n_g exists, but cannot be  used
with _c_a_l_l_r_p_c and _r_e_g_i_s_t_e_r_r_p_c, which only pass two parameters
to their XDR routines.  _x_d_r__w_r_a_p_s_t_r_i_n_g has only two  parame-
ters, and is thus OK.  It calls _x_d_r__s_t_r_i_n_g.

As an example of a user-defined type routine, if you  wanted
to send the structure

        struct simple {
             int a;
             short b;
        } simple;

then you would call _c_a_l_l_r_p_c as

        callrpc(hostname, PROGNUM, VERSNUM, PROCNUM,
                xdr_simple, &simple ...);

where _x_d_r__s_i_m_p_l_e is written as:


















                           - 10 -


#include <rpc/rpc.h>

xdr_simple(xdrsp, simplep)
     XDR *xdrsp;
     struct simple *simplep;
{
     if (!xdr_int(xdrsp, &simplep->a))
          return (0);
     if (!xdr_short(xdrsp, &simplep->b))
          return (0);
     return (1);
}


An XDR routine returns nonzero (true in the sense of  C)  if
it  completes  successfully, and zero otherwise.  A complete
description of XDR is in the _X_D_R _P_r_o_t_o_c_o_l _S_p_e_c_i_f_i_c_a_t_i_o_n sec-
tion  of  this  manual, only few implementation examples are
given here.

In addition to the built-in primitives, there are  also  the
prefabricated building blocks:

        xdr_array()       xdr_bytes()     xdr_reference()
        xdr_vector()      xdr_union()     xdr_pointer()
        xdr_string()      xdr_opaque()

To send a variable array of integers, you might package them
up as a structure like this

        struct varintarr {
             int *data;
             int arrlnth;
        } arr;

and make an RPC call such as

        callrpc(hostname, PROGNUM, VERSNUM, PROCNUM,
                xdr_varintarr, &arr...);

with _x_d_r__v_a_r_i_n_t_a_r_r defined as:

xdr_varintarr(xdrsp, arrp)
     XDR *xdrsp;
     struct varintarr *arrp;
{
     return (xdr_array(xdrsp, &arrp->data, &arrp->arrlnth,
          MAXLEN, sizeof(int), xdr_int));
}

This routine takes as parameters the XDR handle,  a  pointer
to  the  array, a pointer to the size of the array, the max-
imum allowable array size, the size of each  array  element,
and an XDR routine for handling each array element.









                           - 11 -



If the size of the array is known in advance,  one  can  use
_x_d_r__v_e_c_t_o_r, which serializes fixed-length arrays.

int intarr[SIZE];

xdr_intarr(xdrsp, intarr)
     XDR *xdrsp;
     int intarr[];
{
     int i;

     return (xdr_vector(xdrsp, intarr, SIZE, sizeof(int),
          xdr_int));
}


DR always  converts  quantities  to  4-byte  multiples  when
deserializing.   Thus,  if  either  of  the  examples  above
involved characters  instead  of  integers,  each  character
would  occupy  32 bits.  That is the reason for the XDR rou-
tine _x_d_r__b_y_t_e_s which is like _x_d_r__a_r_r_a_y except that it  packs
characters;  _x_d_r__b_y_t_e_s  has  four parameters, similar to the
first four parameters  of  _x_d_r__a_r_r_a_y.   For  null-terminated
strings,  there is also the _x_d_r__s_t_r_i_n_g routine, which is the
same as _x_d_r__b_y_t_e_s without the length parameter.  On  serial-
izing  it gets the string length from _s_t_r_l_e_n, and on deseri-
alizing it creates a null-terminated string.

Here is a final example that calls  the  previously  written
_x_d_r__s_i_m_p_l_e  as well as the built-in functions _x_d_r__s_t_r_i_n_g and
_x_d_r__r_e_f_e_r_e_n_c_e, which chases pointers:

struct finalexample {
     char *string;
     struct simple *simplep;
} finalexample;

xdr_finalexample(xdrsp, finalp)
     XDR *xdrsp;
     struct finalexample *finalp;
{

     if (!xdr_string(xdrsp, &finalp->string, MAXSTRLEN))
          return (0);
     if (!xdr_reference(xdrsp, &finalp->simplep,
       sizeof(struct simple), xdr_simple);
          return (0);
     return (1);
}













                           - 12 -


_3.  _L_o_w_e_s_t _L_a_y_e_r _o_f _R_P_C

In the examples given so far, RPC takes care of many details
automatically  for you.  In this section, we'll show you how
you can change the defaults by using lower layers of the RPC
library.   It  is assumed that you are familiar with sockets
and the system calls for dealing with them.  If not, consult
the _I_P_C _P_r_i_m_e_r section of this manual.

There are several occasions when you may need to  use  lower
layers  of  RPC.   First, you may need to use TCP, since the
higher layer uses UDP, which restricts RPC calls to 8K bytes
of  data.   Using  TCP permits calls to send long streams of
data.  For an example, see the TCP section  below.   Second,
you  may  want to allocate and free memory while serializing
or deserializing with XDR routines.  There is no call at the
higher  level  to  let you free memory explicitly.  For more
explanation, see the  Memory  Allocation  with  XDR  section
below.   Third,  you  may  need to perform authentication on
either the client or server side, by  supplying  credentials
or verifying them. See the explanation in the Authentication
section below.

_3._1.  _M_o_r_e _o_n _t_h_e _S_e_r_v_e_r _S_i_d_e

The server for the _n_u_s_e_r_s program shown below does the  same
thing  as  the  one  using _r_e_g_i_s_t_e_r_r_p_c above, but is written
using a lower layer of the RPC package:



































                           - 13 -


#include <stdio.h>
#include <rpc/rpc.h>
#include <utmp.h>
#include <rpcsvc/rusers.h>

main()
{
     SVCXPRT *transp;
     int nuser();

     transp = svcudp_create(RPC_ANYSOCK);
     if (transp == NULL){
          fprintf(stderr, "can't create an RPC server\n");
          exit(1);
     }
     pmap_unset(RUSERSPROG, RUSERSVERS);
     if (!svc_register(transp, RUSERSPROG, RUSERSVERS,
                 nuser, IPPROTO_UDP)) {
          fprintf(stderr, "can't register RUSER service\n");
          exit(1);
     }
     svc_run();  /* Never returns */
     fprintf(stderr, "should never reach this point\n");
}

nuser(rqstp, transp)
     struct svc_req *rqstp;
     SVCXPRT *transp;
{
     unsigned long nusers;

     switch (rqstp->rq_proc) {
     case NULLPROC:
          if (!svc_sendreply(transp, xdr_void, 0))
               fprintf(stderr, "can't reply to RPC call\n");
          return;
     case RUSERSPROC_NUM:
          /*
           * Code here to compute the number of users
           * and put in variable nusers
           */
          if (!svc_sendreply(transp, xdr_u_long, &nusers))
               fprintf(stderr, "can't reply to RPC call\n");
          return;
     default:
          svcerr_noproc(transp);
          return;
     }
}


First, the server gets a transport handle, which is used for
receiving  and  replying  to RPC messages.  _r_e_g_i_s_t_e_r_r_p_c uses
_s_v_c_u_d_p__c_r_e_a_t_e to get a UDP handle.  If you  require  a  more









                           - 14 -


reliable protocol, call _s_v_c_t_c_p__c_r_e_a_t_e instead.  If the argu-
ment to _s_v_c_u_d_p__c_r_e_a_t_e is _R_P_C__A_N_Y_S_O_C_K the RPC library creates
a socket on which to receive and reply to RPC calls.  Other-
wise, _s_v_c_u_d_p__c_r_e_a_t_e expects  its  argument  to  be  a  valid
socket  number.   If  you specify your own socket, it can be
bound or unbound.  If it is bound to a port by the user, the
port  numbers  of  _s_v_c_u_d_p__c_r_e_a_t_e and _c_l_n_t_c_p__c_r_e_a_t_e (the low-
level client routine) must match.

If the user specifies  the  _R_P_C__A_N_Y_S_O_C_K  argument,  the  RPC
library  routines  will  open  sockets.  Otherwise they will
expect the user to do so.  The  routines  _s_v_c_u_d_p__c_r_e_a_t_e  and
_c_l_n_t_u_d_p__c_r_e_a_t_e  will  cause the RPC library routines to _b_i_n_d
their socket if it is not bound already.

A service may choose to register its port  number  with  the
local  portmapper service.  This is done is done by specify-
ing a non-zero protocol number in _s_v_c__r_e_g_i_s_t_e_r.  Incidently,
a client can discover the server's port number by consulting
the portmapper on their server's machine.  This can be  done
automatically   by   specifying   a   zero  port  number  in
_c_l_n_t_u_d_p__c_r_e_a_t_e or _c_l_n_t_c_p__c_r_e_a_t_e.

After  creating  an  _S_V_C_X_P_R_T,  the  next  step  is  to  call
_p_m_a_p__u_n_s_e_t so that if the _n_u_s_e_r_s server crashed earlier, any
previous trace of it is erased before restarting.  More pre-
cisely,  _p_m_a_p__u_n_s_e_t erases the entry for _R_U_S_E_R_S_P_R_O_G from the
port mapper's tables.

Finally, we associate the program number for _n_u_s_e_r_s with the
procedure _n_u_s_e_r.  The final argument to _s_v_c__r_e_g_i_s_t_e_r is nor-
mally the protocol being  used,  which,  in  this  case,  is
_I_P_P_R_O_T_O__U_D_P Notice that unlike _r_e_g_i_s_t_e_r_r_p_c, there are no XDR
routines involved in the registration process.  Also, regis-
tration  is  done  on  the  program,  rather than procedure,
level.

The user routine _n_u_s_e_r must call and dispatch the  appropri-
ate  XDR  routines based on the procedure number.  Note that
two things are handled by  _n_u_s_e_r  that  _r_e_g_i_s_t_e_r_r_p_c  handles
automatically.    The   first  is  that  procedure  _N_U_L_L_P_R_O_C
(currently zero) returns with no results.  This can be  used
as  a  simple test for detecting if a remote program is run-
ning.  Second,  there  is  a  check  for  invalid  procedure
numbers.   If  one  is  detected, _s_v_c_e_r_r__n_o_p_r_o_c is called to
handle the error.

















                           - 15 -



The user service routine serializes the results and  returns
them to the RPC caller via _s_v_c__s_e_n_d_r_e_p_l_y Its first parameter
is the _S_V_C_X_P_R_T handle, the second is the  XDR  routine,  and
the  third is a pointer to the data to be returned.  Not il-
lustrated above is how a server handles an RPC program  that
receives  data.   As  an  example,  we  can  add a procedure
_R_U_S_E_R_S_P_R_O_C__B_O_O_L which has an argument  _n_u_s_e_r_s,  and  returns
_T_R_U_E  or  _F_A_L_S_E depending on whether there are nusers logged
on.  It would look like this:

case RUSERSPROC_BOOL: {
     int bool;
     unsigned nuserquery;

     if (!svc_getargs(transp, xdr_u_int, &nuserquery) {
          svcerr_decode(transp);
          return;
     }
     /*
      * Code to set nusers = number of users
      */
     if (nuserquery == nusers)
          bool = TRUE;
     else
          bool = FALSE;
     if (!svc_sendreply(transp, xdr_bool, &bool)) {
           fprintf(stderr, "can't reply to RPC call\n");
           exit(1);
     }
     return;
}


The relevant routine is _s_v_c__g_e_t_a_r_g_s which takes  an  _S_V_C_X_P_R_T
handle, the XDR routine, and a pointer to where the input is
to be placed as arguments.

_3._2.  _M_e_m_o_r_y _A_l_l_o_c_a_t_i_o_n _w_i_t_h _X_D_R

DR routines not only do  input  and  output,  they  also  do
memory  allocation.   This  is  why  the second parameter of
_x_d_r__a_r_r_a_y is a pointer to an array, rather  than  the  array
itself.   If  it is _N_U_L_L, then _x_d_r__a_r_r_a_y allocates space for
the array and returns a pointer to it, putting the  size  of
the  array  in  the third argument.  As an example, consider
the following XDR routine _x_d_r__c_h_a_r_a_r_r_1 which  deals  with  a
fixed array of bytes with length _S_I_Z_E















                           - 16 -


xdr_chararr1(xdrsp, chararr)
     XDR *xdrsp;
     char chararr[];
{
     char *p;
     int len;

     p = chararr;
     len = SIZE;
     return (xdr_bytes(xdrsp, &p, &len, SIZE));
}

It might be called from a server like this,

char chararr[SIZE];

svc_getargs(transp, xdr_chararr1, chararr);

space has already been allocated in _c_h_a_r_a_r_r.   If  you  want
XDR  to  do  the  allocation, you would have to rewrite this
routine in the following way:

xdr_chararr2(xdrsp, chararrp)
     XDR *xdrsp;
     char **chararrp;
{
     int len;

     len = SIZE;
     return (xdr_bytes(xdrsp, charrarrp, &len, SIZE));
}

Then the RPC call might look like this:

char *arrptr;

arrptr = NULL;
svc_getargs(transp, xdr_chararr2, &arrptr);
/*
 * Use the result here
 */
svc_freeargs(transp, xdr_chararr2, &arrptr);

Note that, after being used,  the  character  array  can  be
freed  with  _s_v_c__f_r_e_e_a_r_g_s  _s_v_c__f_r_e_e_a_r_g_s  will not attempt to
free any memory if the variable indicating it is NULL.   For
example, in the the routine _x_d_r__f_i_n_a_l_e_x_a_m_p_l_e, given earlier,
if _f_i_n_a_l_p->_s_t_r_i_n_g was NULL, then it would not be freed.  The
same is true for _f_i_n_a_l_p->_s_i_m_p_l_e_p.

To summarize, each XDR routine is responsible for  serializ-
ing, deserializing, and freeing memory.  When an XDR routine
is called from _c_a_l_l_r_p_c the serializing part is  used.   When
called  from _s_v_c__g_e_t_a_r_g_s the deserializer is used.  And when









                           - 17 -


called from _s_v_c__f_r_e_e_a_r_g_s the  memory  deallocator  is  used.
When  building simple examples like those in this section, a
user doesn't have to worry about the three modes.   See  the
eXternal  Data  Representation:  Sun Technical Notes chapter
for examples of more sophisticated XDR routines that  deter-
mine  which  of the three modes they are in and adjust their
behavior accordingly.
























































                           - 18 -



_3._3.  _T_h_e _C_a_l_l_i_n_g _S_i_d_e

When you use _c_a_l_l_r_p_c  you  have  no  control  over  the  RPC
delivery mechanism or the socket used to transport the data.
To illustrate the layer of RPC that lets  you  adjust  these
parameters,  consider  the following code to call the _n_u_s_e_r_s
service:

#include <stdio.h>
#include <rpc/rpc.h>
#include <utmp.h>
#include <rpcsvc/rusers.h>
#include <sys/socket.h>
#include <sys/time.h>
#include <netdb.h>

main(argc, argv)
     int argc;
     char **argv;
{
     struct hostent *hp;
     struct timeval pertry_timeout, total_timeout;
     struct sockaddr_in server_addr;
     int sock = RPC_ANYSOCK;
     register CLIENT *client;
     enum clnt_stat clnt_stat;
     unsigned long nusers;

     if (argc < 2) {
          fprintf(stderr, "usage: nusers hostname\n");
          exit(-1);
     }
     if ((hp = gethostbyname(argv[1])) == NULL) {
          fprintf(stderr, "can't get addr for %s\n",argv[1]);
          exit(-1);
     }
     pertry_timeout.tv_sec = 3;
     pertry_timeout.tv_usec = 0;
     bcopy(hp->h_addr, (caddr_t)&server_addr.sin_addr,
          hp->h_length);
     server_addr.sin_family = AF_INET;
     server_addr.sin_port =  0;
     if ((client = clntudp_create(&server_addr, RUSERSPROG,
       RUSERSVERS, pertry_timeout, &sock)) == NULL) {
          clnt_pcreateerror("clntudp_create");
          exit(-1);
     }
     total_timeout.tv_sec = 20;
     total_timeout.tv_usec = 0;
     clnt_stat = clnt_call(client, RUSERSPROC_NUM, xdr_void,
          0, xdr_u_long, &nusers, total_timeout);
     if (clnt_stat != RPC_SUCCESS) {
          clnt_perror(client, "rpc");









                           - 19 -


          exit(-1);
     }
     clnt_destroy(client);
     close(sock);
}

The low-level version of _c_a_l_l_r_p_c is _c_l_n_t__c_a_l_l which takes  a
_C_L_I_E_N_T  pointer  rather than a host name.  The parameters to
_c_l_n_t__c_a_l_l are a _C_L_I_E_N_T pointer, the  procedure  number,  the
XDR  routine  for serializing the argument, a pointer to the
argument, the  XDR  routine  for  deserializing  the  return
value,  a  pointer to where the return value will be placed,
and the time in seconds to wait for a reply.

The _C_L_I_E_N_T pointer is encoded with the transport  mechanism.
_c_a_l_l_r_p_c  uses  UDP,  thus  it  calls _c_l_n_t_u_d_p__c_r_e_a_t_e to get a
_C_L_I_E_N_T pointer.  To get TCP (Transmission Control Protocol),
you would use _c_l_n_t_t_c_p__c_r_e_a_t_e

The parameters to _c_l_n_t_u_d_p__c_r_e_a_t_e are the server address, the
program number, the version number, a timeout value (between
tries), and a pointer to a socket.  The  final  argument  to
_c_l_n_t__c_a_l_l  is  the total time to wait for a response.  Thus,
the number of tries is the _c_l_n_t__c_a_l_l timeout divided by  the
_c_l_n_t_u_d_p__c_r_e_a_t_e timeout.

There is one thing to note when using the _c_l_n_t__d_e_s_t_r_o_y call.
It  deallocates any space associated with the _C_L_I_E_N_T handle,
but it does not close the socket associated with  it,  which
was  passed as an argument to _c_l_n_t_u_d_p__c_r_e_a_t_e.  This makes it
possible, in cases where there are multiple  client  handles
using the same socket, to destroy one handle without closing
the socket that other handles are using.

To make a stream connection, the call to  _c_l_n_t_u_d_p__c_r_e_a_t_e  is
replaced with a call to _c_l_n_t_t_c_p__c_r_e_a_t_e.

        clnttcp_create(&server_addr, prognum, versnum, &sock,
                       inputsize, outputsize);

There is no timeout argument; instead, the receive and  send
buffer  sizes  must  be  specified.  When the _c_l_n_t_t_c_p__c_r_e_a_t_e
call is made, a TCP  connection  is  established.   All  RPC
calls  using  that  _C_L_I_E_N_T handle would use this connection.
The server side of an RPC call using TCP  has  _s_v_c_u_d_p__c_r_e_a_t_e
replaced by _s_v_c_t_c_p__c_r_e_a_t_e

        transp = svctcp_create(RPC_ANYSOCK, 0, 0);

The last two arguments to _s_v_c_t_c_p__c_r_e_a_t_e are send and receive
sizes  respectively.   If  `0'  is  specified  for either of
these, the system chooses a reasonable default.











                           - 20 -



_4.  _O_t_h_e_r _R_P_C _F_e_a_t_u_r_e_s

This section discusses some other aspects of  RPC  that  are
occasionally useful.

_4._1.  _S_e_l_e_c_t _o_n _t_h_e _S_e_r_v_e_r _S_i_d_e

Suppose a process is processing RPC requests while  perform-
ing  some  other  activity.   If the other activity involves
periodically updating a data structure, the process can  set
an  alarm signal before calling _s_v_c__r_u_n But if the other ac-
tivity involves waiting on a a file descriptor, the  _s_v_c__r_u_n
call won't work.  The code for _s_v_c__r_u_n is as follows:

void
svc_run()
{
     fd_set readfds;
     int dtbsz = getdtablesize();

     for (;;) {
          readfds = svc_fds;
          switch (select(dtbsz, &readfds, NULL,NULL,NULL)) {

          case -1:
               if (errno == EINTR)
                    continue;
               perror("select");
               return;
          case 0:
               break;
          default:
               svc_getreqset(&readfds);
          }
     }
}


You can bypass _s_v_c__r_u_n and call _s_v_c__g_e_t_r_e_q_s_e_t yourself.  All
you  need  to know are the file descriptors of the socket(s)
associated with the programs you are waiting on.   Thus  you
can  have your own _s_e_l_e_c_t that waits on both the RPC socket,
and your own descriptors.  Note that _s_v_c__f_d_s is a  bit  mask
of  all the file descriptors that RPC is using for services.
It can change everytime that  _a_n_y  RPC  library  routine  is
called,  because descriptors are constantly being opened and
closed, for example for TCP connections.

_4._2.  _B_r_o_a_d_c_a_s_t _R_P_C

The _p_o_r_t_m_a_p_p_e_r is a daemon that converts RPC program numbers
into  DARPA protocol port numbers; see the _p_o_r_t_m_a_p man page.
You can't do broadcast RPC without the portmapper.  Here are









                           - 21 -


the  main  differences  between broadcast RPC and normal RPC
calls:

1.   Normal RPC expects one answer,  whereas  broadcast  RPC
     expects  many  answers  (one  or  more answer from each
     responding machine).

2.   Broadcast RPC can only be supported by  packet-oriented
     (connectionless) transport protocols like UPD/IP.

3.   The implementation of broadcast RPC treats  all  unsuc-
     cessful  responses  as  garbage  by filtering them out.
     Thus, if there is a version mismatch between the broad-
     caster  and a remote service, the user of broadcast RPC
     never knows.

4.   All broadcast messages are sent to  the  portmap  port.
     Thus, only services that register themselves with their
     portmapper are accessible via the broadcast RPC mechan-
     ism.

_4._2._1.  _B_r_o_a_d_c_a_s_t _R_P_C _S_y_n_o_p_s_i_s

#include <rpc/pmap_clnt.h>
     . . .
enum clnt_stat clnt_stat;
     . . .
clnt_stat = clnt_broadcast(prognum, versnum, procnum,
  inproc, in, outproc, out, eachresult)
     u_long    prognum;        /* program number */
     u_long    versnum;        /* version number */
     u_long    procnum;        /* procedure number */
     xdrproc_t inproc;         /* xdr routine for args */
     caddr_t   in;             /* pointer to args */
     xdrproc_t outproc;        /* xdr routine for results */
     caddr_t   out;            /* pointer to results */
     bool_t    (*eachresult)();/* call with each result gotten */


The procedure _e_a_c_h_r_e_s_u_l_t is called each time a valid  result
is obtained.  It returns a boolean that indicates whether or
not the user wants more responses.

bool_t done;
     . . .
done = eachresult(resultsp, raddr)
     caddr_t resultsp;
     struct sockaddr_in *raddr; /* Addr of responding machine */

If _d_o_n_e is _T_R_U_E, then broadcasting stops and  _c_l_n_t__b_r_o_a_d_c_a_s_t
returns  successfully.   Otherwise,  the  routine  waits for
another response.  The request is rebroadcast  after  a  few
seconds  of waiting.  If no responses come back, the routine
returns with _R_P_C__T_I_M_E_D_O_U_T









                           - 22 -


_4._3.  _B_a_t_c_h_i_n_g

The RPC architecture is designed so that clients send a call
message,  and  wait  for servers to reply that the call suc-
ceeded.  This implies that  clients  do  not  compute  while
servers  are  processing a call.  This is inefficient if the
client does not want or need an  acknowledgement  for  every
message  sent.   It is possible for clients to continue com-
puting while waiting for a response, using RPC batch facili-
ties.

RPC messages can be placed in a ``pipeline'' of calls  to  a
desired  server;  this is called batching.  Batching assumes
that: 1) each RPC call in the pipeline requires no  response
from  the  server,  and  the server does not send a response
message; and 2) the pipeline of calls is  transported  on  a
reliable  byte  stream  transport such as TCP/IP.  Since the
server does not respond to every call, the client  can  gen-
erate new calls in parallel with the server executing previ-
ous  calls.   Furthermore,  the  TCP/IP  implementation  can
buffer up many call messages, and send them to the server in
one _w_r_i_t_e system call.  This  overlapped  execution  greatly
decreases  the  interprocess  communication  overhead of the
client and server processes, and the total elapsed time of a
series of calls.

Since the batched calls  are  buffered,  the  client  should
eventually  do a legitimate call in order to flush the pipe-
line.

A contrived example of batching follows.   Assume  a  string
rendering  service  (like  a  window system) has two similar
calls: one renders a string and returns void results,  while
the  other renders a string and remains silent.  The service
(using the TCP/IP transport) may look like:




























                           - 23 -


#include <stdio.h>
#include <rpc/rpc.h>
#include <suntool/windows.h>

void windowdispatch();

main()
{
     SVCXPRT *transp;

     transp = svctcp_create(RPC_ANYSOCK, 0, 0);
     if (transp == NULL){
          fprintf(stderr, "can't create an RPC server\n");
          exit(1);
     }
     pmap_unset(WINDOWPROG, WINDOWVERS);
     if (!svc_register(transp, WINDOWPROG, WINDOWVERS,
       windowdispatch, IPPROTO_TCP)) {
          fprintf(stderr, "can't register WINDOW service\n");
          exit(1);
     }
     svc_run();  /* Never returns */
     fprintf(stderr, "should never reach this point\n");
}

void
windowdispatch(rqstp, transp)
     struct svc_req *rqstp;
     SVCXPRT *transp;
{
     char *s = NULL;

     switch (rqstp->rq_proc) {
     case NULLPROC:
          if (!svc_sendreply(transp, xdr_void, 0))
               fprintf(stderr, "can't reply to RPC call\n");
          return;
     case RENDERSTRING:
          if (!svc_getargs(transp, xdr_wrapstring, &s)) {
               fprintf(stderr, "can't decode arguments\n");
               /*
                * Tell caller he screwed up
                */
               svcerr_decode(transp);
               break;
          }
          /*
           * Call here to render the string s
           */
          if (!svc_sendreply(transp, xdr_void, NULL))
               fprintf(stderr, "can't reply to RPC call\n");
          break;
     case RENDERSTRING_BATCHED:
          if (!svc_getargs(transp, xdr_wrapstring, &s)) {









                           - 24 -


               fprintf(stderr, "can't decode arguments\n");
               /*
                * We are silent in the face of protocol errors
                */
               break;
          }
          /*
           * Call here to render string s, but send no reply!
           */
          break;
     default:
          svcerr_noproc(transp);
          return;
     }
     /*
      * Now free string allocated while decoding arguments
      */
     svc_freeargs(transp, xdr_wrapstring, &s);
}

Of course the service could have one  procedure  that  takes
the string and a boolean to indicate whether or not the pro-
cedure should respond.

In order for a client to take  advantage  of  batching,  the
client  must  perform RPC calls on a TCP-based transport and
the actual calls must have the following attributes: 1)  the
result's  XDR  routine  must  be  zero _N_U_L_L), and 2) the RPC
call's timeout must be zero.


































                           - 25 -



Here is an example of a client that uses batching to  render
a  bunch of strings; the batching is flushed when the client
gets a null string:

#include <stdio.h>
#include <rpc/rpc.h>
#include <sys/socket.h>
#include <sys/time.h>
#include <netdb.h>
#include <suntool/windows.h>

main(argc, argv)
     int argc;
     char **argv;
{
     struct hostent *hp;
     struct timeval pertry_timeout, total_timeout;
     struct sockaddr_in server_addr;
     int sock = RPC_ANYSOCK;
     register CLIENT *client;
     enum clnt_stat clnt_stat;
     char buf[1000], *s = buf;

     if ((client = clnttcp_create(&server_addr,
       WINDOWPROG, WINDOWVERS, &sock, 0, 0)) == NULL) {
          perror("clnttcp_create");
          exit(-1);
     }
     total_timeout.tv_sec = 0;
     total_timeout.tv_usec = 0;
     while (scanf("%s", s) != EOF) {
          clnt_stat = clnt_call(client, RENDERSTRING_BATCHED,
               xdr_wrapstring, &s, NULL, NULL, total_timeout);
          if (clnt_stat != RPC_SUCCESS) {
               clnt_perror(client, "batched rpc");
               exit(-1);
          }
     }

     /* Now flush the pipeline */

     total_timeout.tv_sec = 20;
     clnt_stat = clnt_call(client, NULLPROC, xdr_void, NULL,
          xdr_void, NULL, total_timeout);
     if (clnt_stat != RPC_SUCCESS) {
          clnt_perror(client, "rpc");
          exit(-1);
     }
     clnt_destroy(client);
}

Since the server sends no message,  the  clients  cannot  be
notified  of any of the failures that may occur.  Therefore,









                           - 26 -


clients are on their own when it comes to handling errors.

The above example was completed to render all of the  (2000)
lines  in  the file /_e_t_c/_t_e_r_m_c_a_p.  The rendering service did
nothing but throw the lines away.  The example  was  run  in
the  following  four  configurations:  1) machine to itself,
regular RPC; 2) machine to itself, batched RPC;  3)  machine
to  another, regular RPC; and 4) machine to another, batched
RPC.  The results are as  follows:  1)  50  seconds;  2)  16
seconds;  3)  52  seconds; 4) 10 seconds.  Running _f_s_c_a_n_f on
/_e_t_c/_t_e_r_m_c_a_p only requires six seconds.  These timings  show
the  advantage of protocols that allow for overlapped execu-
tion, though these protocols are often hard to design.

_4._4.  _A_u_t_h_e_n_t_i_c_a_t_i_o_n

In the examples presented so far, the caller  never  identi-
fied  itself to the server, and the server never required an
ID from the caller.  Clearly, some network services, such as
a  network  filesystem,  require stronger security than what
has been presented so far.

In reality, every RPC call is authenticated by the RPC pack-
age  on  the  server,  and similarly, the RPC client package
generates and sends authentication parameters.  Just as dif-
ferent transports (TCP/IP or UDP/IP) can be used when creat-
ing RPC clients and servers, different forms of  authentica-
tion can be associated with RPC clients; the default authen-
tication type used as a default is type _n_o_n_e.

The authentication subsystem of  the  RPC  package  is  open
ended.   That  is, numerous types of authentication are easy
to support.

_4._4._1.  _U_N_I_X _A_u_t_h_e_n_t_i_c_a_t_i_o_n

The Client Side

When a caller creates a new RPC client handle as in:

        clnt = clntudp_create(address, prognum, versnum,
                        wait, sockp)

the appropriate transport instance  defaults  the  associate
authentication handle to be

        clnt->cl_auth = authnone_create();

The RPC client can choose to use _U_N_I_X  style  authentication
by  setting _c_l_n_t->_c_l__a_u_t_h after creating the RPC client han-
dle:

        clnt->cl_auth = authunix_create_default();










                           - 27 -


This causes each RPC call associated with _c_l_n_t to carry with
it the following authentication credentials structure:

/*
 * UNIX style credentials.
 */
struct authunix_parms {
    u_long  aup_time;       /* credentials creation time */
    char    *aup_machname;  /* host name where client is */
    int     aup_uid;        /* client's UNIX effective uid */
    int     aup_gid;        /* client's current group id */
    u_int   aup_len;        /* element length of aup_gids */
    int     *aup_gids;      /* array of groups user is in */
};

These fields are set by _a_u_t_h_u_n_i_x__c_r_e_a_t_e__d_e_f_a_u_l_t by  invoking
the  appropriate  system  calls.  Since the RPC user created
this new style of authentication, the  user  is  responsible
for destroying it with:

        auth_destroy(clnt->cl_auth);

This should be done in all cases, to conserve memory.


The Server Side

Service implementors have a harder time dealing with authen-
tication  issues  since  the  RPC package passes the service
dispatch routine a request that has an arbitrary authentica-
tion  style  associated  with  it.  Consider the fields of a
request handle passed to a service dispatch routine:

/*
 * An RPC Service request
 */
struct svc_req {
    u_long    rq_prog;        /* service program number */
    u_long    rq_vers;        /* service protocol vers num */
    u_long    rq_proc;        /* desired procedure number */
    struct opaque_auth rq_cred; /* raw credentials from wire */
    caddr_t   rq_clntcred;  /* credentials (read only) */
};

The _r_q__c_r_e_d is  mostly  opaque,  except  for  one  field  of
interest: the style or flavor of authentication credentials:

















                           - 28 -


/*
 * Authentication info.  Mostly opaque to the programmer.
 */
struct opaque_auth {
    enum_t  oa_flavor;  /* style of credentials */
    caddr_t oa_base;    /* address of more auth stuff */
    u_int   oa_length;  /* not to exceed MAX_AUTH_BYTES */
};

The RPC package guarantees  the  following  to  the  service
dispatch routine:

1.   That the request's _r_q__c_r_e_d is well  formed.   Thus  the
     service   implementor   may   inspect   the   request's
     _r_q__c_r_e_d._o_a__f_l_a_v_o_r to determine which style of authenti-
     cation  the  caller  used.  The service implementor may
     also wish to inspect the other fields of _r_q__c_r_e_d if the
     style  is  not  one  of the styles supported by the RPC
     package.

2.   That the request's _r_q__c_l_n_t_c_r_e_d field is either _N_U_L_L  or
     points to a well formed structure that corresponds to a
     supported   style   of   authentication    credentials.
     Remember  that  only _u_n_i_x style is currently supported,
     so (currently) _r_q__c_l_n_t_c_r_e_d could be cast to  a  pointer
     to  an  _a_u_t_h_u_n_i_x__p_a_r_m_s  structure.   If  _r_q__c_l_n_t_c_r_e_d is
     _N_U_L_L, the service implementor may wish to  inspect  the
     other  (opaque)  fields  of _r_q__c_r_e_d in case the service
     knows about a new type of authentication that  the  RPC
     package does not know about.

Our remote users service example can be extended so that  it
computes results for all users except UID 16:






























                           - 29 -


nuser(rqstp, transp)
     struct svc_req *rqstp;
     SVCXPRT *transp;
{
     struct authunix_parms *unix_cred;
     int uid;
     unsigned long nusers;

     /*
      * we don't care about authentication for null proc
      */
     if (rqstp->rq_proc == NULLPROC) {
          if (!svc_sendreply(transp, xdr_void, 0)) {
               fprintf(stderr, "can't reply to RPC call\n");
               exit(1);
           }
           return;
     }
     /*
      * now get the uid
      */
     switch (rqstp->rq_cred.oa_flavor) {
     case AUTH_UNIX:
          unix_cred =
               (struct authunix_parms *)rqstp->rq_clntcred;
          uid = unix_cred->aup_uid;
          break;
     case AUTH_NULL:
     default:
          svcerr_weakauth(transp);
          return;
     }
     switch (rqstp->rq_proc) {
     case RUSERSPROC_NUM:
          /*
           * make sure caller is allowed to call this proc
           */
          if (uid == 16) {
               svcerr_systemerr(transp);
               return;
          }
          /*
           * code here to compute the number of users
           * and put in variable nusers
           */
          if (!svc_sendreply(transp, xdr_u_long, &nusers)) {
               fprintf(stderr, "can't reply to RPC call\n");
               exit(1);
          }
          return;
     default:
          svcerr_noproc(transp);
          return;
     }









                           - 30 -


}

A few things should be noted here.  First, it  is  customary
not  to  check the authentication parameters associated with
the  _N_U_L_L_P_R_O_C  (procedure  number  zero).   Second,  if  the
authentication  parameter's  type  is  not suitable for your
service, you should call _s_v_c_e_r_r__w_e_a_k_a_u_t_h  And  finally,  the
service  protocol  itself  should  return  status for access
denied; in the case of our example, the  protocol  does  not
have  such  a  status,  so  we  call  the  service primitive
_s_v_c_e_r_r__s_y_s_t_e_m_e_r_r instead.

The last point underscores  the  relation  between  the  RPC
authentication package and the services; RPC deals only with
_a_u_t_h_e_n_t_i_c_a_t_i_o_n and not with individual services' _a_c_c_e_s_s _c_o_n_-
_t_r_o_l.   The  services  themselves  must  implement their own
access control policies and reflect these policies as return
statuses in their protocols.

_4._5.  _U_s_i_n_g _I_n_e_t_d

An RPC server can be started from _i_n_e_t_d The only  difference
from  the  usual  code  is that the service creation routine
should be called in the following form:

transp = svcudp_create(0);     /* For UDP */
transp = svctcp_create(0,0,0); /* For listener TCP sockets */
transp = svcfd_create(0,0,0);  /* For connected TCP sockets */

since _i_n_e_t passes a socket  as  file  descriptor  0.   Also,
_s_v_c__r_e_g_i_s_t_e_r should be called as

svc_register(transp, PROGNUM, VERSNUM, service, 0);

with the final flag as 0, since the program would already be
registered  by  _i_n_e_t_d Remember that if you want to exit from
the server process and return control to _i_n_e_t  you  need  to
explicitly exit, since _s_v_c__r_u_n never returns.

The format of entries in /_e_t_c/_i_n_e_t_d._c_o_n_f for RPC services is
in one of the following two forms:

p_name/version dgram  rpc/udp wait/nowait user server args
p_name/version stream rpc/tcp wait/nowait user server args

where _p__n_a_m_e is the symbolic  name  of  the  program  as  it
appears  in  _r_p_c(5),  _s_e_r_v_e_r  is the C code implementing the
server, and _p_r_o_g_r_a_m and _v_e_r_s_i_o_n are the program and  version
numbers   of   the   service.   For  more  information,  see
_i_n_e_t_d._c_o_n_f(5).

If the same program handles multiple versions, then the ver-
sion number can be a range, as in this example:










                           - 31 -


rstatd/1-2 dgram rpc/udp wait root /usr/etc/rpc.rstatd


_5.  _M_o_r_e _E_x_a_m_p_l_e_s


_5._1.  _V_e_r_s_i_o_n_s

By convention, the first version number of program  _P_R_O_G  is
_P_R_O_G_V_E_R_S__O_R_I_G  and  the most recent version is _P_R_O_G_V_E_R_S Sup-
pose there is a new version of the _u_s_e_r program that returns
an  _u_n_s_i_g_n_e_d  rather  than  a _l_o_n_g.  If we name this version
_R_U_S_E_R_S_V_E_R_S__S_H_O_R_T then a server that wants  to  support  both
versions would do a double register.

if (!svc_register(transp, RUSERSPROG, RUSERSVERS_ORIG,
  nuser, IPPROTO_TCP)) {
     fprintf(stderr, "can't register RUSER service\n");
     exit(1);
}
if (!svc_register(transp, RUSERSPROG, RUSERSVERS_SHORT,
  nuser, IPPROTO_TCP)) {
     fprintf(stderr, "can't register RUSER service\n");
     exit(1);
}

Both versions can be handled by the same C procedure:




































                           - 32 -


nuser(rqstp, transp)
     struct svc_req *rqstp;
     SVCXPRT *transp;
{
     unsigned long nusers;
     unsigned short nusers2;

     switch (rqstp->rq_proc) {
     case NULLPROC:
          if (!svc_sendreply(transp, xdr_void, 0)) {
               fprintf(stderr, "can't reply to RPC call\n");
               exit(1);
          }
          return;
     case RUSERSPROC_NUM:
          /*
           * code here to compute the number of users
           * and put in variable nusers
           */
          nusers2 = nusers;
          switch (rqstp->rq_vers) {
          case RUSERSVERS_ORIG:
               if (!svc_sendreply(transp, xdr_u_long, &nusers)) {
                    fprintf(stderr, "can't reply to RPC call\n");
               }
               break;
          case RUSERSVERS_SHORT:
               if (!svc_sendreply(transp, xdr_u_short, &nusers2)) {
                    fprintf(stderr, "can't reply to RPC call\n");
               }
               break;
          }
     default:
          svcerr_noproc(transp);
          return;
     }
}


























                           - 33 -



_5._2.  _T_C_P

Here is an example that is essentially _r_c_p The initiator  of
the  RPC  _s_n_d  call takes its standard input and sends it to
the server _r_c_v which prints it on standard output.  The  RPC
call  uses TCP.  This also illustrates an XDR procedure that
behaves differently on serialization  than  on  deserializa-
tion.

/*
 * The xdr routine:
 *        on decode, read from wire, write onto fp
 *        on encode, read from fp, write onto wire
 */
#include <stdio.h>
#include <rpc/rpc.h>

xdr_rcp(xdrs, fp)
     XDR *xdrs;
     FILE *fp;
{
     unsigned long size;
     char buf[BUFSIZ], *p;

     if (xdrs->x_op == XDR_FREE)/* nothing to free */
          return 1;
     while (1) {
          if (xdrs->x_op == XDR_ENCODE) {
               if ((size = fread(buf, sizeof(char), BUFSIZ,
                 fp)) == 0 && ferror(fp)) {
                    fprintf(stderr, "can't fread\n");
                    exit(1);
               }
          }
          p = buf;
          if (!xdr_bytes(xdrs, &p, &size, BUFSIZ))
               return 0;
          if (size == 0)
               return 1;
          if (xdrs->x_op == XDR_DECODE) {
               if (fwrite(buf, sizeof(char), size,
                 fp) != size) {
                    fprintf(stderr, "can't fwrite\n");
                    exit(1);
               }
          }
     }
}














                           - 34 -


/*
 * The sender routines
 */
#include <stdio.h>
#include <netdb.h>
#include <rpc/rpc.h>
#include <sys/socket.h>
#include <sys/time.h>

main(argc, argv)
     int argc;
     char **argv;
{
     int xdr_rcp();
     int err;

     if (argc < 2) {
          fprintf(stderr, "usage: %s servername\n", argv[0]);
          exit(-1);
     }
     if ((err = callrpctcp(argv[1], RCPPROG, RCPPROC,
       RCPVERS, xdr_rcp, stdin, xdr_void, 0) != 0)) {
          clnt_perrno(err);
          fprintf(stderr, "can't make RPC call\n");
          exit(1);
     }
}

callrpctcp(host, prognum, procnum, versnum,
           inproc, in, outproc, out)
     char *host, *in, *out;
     xdrproc_t inproc, outproc;
{
     struct sockaddr_in server_addr;
     int socket = RPC_ANYSOCK;
     enum clnt_stat clnt_stat;
     struct hostent *hp;
     register CLIENT *client;
     struct timeval total_timeout;

     if ((hp = gethostbyname(host)) == NULL) {
          fprintf(stderr, "can't get addr for '%s'\n", host);
          exit(-1);
     }
     bcopy(hp->h_addr, (caddr_t)&server_addr.sin_addr,
          hp->h_length);
     server_addr.sin_family = AF_INET;
     server_addr.sin_port =  0;
     if ((client = clnttcp_create(&server_addr, prognum,
       versnum, &socket, BUFSIZ, BUFSIZ)) == NULL) {
          perror("rpctcp_create");
          exit(-1);
     }
     total_timeout.tv_sec = 20;









                           - 35 -


     total_timeout.tv_usec = 0;
     clnt_stat = clnt_call(client, procnum,
          inproc, in, outproc, out, total_timeout);
     clnt_destroy(client);
     return (int)clnt_stat;
}

























































                           - 36 -


/*
 * The receiving routines
 */
#include <stdio.h>
#include <rpc/rpc.h>

main()
{
     register SVCXPRT *transp;
     int rcp_service(), xdr_rcp();

     if ((transp = svctcp_create(RPC_ANYSOCK,
       BUFSIZ, BUFSIZ)) == NULL) {
          fprintf("svctcp_create: error\n");
          exit(1);
     }
     pmap_unset(RCPPROG, RCPVERS);
     if (!svc_register(transp,
       RCPPROG, RCPVERS, rcp_service, IPPROTO_TCP)) {
          fprintf(stderr, "svc_register: error\n");
          exit(1);
     }
     svc_run();  /* never returns */
     fprintf(stderr, "svc_run should never return\n");
}

rcp_service(rqstp, transp)
     register struct svc_req *rqstp;
     register SVCXPRT *transp;
{
     switch (rqstp->rq_proc) {
     case NULLPROC:
          if (svc_sendreply(transp, xdr_void, 0) == 0) {
               fprintf(stderr, "err: rcp_service");
               exit(1);
          }
          return;
     case RCPPROC_FP:
          if (!svc_getargs(transp, xdr_rcp, stdout)) {
               svcerr_decode(transp);
               return;
          }
          if (!svc_sendreply(transp, xdr_void, 0)) {
               fprintf(stderr, "can't reply\n");
               return;
          }
          exit(0);
     default:
          svcerr_noproc(transp);
          return;
     }
}











                           - 37 -


_5._3.  _C_a_l_l_b_a_c_k _P_r_o_c_e_d_u_r_e_s

Occasionally, it is useful to have a server become a client,
and  make  an RPC call back the process which is its client.
An example is remote debugging, where the client is a window
system  program, and the server is a debugger running on the
remote machine.  Most of the time, the user clicks  a  mouse
button  at  the  debugging  window, which converts this to a
debugger command, and then makes an RPC call to  the  server
(where the debugger is actually running), telling it to exe-
cute that command.  However, when the debugger hits a break-
point,  the  roles  are  reversed, and the debugger wants to
make an rpc call to the  window  program,  so  that  it  can
inform the user that a breakpoint has been reached.

In order to do an RPC callback, you need a program number to
make the RPC call on.  Since this will be a dynamically gen-
erated program number, it should be in the transient  range,
_0_x_4_0_0_0_0_0_0_0 - _0_x_5_f_f_f_f_f_f_f.  The routine _g_e_t_t_r_a_n_s_i_e_n_t returns a
valid program number in the transient range,  and  registers
it  with  the  portmapper.   It only talks to the portmapper
running on the same  machine  as  the  _g_e_t_t_r_a_n_s_i_e_n_t  routine
itself.   The  call to _p_m_a_p__s_e_t is a test and set operation,
in that it indivisibly tests whether a  program  number  has
already  been  registered,  and if it has not, then reserves
it.  On return, the _s_o_c_k_p argument  will  contain  a  socket
that  can  be  used  as  the argument to an _s_v_c_u_d_p__c_r_e_a_t_e or
_s_v_c_t_c_p__c_r_e_a_t_e call.



































                           - 38 -


#include <stdio.h>
#include <rpc/rpc.h>
#include <sys/socket.h>

gettransient(proto, vers, sockp)
     int proto, vers, *sockp;
{
     static int prognum = 0x40000000;
     int s, len, socktype;
     struct sockaddr_in addr;

     switch(proto) {
          case IPPROTO_UDP:
               socktype = SOCK_DGRAM;
               break;
          case IPPROTO_TCP:
               socktype = SOCK_STREAM;
               break;
          default:
               fprintf(stderr, "unknown protocol type\n");
               return 0;
     }
     if (*sockp == RPC_ANYSOCK) {
          if ((s = socket(AF_INET, socktype, 0)) < 0) {
               perror("socket");
               return (0);
          }
          *sockp = s;
     }
     else
          s = *sockp;
     addr.sin_addr.s_addr = 0;
     addr.sin_family = AF_INET;
     addr.sin_port = 0;
     len = sizeof(addr);
     /*
      * may be already bound, so don't check for error
      */
     bind(s, &addr, len);
     if (getsockname(s, &addr, &len)< 0) {
          perror("getsockname");
          return (0);
     }
     while (!pmap_set(prognum++, vers, proto,
          ntohs(addr.sin_port))) continue;
     return (prognum-1);
}

_N_O_T_E: _T_h_e _c_a_l_l _t_o _n_t_o_h_s is necessary to ensure that the port
number  in _a_d_d_r._s_i_n__p_o_r_t, which is in _n_e_t_w_o_r_k byte order, is
passed in _h_o_s_t byte order (as _p_m_a_p__s_e_t expects).  This works
on  all  Sun  machines.   See the _b_y_t_e_o_r_d_e_r(3N) man page for
more details on the conversion  of  network  addresses  from
network to host byte order.









                           - 39 -



The following pair of programs illustrate  how  to  use  the
_g_e_t_t_r_a_n_s_i_e_n_t  routine.   The client makes an RPC call to the
server, passing it a transient  program  number.   Then  the
client waits around to receive a callback from the server at
that program number.  The server registers the program _E_X_A_M-
_P_L_E_P_R_O_G  so that it can receive the RPC call informing it of
the callback program number.  Then at some random  time  (on
receiving  an _A_L_R_M signal in this example), it sends a call-
back RPC call, using the program number it received earlier.

/*
 * client
 */
#include <stdio.h>
#include <rpc/rpc.h>

int callback();
char hostname[256];

main()
{
     int x, ans, s;
     SVCXPRT *xprt;

     gethostname(hostname, sizeof(hostname));
     s = RPC_ANYSOCK;
     x = gettransient(IPPROTO_UDP, 1, &s);
     fprintf(stderr, "client gets prognum %d\n", x);
     if ((xprt = svcudp_create(s)) == NULL) {
       fprintf(stderr, "rpc_server: svcudp_create\n");
          exit(1);
     }
     /* protocol is 0 - gettransient() does registering
      */
     (void)svc_register(xprt, x, 1, callback, 0);
     ans = callrpc(hostname, EXAMPLEPROG, EXAMPLEVERS,
          EXAMPLEPROC_CALLBACK, xdr_int, &x, xdr_void, 0);
     if ((enum clnt_stat) ans != RPC_SUCCESS) {
          fprintf(stderr, "call: ");
          clnt_perrno(ans);
          fprintf(stderr, "\n");
     }
     svc_run();
     fprintf(stderr, "Error: svc_run shouldn't return\n");
}

callback(rqstp, transp)
     register struct svc_req *rqstp;
     register SVCXPRT *transp;
{
     switch (rqstp->rq_proc) {
          case 0:
               if (!svc_sendreply(transp, xdr_void, 0)) {









                           - 40 -


                    fprintf(stderr, "err: rusersd\n");
                    exit(1);
               }
               exit(0);
          case 1:
               if (!svc_getargs(transp, xdr_void, 0)) {
                    svcerr_decode(transp);
                    exit(1);
               }
               fprintf(stderr, "client got callback\n");
               if (!svc_sendreply(transp, xdr_void, 0)) {
                    fprintf(stderr, "err: rusersd");
                    exit(1);
               }
     }
}















































                           - 41 -


/*
 * server
 */
#include <stdio.h>
#include <rpc/rpc.h>
#include <sys/signal.h>

char *getnewprog();
char hostname[256];
int docallback();
int pnum;      /* program number for callback routine */

main()
{
     gethostname(hostname, sizeof(hostname));
     registerrpc(EXAMPLEPROG, EXAMPLEVERS,
       EXAMPLEPROC_CALLBACK, getnewprog, xdr_int, xdr_void);
     fprintf(stderr, "server going into svc_run\n");
     signal(SIGALRM, docallback);
     alarm(10);
     svc_run();
     fprintf(stderr, "Error: svc_run shouldn't return\n");
}

char *
getnewprog(pnump)
     char *pnump;
{
     pnum = *(int *)pnump;
     return NULL;
}

docallback()
{
     int ans;

     ans = callrpc(hostname, pnum, 1, 1, xdr_void, 0,
          xdr_void, 0);
     if (ans != 0) {
          fprintf(stderr, "server: ");
          clnt_perrno(ans);
          fprintf(stderr, "\n");
     }
}


rpcgen _P_r_o_g_r_a_m_m_i_n_g _G_u_i_d_e

_1.  _T_h_e rpcgen _P_r_o_t_o_c_o_l _C_o_m_p_i_l_e_r

The details of programming applications to use  Remote  Pro-
cedure  Calls can be overwhelming.  Perhaps most daunting is
the writing of the XDR routines necessary  to  convert  pro-
cedure  arguments  and results into their network format and









                           - 42 -


vice-versa.

Fortunately, _r_p_c_g_e_n exists to  help  programmers  write  RPC
applications  simply  and directly.  _r_p_c_g_e_n does most of the
dirty  work,  allowing  programmers  to  debug   the    main
features  of their application, instead of requiring them to
spend most of their time debugging their  network  interface
code.

_r_p_c_g_e_n is a  compiler.  It accepts a remote  program  inter-
face  definition written in a language, called RPC Language,
which is similar to C.  It  produces  a  C  language  output
which  includes  stub  versions  of  the  client routines, a
server skeleton, XDR filter routines for both parameters and
results, and a header file that contains common definitions.
The client stubs interface with the RPC library  and  effec-
tively hide the network from their callers.  The server stub
similarly hides the network from the server procedures  that
are  to be invoked by remote clients.  _r_p_c_g_e_n's output files
can be compiled and linked in the usual way.  The  developer
writes  server  procedures-in any language that observes Sun
calling conventions-and links them with the server  skeleton
produced  by _r_p_c_g_e_n to get an executable server program.  To
use a remote program, a programmer writes an  ordinary  main
program that makes local procedure calls to the client stubs
produced by _r_p_c_g_e_n.   Linking  this  program  with  _r_p_c_g_e_n's
stubs  creates  an executable program.  (At present the main
program must be written in C).  _r_p_c_g_e_n options can  be  used
to  suppress stub generation and to specify the transport to
be used by the server stub.

Like all compilers, _r_p_c_g_e_n  reduces  development  time  that
would otherwise be spent coding and debugging low-level rou-
tines.  All compilers, including _r_p_c_g_e_n, do this at a  small
cost  in  efficiency  and flexibility.  However,   many com-
pilers allow  escape  hatches for programmers to   mix  low-
level  code  with   high-level code. _r_p_c_g_e_n is no exception.
In speed-critical applications, hand-written routines can be
linked with the _r_p_c_g_e_n output without any difficulty.  Also,
one may proceed by using _r_p_c_g_e_n output as a starting  point,
and rewriting it as necessary.

_2.  _C_o_n_v_e_r_t_i_n_g _L_o_c_a_l _P_r_o_c_e_d_u_r_e_s _i_n_t_o _R_e_m_o_t_e _P_r_o_c_e_d_u_r_e_s

Assume an application that runs on  a  single  machine,  one
which  we  want to convert to run over the network.  Here we
will demonstrate such  a  conversion  by  way  of  a  simple
example-a program that prints a message to the console:















                           - 43 -


/*
 * printmsg.c: print a message on the console
 */
#include <stdio.h>

main(argc, argv)
     int argc;
     char *argv[];
{
     char *message;

     if (argc < 2) {
          fprintf(stderr, "usage: %s <message>\n", argv[0]);
          exit(1);
     }
     message = argv[1];

     if (!printmessage(message)) {
          fprintf(stderr, "%s: couldn't print your message\n",
               argv[0]);
          exit(1);
     }
     printf("Message delivered!0);
}
/*
 * Print a message to the console.
 * Return a boolean indicating whether the message was actually printed.
 */
printmessage(msg)
     char *msg;
{
     FILE *f;

     f = fopen("/dev/console", "w");
     if (f == NULL) {
          return (0);
     }
     fprintf(f, "%s\n", msg);
     fclose(f);
     return(1);
}


And then, of course:

example%  cc printmsg.c -o printmsg
example%  printmsg "Hello, there."
Message delivered!
example%


If _p_r_i_n_t_m_e_s_s_a_g_e was turned into  a remote procedure, then it
could  be   called  from anywhere in   the network. Ideally,
one would just  like to stick   a  keyword  like  _r_e_m_o_t_e  in









                           - 44 -


front   of  a procedure to turn it into a  remote procedure.
Unfortunately, we  have to live  within the  constraints  of
the    C  language, since it existed   long before  RPC did.
But   even without language support, it's not very difficult
to make a procedure remote.

In  general, it's necessary to figure  out  what  the  types
are  for  all  procedure inputs and outputs.  In  this case,
we  have a procedure _p_r_i_n_t_m_e_s_s_a_g_e which takes a   string  as
input, and returns  an integer as output.  Knowing  this, we
can write a  protocol specification  in  RPC  language  that
describes the remote  version of _p_r_i_n_t_m_e_s_s_a_g_e.  Here it is:

/*
 * msg.x: Remote message printing protocol
 */

program MESSAGEPROG {
     version MESSAGEVERS {
          int PRINTMESSAGE(string) = 1;
     } = 1;
} = 99;


Remote procedures are part of remote programs, so  we  actu-
ally  declared  an  entire  remote program  here  which con-
tains  the single procedure  _P_R_I_N_T_M_E_S_S_A_G_E.   This  procedure
was declared to be  in version  1 of the remote program.  No
null procedure (procedure 0)  is  necessary  because  _r_p_c_g_e_n
generates it automatically.

Notice  that  everything  is  declared  with   all   capital
letters.   This is not required, but is a good convention to
follow.

Notice also that the argument type is "string" and not "char
*".   This is because a "char *" in C is ambiguous. Program-
mers usually intend it to  mean   a  null-terminated  string
of  characters, but  it  could also represent a pointer to a
single character or a  pointer to an  array  of  characters.
In   RPC  language,  a  null-terminated  string is unambigu-
ously called a "string".

There are  just two more things to  write.  First, there  is
the  remote  procedure  itself.   Here's the definition of a
remote procedure to implement the _P_R_I_N_T_M_E_S_S_A_G_E procedure  we
declared above:
















                           - 45 -


/*
 * msg_proc.c: implementation of the remote procedure "printmessage"
 */

#include <stdio.h>
#include <rpc/rpc.h>    /* always needed  */
#include "msg.h"        /* need this too: msg.h will be generated by rpcgen */

/*
 * Remote verson of "printmessage"
 */
int *
printmessage_1(msg)
     char **msg;
{
     static int result;  /* must be static! */
     FILE *f;

     f = fopen("/dev/console", "w");
     if (f == NULL) {
          result = 0;
          return (&result);
     }
     fprintf(f, "%s\n", *msg);
     fclose(f);
     result = 1;
     return (&result);
}


Notice here that the declaration  of  the  remote  procedure
_p_r_i_n_t_m_e_s_s_a_g_e__1  differs  from  that  of  the local procedure
_p_r_i_n_t_m_e_s_s_a_g_e in three ways:

1.   It takes a pointer to a  string  instead  of  a  string
     itself.   This is true of all  remote procedures:  they
     always take pointers to  their  arguments  rather  than
     the arguments themselves.

2.   It returns a pointer to  an   integer  instead  of   an
     integer  itself.  This is also generally true of remote
     procedures: they  always  return  a  pointer  to  their
     results.

3.   It has  an "_1" appended to  its name.    In   general,
     all   remote  procedures  called by _r_p_c_g_e_n are named by
     the following rule: the name in the program  definition
     (here  _P_R_I_N_T_M_E_S_S_A_G_E)  is  converted   to all lower-case
     letters, an underbar ("_")   is appended   to  it,  and
     finally the version number (here 1) is appended.

The last thing to do is declare the main client program that
will call the remote procedure. Here it is:










                           - 46 -


/*
 * rprintmsg.c: remote version of "printmsg.c"
 */
#include <stdio.h>
#include <rpc/rpc.h>     /* always needed  */
#include "msg.h"         /* need this too: msg.h will be generated by rpcgen */

main(argc, argv)
     int argc;
     char *argv[];
{
     CLIENT *cl;
     int *result;
     char *server;
     char *message;

     if (argc < 3) {
          fprintf(stderr, "usage: %s host message\n", argv[0]);
          exit(1);
     }

     /*
      * Save values of command line arguments
      */
     server = argv[1];
     message = argv[2];

     /*
      * Create client "handle" used for calling MESSAGEPROG on the
      * server designated on the command line. We tell the RPC package
      * to use the "tcp" protocol when contacting the server.
      */
     cl = clnt_create(server, MESSAGEPROG, MESSAGEVERS, "tcp");
     if (cl == NULL) {
          /*
           * Couldn't establish connection with server.
           * Print error message and die.
           */
          clnt_pcreateerror(server);
          exit(1);
     }

     /*
      * Call the remote procedure "printmessage" on the server
      */
     result = printmessage_1(&message, cl);
     if (result == NULL) {
          /*
           * An error occurred while calling the server.
           * Print error message and die.
           */
          clnt_perror(cl, server);
          exit(1);
     }









                           - 47 -


     /*
      * Okay, we successfully called the remote procedure.
      */
     if (*result == 0) {
          /*
           * Server was unable to print our message.
           * Print error message and die.
           */
          fprintf(stderr, "%s: %s couldn't print your message\n",
               argv[0], server);
          exit(1);
     }

     /*
      * The message got printed on the server's console
      */
     printf("Message delivered to %s!\n", server);
}

There are two things to note here:

1.   First a client  "handle"  is  created   using  the  RPC
     library  routine  _c_l_n_t__c_r_e_a_t_e.  This client handle will
     be passed  to the stub routines which call  the  remote
     procedure.

2.   The remote procedure _p_r_i_n_t_m_e_s_s_a_g_e__1 is  called  exactly
     the  same  way  as it is  declared in _m_s_g__p_r_o_c._c except
     for the inserted client handle as the first argument.

Here's how to put all of the pieces together:

example%  rpcgen msg.x
example%  cc rprintmsg.c msg_clnt.c -o rprintmsg
example%  cc msg_proc.c msg_svc.c -o msg_server

Two programs were compiled here: the client program _p_r_i_n_t_m_s_g
and  the  server   program  _m_s_g__s_e_r_v_e_r.   Before  doing this
though, _r_p_c_g_e_n was used to fill in the missing pieces.

Here is what _r_p_c_g_e_n did with the input file _m_s_g._x:

1.   It created a header file called  _m_s_g._h  that  contained
     #define's for _M_E_S_S_A_G_E_P_R_O_G, _M_E_S_S_A_G_E_V_E_R_S and _P_R_I_N_T_M_E_S_S_A_G_E
     for use in  the  other modules.

2.   It created client "stub"  routines  in  the  _m_s_g__c_l_n_t._c
     file.    In  this case there is only one, the _p_r_i_n_t_m_e_s_-
     _s_a_g_e__1 that was referred to from  the  _p_r_i_n_t_m_s_g  client
     program.   The name  of the output file for client stub
     routines is always formed in this way:  if the name  of
     the  input  file is _F_O_O._x, the   client  stubs   output
     file is    called _F_O_O__c_l_n_t._c.










                           - 48 -


3.   It created  the  server   program which calls _p_r_i_n_t_m_e_s_-
     _s_a_g_e__1  in  _m_s_g__p_r_o_c._c.   This  server program is named
     _m_s_g__s_v_c._c.  The rule for naming the server output  file
     is  similar   to  the previous one:  for an input  file
     called _F_O_O._x, the   output   server    file  is   named
     _F_O_O__s_v_c._c.

Now we're ready to have some fun.  First, copy the server to
a  remote  machine  and  run  it.   For  this  example,  the
machine is called "moon".  Server processes are run  in  the
background, because they never exit.

moon% msg_server &

Then on our local machine ("sun") we can print a message  on
"moon"s console.

sun% printmsg moon "Hello, moon."

The message will   get printed  to   "moon"s   console.  You
can  print   a  message on anybody's console (including your
own) with this program if you are able to copy the server to
their machine and run it.

_3.  _G_e_n_e_r_a_t_i_n_g _X_D_R _R_o_u_t_i_n_e_s

The previous example  only demonstrated  the  automatic gen-
eration of client  and server RPC  code. _r_p_c_g_e_n may also  be
used to generate  XDR  routines,  that   is,   the  routines
necessary  to  convert   local  data structures into network
format and vice-versa.  This example presents a complete RPC
service-a  remote  directory  listing  service,  which  uses
_r_p_c_g_e_n not  only  to generate stub  routines,  but  also  to
generate   the  XDR routines.  Here is the protocol descrip-
tion file:




























                           - 49 -


/*
 * dir.x: Remote directory listing protocol
 */
const MAXNAMELEN = 255;       /* maximum length of a directory entry */

typedef string nametype<MAXNAMELEN>;    /* a directory entry */

typedef struct namenode *namelist;      /* a link in the listing */

/*
 * A node in the directory listing
 */
struct namenode {
     nametype name;      /* name of directory entry */
     namelist next;      /* next entry */
};

/*
 * The result of a READDIR operation.
 */
union readdir_res switch (int errno) {
case 0:
     namelist list; /* no error: return directory listing */
default:
     void;          /* error occurred: nothing else to return */
};

/*
 * The directory program definition
 */
program DIRPROG {
     version DIRVERS {
          readdir_res
          READDIR(nametype) = 1;
     } = 1;
} = 76;

Running _r_p_c_g_e_n on _d_i_r._x creates four output files. Three are
the  same  as before: header file, client stub routines  and
server skeleton. The fourth are the XDR  routines  necessary
for  converting  the  data types we declared into XDR format
and vice-versa. These are  output in the file _d_i_r__x_d_r._c.

Here is the implementation of the "READDIR" procedure:



















                           - 50 -


/*
 * dir_proc.c: remote readdir implementation
 */
#include <rpc/rpc.h>
#include <sys/dir.h>
#include "dir.h"

extern int errno;
extern char *malloc();
extern char *strdup();

readdir_res *
readdir_1(dirname)
     nametype *dirname;
{
     DIR *dirp;
     struct direct *d;
     namelist nl;
     namelist *nlp;
     static readdir_res res; /* must be static! */

     /*
      * Open directory
      */
     dirp = opendir(*dirname);
     if (dirp == NULL) {
          res.errno = errno;
          return (&res);
     }

     /*
      * Free previous result
      */
     xdr_free(xdr_readdir_res, &res);

     /*
      * Collect directory entries
      */
     nlp = &res.readdir_res_u.list;
     while (d = readdir(dirp)) {
          nl = *nlp = (namenode *) malloc(sizeof(namenode));
          nl->name = strdup(d->d_name);
          nlp = &nl->next;
     }
     *nlp = NULL;

     /*
      * Return the result
      */
     res.errno = 0;
     closedir(dirp);
     return (&res);
}










                           - 51 -


Finally, there is  the  client  side  program  to  call  the
server:





























































                           - 52 -


/*
 * rls.c: Remote directory listing client
 */
#include <stdio.h>
#include <rpc/rpc.h>     /* always need this */
#include "dir.h"         /* need this too: will be generated by rpcgen */

extern int errno;

main(argc, argv)
     int argc;
     char *argv[];
{
     CLIENT *cl;
     char *server;
     char *dir;
     readdir_res *result;
     namelist nl;


     if (argc != 3) {
          fprintf(stderr, "usage: %s host directory\n", argv[0]);
          exit(1);
     }

     /*
      * Remember what our command line arguments refer to
      */
     server = argv[1];
     dir = argv[2];

     /*
      * Create client "handle" used for calling MESSAGEPROG on the
      * server designated on the command line. We tell the RPC package
      * to use the "tcp" protocol when contacting the server.
      */
     cl = clnt_create(server, DIRPROG, DIRVERS, "tcp");
     if (cl == NULL) {
          /*
           * Couldn't establish connection with server.
           * Print error message and die.
           */
          clnt_pcreateerror(server);
          exit(1);
     }

     /*
      * Call the remote procedure readdir on the server
      */
     result = readdir_1(&dir, cl);
     if (result == NULL) {
          /*
           * An error occurred while calling the server.
           * Print error message and die.









                           - 53 -


           */
          clnt_perror(cl, server);
          exit(1);
     }

     /*
      * Okay, we successfully called the remote procedure.
      */
     if (result->errno != 0) {
          /*
           * A remote system error occurred.
           * Print error message and die.
           */
          errno = result->errno;
          perror(dir);
          exit(1);
     }

     /*
      * Successfully got a directory listing.
      * Print it out.
      */
     for (nl = result->readdir_res_u.list; nl != NULL;
       nl = nl->next) {
          printf("%s0, nl->name);
     }
}

Compile everything, and run.

        sun%  rpcgen dir.x
        sun%  cc rls.c dir_clnt.c dir_xdr.c -o rls
        sun%  cc dir_svc.c dir_proc.c dir_xdr.c -o dir_svc

        sun%  dir_svc &

        moon%  rls sun /usr/pub
        .
        ..
        ascii
        eqnchar
        greek
        kbd
        marg8
        tabclr
        tabs
        tabs4
        moon%


A final note about _r_p_c_g_e_n: The client program and the server
procedure can be tested together as a single program by sim-
ply linking them with each other rather than with the client
and  server  stubs.  The procedure calls will be executed as









                           - 54 -


ordinary local  procedure  calls  and  the  program  can  be
debugged  with  a local debugger such as _d_b_x.  When the pro-
gram is working, the client program can  be  linked  to  the
client stub produced by _r_p_c_g_e_n and the server procedures can
be linked to the server stub produced by _r_p_c_g_e_n.

_N_O_T_E: If you do this, you may want to comment out  calls  to
RPC  library  routines,  and  have client-side routines call
server routines directly.


_4.  _T_h_e _C-_P_r_e_p_r_o_c_e_s_s_o_r

The C-preprocessor is  run on all input  files  before  they
are  compiled, so all the preprocessor  directives are legal
within a  ".x" file. Four symbols may be defined,  depending
upon  which  output  file  is getting generated. The symbols
are:

_______________________________________
 Symbol     Usage
_______________________________________
 RPC_HDR    for header-file output
 RPC_XDR    for XDR routine output
 RPC_SVC    for server-skeleton output
 RPC_CLNT   for client stub output
_______________________________________
||||||




                                      ||||||







Also, _r_p_c_g_e_n does  a little preprocessing   of its own.  Any
line  that  begins  with  a percent sign is passed  directly
into the output file,  without  any  interpretation  of  the
line.   Here  is  a  simple  example  that  demonstrates the
preprocessing features.

/*
 * time.x: Remote time protocol
 */
program TIMEPROG {
        version TIMEVERS {
                unsigned int TIMEGET(void) = 1;
        } = 1;
} = 44;

#ifdef RPC_SVC
%int *
%timeget_1()
%{
%        static int thetime;
%
%        thetime = time(0);
%        return (&thetime);
%}
#endif

The '%' feature is not generally recommended, as there is no








                           - 55 -


guarantee  that the compiler will stick the output where you
intended.

_5.  _R_P_C _L_a_n_g_u_a_g_e

RPC language is an extension of XDR   language.    The  sole
extension  is  the addition of the _p_r_o_g_r_a_m type.  For a com-
plete description of the XDR language syntax, see the eXter-
nal  Data  Representation  Standard:  Protocol Specification
chapter.  For a description of the RPC extensions to the XDR
language,  see the Remote Procedure Calls: Protocol Specifi-
cation chapter.

However, XDR language is so close to C that if you  know  C,
you  know  most of it already.  We describe here  the syntax
of the RPC language, showing a  few examples along the  way.
We  also  show how  the various RPC and XDR type definitions
get  compiled into C  type definitions in the output  header
file.

_5._1.  _D_e_f_i_n_i_t_i_o_n_s

An RPC language file consists of a series of definitions.

    definition-list:
        definition ";"
        definition ";" definition-list

It recognizes five types of definitions.

    definition:
        enum-definition
        struct-definition
        union-definition
        typedef-definition
        const-definition
        program-definition


_5._2.  _S_t_r_u_c_t_u_r_e_s

An XDR struct  is declared almost exactly like  its C  coun-
terpart.  It looks like the following:

    struct-definition:
        "struct" struct-ident "{"
            declaration-list
        "}"

    declaration-list:
        declaration ";"
        declaration ";" declaration-list

As  an example, here is an  XDR structure to define  a  two-









                           - 56 -


dimensional  coordinate,  and the C structure  that it  gets
compiled into  in the output header file.

           struct coord {             struct coord {
                int x;       -->           int x;
                int y;                     int y;
           };                         };
                                      typedef struct coord coord;

The output is identical to the  input, except  for the added
_t_y_p_e_d_e_f  at  the end of  the output. This allows  one to use
"coord" instead  of "struct coord" when declaring items.

_5._3.  _U_n_i_o_n_s

DR unions are discriminated unions, and look quite different
from  C  unions.  They are more analogous to  Pascal variant
records than they are to C unions.

    union-definition:
        "union" union-ident "switch" "(" declaration ")" "{"
            case-list
        "}"

    case-list:
        "case" value ":" declaration ";"
        "default" ":" declaration ";"
        "case" value ":" declaration ";" case-list

Here is an example of a type that might be returned  as  the
result  of  a "read data" operation.  If there is no  error,
return a block of data.  Otherwise, don't return anything.

    union read_result switch (int errno) {
    case 0:
        opaque data[1024];
    default:
        void;
    };

It gets compiled into the following:

    struct read_result {
        int errno;
        union {
            char data[1024];
        } read_result_u;
    };
    typedef struct read_result read_result;

Notice that the union component of the  output  struct   has
the name as the type name, except for the trailing "_u".











                           - 57 -


_5._4.  _E_n_u_m_e_r_a_t_i_o_n_s

DR enumerations have the same syntax as C enumerations.

    enum-definition:
        "enum" enum-ident "{"
            enum-value-list
        "}"

    enum-value-list:
        enum-value
        enum-value "," enum-value-list

    enum-value:
        enum-value-ident
        enum-value-ident "=" value

Here is a short example of  an XDR enum,   and  the  C  enum
that  it gets compiled into.

     enum colortype {      enum colortype {
          RED = 0,              RED = 0,
          GREEN = 1,   -->      GREEN = 1,
          BLUE = 2              BLUE = 2,
     };                    };
                           typedef enum colortype colortype;


_5._5.  _T_y_p_e_d_e_f

DR typedefs have the same syntax as C typedefs.

    typedef-definition:
        "typedef" declaration

Here  is an example  that defines  a  _f_n_a_m_e__t_y_p_e  used   for
declaring  file  name  strings that have a maximum length of
255 characters.

    typedef string fname_type<255>; --> typedef char *fname_type;


_5._6.  _C_o_n_s_t_a_n_t_s

DR constants  symbolic constants  that may be  used wherever
a  integer  constant  is  used,  for  example, in array size
specifications.

    const-definition:
        "const" const-ident "=" integer

For example, the following defines a constant _D_O_Z_E_N equal to
12.










                           - 58 -


    const DOZEN = 12;  -->  #define DOZEN 12


_5._7.  _P_r_o_g_r_a_m_s

RPC programs are declared using the following syntax:

    program-definition:
        "program" program-ident "{"
            version-list
        "}" "=" value

    version-list:
        version ";"
        version ";" version-list

    version:
        "version" version-ident "{"
            procedure-list
        "}" "=" value

    procedure-list:
        procedure ";"
        procedure ";" procedure-list

    procedure:
        type-ident procedure-ident "(" type-ident ")" "=" value

For example, here is the time protocol, revisited:

/*
 * time.x: Get or set the time. Time is represented as number of seconds
 * since 0:00, January 1, 1970.
 */
program TIMEPROG {
    version TIMEVERS {
        unsigned int TIMEGET(void) = 1;
        void TIMESET(unsigned) = 2;
    } = 1;
} = 44;

This file compiles into #defines in the output header file:

#define TIMEPROG 44
#define TIMEVERS 1
#define TIMEGET 1
#define TIMESET 2


_5._8.  _D_e_c_l_a_r_a_t_i_o_n_s

In XDR, there are only four kinds of declarations.











                           - 59 -


    declaration:
        simple-declaration
        fixed-array-declaration
        variable-array-declaration
        pointer-declaration

1) Simple declarations are just like simple C declarations.

    simple-declaration:
        type-ident variable-ident

Example:

    colortype color;    --> colortype color;

2) Fixed-length Array Declarations are  just  like  C  array
declarations:

    fixed-array-declaration:
        type-ident variable-ident "[" value "]"

Example:

    colortype palette[8];    --> colortype palette[8];

3) Variable-Length Array Declarations have no explicit  syn-
tax in C, so XDR invents its own using angle-brackets.

variable-array-declaration:
    type-ident variable-ident "<" value ">"
    type-ident variable-ident "<" ">"

The maximum size is specified between  the  angle  brackets.
The size may be omitted, indicating that the array may be of
any size.

    int heights<12>;    /* at most 12 items */
    int widths<>;       /* any number of items */

Since  variable-length  arrays have no  explicit  syntax  in
C,    these   declarations   are   actually   compiled  into
"struct"s.  For example,   the  "heights"  declaration  gets
compiled into the following struct:

    struct {
        u_int heights_len;  /* # of items in array */
        int *heights_val;   /* pointer to array */
    } heights;

Note  that the number  of items in  the array is  stored  in
the  "_len"  component   and the  pointer  to   the array is
stored  in  the "_val" component. The first part of each  of
these  component's  names  is  the  same  as the name of the
declared XDR variable.









                           - 60 -


4) Pointer Declarations are made in DR  exactly as they  are
in  C.   You   can't  really send pointers over the network,
but  you  can use XDR pointers for  sending  recursive  data
types  such as lists and trees.  The type is actually called
"optional-data", not "pointer", in XDR language.

    pointer-declaration:
        type-ident "*" variable-ident

Example:

    listitem *next;  -->  listitem *next;


_5._9.  _S_p_e_c_i_a_l _C_a_s_e_s

There are a few exceptions to the rules described above.

_B_o_o_l_e_a_n_s: C has no built-in boolean type. However,  the  RPC
library  does   a  boolean  type    called  _b_o_o_l__t that   is
either _T_R_U_E or _F_A_L_S_E.  Things declared as  type _b_o_o_l in  XDR
language   are   compiled   into _b_o_o_l__t in the output header
file.

Example:

    bool married;  -->  bool_t married;

_S_t_r_i_n_g_s: C has  no built-in string  type, but  instead  uses
the  null-terminated "char *" convention.  In XDR  language,
strings are declared using the "string" keyword,  and   com-
piled  into "char  *"s in the  output header file. The  max-
imum size contained  in the  angle  brackets  specifies  the
maximum  number  of  characters allowed in the  strings (not
counting the _N_U_L_L character). The maximum size may  be  left
off, indicating a string of arbitrary length.

Examples:

    string name<32>;    -->  char *name;
    string longname<>;  -->  char *longname;

_O_p_a_q_u_e  _D_a_t_a: Opaque data is used in RPC and XDR to describe
untyped  data, that is, just  sequences of arbitrary  bytes.
It may be  declared  either as a fixed  or  variable  length
array.

Examples:
    opaque diskblock[512];  -->  char diskblock[512];

    opaque filedata<1024>;  -->  struct {
                                    u_int filedata_len;
                                    char *filedata_val;
                                 } filedata;









                           - 61 -


_V_o_i_d_s: In a void declaration, the variable  is   not  named.
The  declaration  is  just  "void"  and  nothing else.  Void
declarations can only occur in two places: union definitions
and  program  definitions  (as  the  argument or result of a
remote procedure).

_e_X_t_e_r_n_a_l _D_a_t_a _R_e_p_r_e_s_e_n_t_a_t_i_o_n: _S_u_n _T_e_c_h_n_i_c_a_l _N_o_t_e_s

This chapter contains technical notes on  Sun's  implementa-
tion  of  the eXternal Data Representation (XDR) standard, a
set of  library  routines  that  allow  a  C  programmer  to
describe  arbitrary data structures in a machine-independent
fashion.  For a formal specification of  the  XDR  standard,
see  the  eXternal  Data Representation Standard.  DR is the
backbone of Sun's Remote  Procedure  Call  package,  in  the
sense  that  data  for remote procedure calls is transmitted
using the standard.  XDR library routines should be used  to
transmit  data  that  is  accessed (read or written) by more
than one type of machine.

This chapter contains a short tutorial overview of  the  XDR
library  routines,  a guide to accessing currently available
XDR streams, and information on  defining  new  streams  and
data  types.   XDR  was  designed  to  work across different
languages, operating  systems,  and  machine  architectures.
Most  users  (particularly  RPC  users)  will  need only the
information in sections 1, 2 and 3 of this  document.   Pro-
grammers  wishing  to  implement RPC and XDR on new machines
will need the information in the rest of this document,  and
especially the eXternal Data Representation Standard.

_N_O_T_E: rpcgen can be used to write XDR routines even in cases
where no RPC calls are being made.

On Sun systems, C programs that want  to  use  XDR  routines
must  include  the  file <_r_p_c/_r_p_c._h>, which contains all the
necessary interfaces to the XDR system.  Since the C library
_l_i_b_c._a contains all the XDR routines, compile as normal.

        % cc program.c










__________________________
For a compete specification of the system eXternal Data
Representation routines, see the _x_d_r(3N) manual page.










                           - 62 -


_1.  _J_u_s_t_i_f_i_c_a_t_i_o_n

Consider the following two programs, _w_r_i_t_e_r

#include <stdio.h>
main()              /* writer.c */
{
     long i;
     for (i = 0; i < 8; i++) {
          if (fwrite((char *)&i, sizeof(i), 1, stdout) != 1) {
               fprintf(stderr, "failed!\n");
               exit(1);
          }
     }
}

and _r_e_a_d_e_r

#include <stdio.h>
main()              /* reader.c */
{
     long i, j;
     for (j = 0; j < 8; j++) {
          if (fread((char *)&i, sizeof (i), 1, stdin) != 1) {
               fprintf(stderr, "failed!\n");
               exit(1);
          }
          printf("%ld ", i);
     }
     printf("\n");
}

The two programs appear to be  portable,  because  (a)  they
pass  _l_i_n_t  checking, and (b) they exhibit the same behavior
when executed on two different hardware architectures, a Sun
and a VAX.

Piping the output of the _w_r_i_t_e_r program to the  _r_e_a_d_e_r  pro-
gram gives identical results on a Sun or a VAX.

        sun% writer | reader
        0 1 2 3 4 5 6 7
        sun%

        vax% writer | reader
        0 1 2 3 4 5 6 7
        vax%

With the advent of local area networks and 4.2BSD  came  the
concept  of  ``network  pipes'' - a process produces data on
one machine, and a second process consumes data  on  another
machine.   A network pipe can be constructed with _w_r_i_t_e_r and









                           - 63 -


_r_e_a_d_e_r.  Here are the results if the first produces data  on
a Sun, and the second consumes data on a VAX.

        sun% writer | rsh vax reader
        0 16777216 33554432 50331648 67108864 83886080 100663296
        117440512
        sun%

Identical results can be obtained by executing _w_r_i_t_e_r on the
VAX  and _r_e_a_d_e_r on the Sun.  These results occur because the
byte ordering of long integers differs between the  VAX  and
the  Sun,  even  though  word  size  is the same.  Note that
$16777216$ is $2 sup 24$ - when four bytes are reversed, the
1 winds up in the 24th bit.

Whenever data is shared by two or more machine types,  there
is  a  need  for  portable data.  Programs can be made data-
portable by replacing the _r_e_a_d and _w_r_i_t_e calls with calls to
an  XDR  library  routine  _x_d_r__l_o_n_g  a filter that knows the
standard representation of a long integer  in  its  external
form.  Here are the revised versions of _w_r_i_t_e_r:

#include <stdio.h>
#include <rpc/rpc.h>     /* xdr is a sub-library of rpc */
main()         /* writer.c */
{
     XDR xdrs;
     long i;
     xdrstdio_create(&xdrs, stdout, XDR_ENCODE);
     for (i = 0; i < 8; i++) {
          if (!xdr_long(&xdrs, &i)) {
               fprintf(stderr, "failed!\n");
               exit(1);
          }
     }
}

and _r_e_a_d_e_r:
























                           - 64 -


#include <stdio.h>
#include <rpc/rpc.h>     /* xdr is a sub-library of rpc */
main()         /* reader.c */
{
     XDR xdrs;
     long i, j;
     xdrstdio_create(&xdrs, stdin, XDR_DECODE);
     for (j = 0; j < 8; j++) {
          if (!xdr_long(&xdrs, &i)) {
               fprintf(stderr, "failed!\n");
               exit(1);
          }
          printf("%ld ", i);
     }
     printf("\n");
}

The new programs were executed on a Sun, on a VAX, and  from
a Sun to a VAX; the results are shown below.

        sun% writer | reader
        0 1 2 3 4 5 6 7
        sun%

        vax% writer | reader
        0 1 2 3 4 5 6 7
        vax%

        sun% writer | rsh vax reader
        0 1 2 3 4 5 6 7
        sun%


_N_O_T_E: _I_n_t_e_g_e_r_s _a_r_e _j_u_s_t _t_h_e _t_i_p _o_f  _t_h_e  _p_o_r_t_a_b_l_e-_d_a_t_a  _i_c_e_-
_b_e_r_g.   _A_r_b_i_t_r_a_r_y  _d_a_t_a _s_t_r_u_c_t_u_r_e_s _p_r_e_s_e_n_t _p_o_r_t_a_b_i_l_i_t_y _p_r_o_b_-
_l_e_m_s, _p_a_r_t_i_c_u_l_a_r_l_y _w_i_t_h _r_e_s_p_e_c_t _t_o _a_l_i_g_n_m_e_n_t  _a_n_d  _p_o_i_n_t_e_r_s.
_A_l_i_g_n_m_e_n_t  _o_n _w_o_r_d _b_o_u_n_d_a_r_i_e_s _m_a_y _c_a_u_s_e _t_h_e _s_i_z_e _o_f _a _s_t_r_u_c_-
_t_u_r_e _t_o _v_a_r_y _f_r_o_m _m_a_c_h_i_n_e _t_o _m_a_c_h_i_n_e.  _A_n_d  _p_o_i_n_t_e_r_s,  _w_h_i_c_h
_a_r_e  _v_e_r_y  _c_o_n_v_e_n_i_e_n_t  _t_o  _u_s_e,  _h_a_v_e _n_o _m_e_a_n_i_n_g _o_u_t_s_i_d_e _t_h_e
_m_a_c_h_i_n_e _w_h_e_r_e _t_h_e_y _a_r_e _d_e_f_i_n_e_d.


_2.  _A _C_a_n_o_n_i_c_a_l _S_t_a_n_d_a_r_d

DR's  approach  to  standardizing  data  representations  is
_c_a_n_o_n_i_c_a_l.   That  is,  XDR defines a single byte order (Big
Endian), a single floating-point representation (IEEE),  and
so  on.   Any  program running on any machine can use XDR to
create portable data by translating its local representation
to  the XDR standard representations; similarly, any program
running on any machine can read portable data by translating
the  DR  standard  representaions  to its local equivalents.
The  single  standard  completely  decouples  programs  that









                           - 65 -


create  or send portable data from those that use or receive
portable data.  The  advent  of  a  new  machine  or  a  new
language  has  no effect opn the community of existing port-
able data creators and users.  A new machine joins this com-
munity  be  being  ``taught''  how  to  convert the standard
representations and its  local  representations;  the  local
representations  of  other  machines  are  irrelevant.  Con-
versely, to existing programs running on other machines, the
local   representations   of   the   new  machine  are  also
irrelevant; such programs can immediately read portable data
produced  by  the  new machine because such data conforms to
the canonical standards that they already understand.

There are strong precedents for  XDR's  canonical  approach.
For example, TCP/IP, UDP/IP, XNS, Ethernet, and, indeed, all
protocols below layer five of the ISO model,  are  canonical
protocols.   The advantage of any canonical approach is sim-
plicity; in the case of XDR, a single set of conversion rou-
tines  is  written  once  and  is  never touched again.  The
canonical approach has a disadvantage, but it is unimportant
in  real-world  data  transfer  applications.   Suppose  two
Little-Endian machines are transferring  integers  according
to  the  XDR  standard.   The  sending  machine converts the
integers from Little-Endian byte order to  XDR  (Big-Endian)
byte  order;  the  receiving  machine  performs  the reverse
conversion.  Because both machines  observe  the  same  byte
order,  their  conversions are unnecessary.  The point, how-
ever, is not necessity, but cost as compared to the alterna-
tive.

The time spent converting to and from a canonical  represen-
tation  is  insignificant, especially in networking applica-
tions.  Most of the time required to prepare a  data  struc-
ture for transfer is not spent in conversion but in travers-
ing the elements of the data structure.  To transmit a tree,
for example, each leaf must be visited and each element in a
leaf record must be copied to a buffer  and  aligned  there;
storage  for  the  leaf  may have to be deallocated as well.
Similarly, to receive a tree, storage must be allocated  for
each  leaf,  data  must be moved from the buffer to the leaf
and properly aligned, and pointers must  be  constructed  to
link  the  leaves  together.  Every machine pays the cost of
traversing  and  copying  data  structures  whether  or  not
conversion is required.  In networking applications, commun-
ications overhead-the time required to move  the  data  down
through the sender's protocol layers, across the network and
up through the receiver's protocol layers-dwarfs  conversion
overhead.

_3.  _T_h_e _X_D_R _L_i_b_r_a_r_y

The XDR library not only solves data  portability  problems,
it  also allows you to write and read arbitrary C constructs
in a consistent, specified, well-documented  manner.   Thus,









                           - 66 -


it  can  make sense to use the library even when the data is
not shared among machines on a network.

The XDR library  has  filter  routines  for  strings  (null-
terminated arrays of bytes), structures, unions, and arrays,
to name a few.  Using more primitive routines, you can write
your  own  specific  XDR routines to describe arbitrary data
structures, including elements of arrays, arms of unions, or
objects  pointed  at  from other structures.  The structures
themselves may contain  arrays  of  arbitrary  elements,  or
pointers to other structures.

Let's examine the two programs more  closely.   There  is  a
family  of XDR stream creation routines in which each member
treats the stream of bits differently.  In our example, data
is  manipulated  using  standard  I/O  routines,  so  we use
_x_d_r_s_t_d_i_o__c_r_e_a_t_e.  The parameters to XDR stream creation rou-
tines  vary  according  to  their function.  In our example,
_x_d_r_s_t_d_i_o__c_r_e_a_t_e takes a pointer to an XDR structure that  it
initializes, a pointer to a _F_I_L_E that the input or output is
performed on, and  the  operation.   The  operation  may  be
_X_D_R__E_N_C_O_D_E   for  serializing  in  the  _w_r_i_t_e_r  program,  or
_X_D_R__D_E_C_O_D_E for deserializing in the _r_e_a_d_e_r program.

Note: RPC users never need to create XDR  streams;  the  RPC
system  itself  creates these streams, which are then passed
to the users.

The _x_d_r__l_o_n_g primitive is characteristic of most XDR library
primitives  and all client XDR routines.  First, the routine
returns _F_A_L_S_E (0) if it fails, and _T_R_U_E (1) if it  succeeds.
Second,  for each data type, _x_x_x, there is an associated XDR
routine of the form:

        xdr_xxx(xdrs, xp)
             XDR *xdrs;
             xxx *xp;
        {
        }

In our case, _x_x_x is long, and the corresponding XDR  routine
is  a  primitive,  _x_d_r__l_o_n_g  The client could also define an
arbitrary structure _x_x_x in which case the client would  also
supply the routine _x_d_r__x_x_x, describing each field by calling
XDR routines of the appropriate  type.   In  all  cases  the
first  parameter,  _x_d_r_s  can be treated as an opaque handle,
and passed to the primitive routines.

DR routines are direction independent;  that  is,  the  same
routines  are called to serialize or deserialize data.  This
feature is critical  to  software  engineering  of  portable
data.   The  idea  is  to  call  the same routine for either
operation - this almost guarantees that serialized data  can
also  be deserialized.  One routine is used by both producer









                           - 67 -


and consumer of networked  data.   This  is  implemented  by
always  passing  the  address  of  an object rather than the
object itself - only in the case of deserialization  is  the
object  modified.   This feature is not shown in our trivial
example, but its value becomes obvious when nontrivial  data
structures  are  passed among machines.  If needed, the user
can obtain the direction of the XDR operation.  See the  XDR
Operation Directions section of this chapter for details.

Let's look at a slightly more complicated  example.   Assume
that  a  person's  gross  assets  and  liabilities are to be
exchanged among processes.  Also assume  that  these  values
are important enough to warrant their own data type:

struct gnumbers {
     long g_assets;
     long g_liabilities;
};

The corresponding  XDR  routine  describing  this  structure
would be:

bool_t         /* TRUE is success, FALSE is failure */
xdr_gnumbers(xdrs, gp)
     XDR *xdrs;
     struct gnumbers *gp;
{
     if (xdr_long(xdrs, &gp->g_assets) &&
         xdr_long(xdrs, &gp->g_liabilities))
          return(TRUE);
     return(FALSE);
}

Note that the parameter _x_d_r_s is never inspected or modified;
it  is  only  passed on to the subcomponent routines.  It is
imperative to inspect the return value of each  XDR  routine
call,  and  to  give  up immediately and return _F_A_L_S_E if the
subroutine fails.

This example also shows that the type _b_o_o_l__t is declared  as
an  integer  whose  only  values are _T_R_U_E (1) and _F_A_L_S_E (0).
This document uses the following definitions:

#define bool_t int
#define TRUE   1
#define FALSE  0
#define enum_t int  /* enum_t used for generic enums */


Keeping these  conventions  in  mind,  _x_d_r__g_n_u_m_b_e_r_s  can  be
rewritten as follows:











                           - 68 -


xdr_gnumbers(xdrs, gp)
     XDR *xdrs;
     struct gnumbers *gp;
{
     return(xdr_long(xdrs, &gp->g_assets) &&
          xdr_long(xdrs, &gp->g_liabilities));
}

This document uses both coding styles.

_4.  _X_D_R _L_i_b_r_a_r_y _P_r_i_m_i_t_i_v_e_s

This section gives a synopsis of  each  XDR  primitive.   It
starts  with  basic  data  types and moves on to constructed
data types.  Finally,  XDR  utilities  are  discussed.   The
interface  to  these  primitives and utilities is defined in
the include  file  <_r_p_c/_x_d_r._h>,  automatically  included  by
<_r_p_c/_r_p_c._h>.

_4._1.  _N_u_m_b_e_r _F_i_l_t_e_r_s

The XDR library provides  primitives  to  translate  between
numbers  and  their  corresponding external representations.
Primitives cover the set of numbers in:

             [_s_i_g_n_e_d,_u_n_s_i_g_n_e_d]_*[_s_h_o_r_t,_i_n_t,_l_o_n_g]

Specifically, the eight primitives are:



































                           - 69 -


        bool_t xdr_char(xdrs, cp)
             XDR *xdrs;
             char *cp;
        bool_t xdr_u_char(xdrs, ucp)
             XDR *xdrs;
             unsigned char *ucp;
        bool_t xdr_int(xdrs, ip)
             XDR *xdrs;
             int *ip;
        bool_t xdr_u_int(xdrs, up)
             XDR *xdrs;
             unsigned *up;
        bool_t xdr_long(xdrs, lip)
             XDR *xdrs;
             long *lip;
        bool_t xdr_u_long(xdrs, lup)
             XDR *xdrs;
             u_long *lup;
        bool_t xdr_short(xdrs, sip)
             XDR *xdrs;
             short *sip;
        bool_t xdr_u_short(xdrs, sup)
             XDR *xdrs;
             u_short *sup;

The first parameter, _x_d_r_s, is an  XDR  stream  handle.   The
second  parameter is the address of the number that provides
data to the stream or receives data from it.   All  routines
return  _T_R_U_E if they complete successfully, and _F_A_L_S_E other-
wise.

_4._2.  _F_l_o_a_t_i_n_g _P_o_i_n_t _F_i_l_t_e_r_s

The XDR library also provides  primitive  routines  for  C's
floating point types:

        bool_t xdr_float(xdrs, fp)
             XDR *xdrs;
             float *fp;
        bool_t xdr_double(xdrs, dp)
             XDR *xdrs;
             double *dp;

The first parameter, _x_d_r_s is  an  XDR  stream  handle.   The
second parameter is the address of the floating point number
that provides data to the stream or receives data  from  it.
All  routines return _T_R_U_E if they complete successfully, and
_F_A_L_S_E otherwise.

Note: Since the numbers are  represented  in  IEEE  floating









                           - 70 -


point,   routines  may  fail  when  decoding  a  valid  IEEE
representation into a  machine-specific  representation,  or
vice-versa.

_4._3.  _E_n_u_m_e_r_a_t_i_o_n _F_i_l_t_e_r_s

The XDR library provides a primitive  for  generic  enumera-
tions.   The  primitive  assumes  that a C _e_n_u_m has the same
representation inside the  machine  as  a  C  integer.   The
boolean  type  is  an  important  instance of the _e_n_u_m.  The
external representation of a boolean is always _T_R_U_E  (1)  or
_F_A_L_S_E (0).

        #define bool_t int
        #define FALSE  0
        #define TRUE   1
        #define enum_t int
        bool_t xdr_enum(xdrs, ep)
             XDR *xdrs;
             enum_t *ep;
        bool_t xdr_bool(xdrs, bp)
             XDR *xdrs;
             bool_t *bp;

The second parameters _e_p and _b_p are addresses of the associ-
ated  type that provides data to, or receives data from, the
stream _x_d_r_s The routine returns _F_A_L_S_E if the number of char-
acters exceeds _m_a_x_l_e_n_g_t_h, and _T_R_U_E if it doesn't.

_4._4.  _N_o _D_a_t_a

Occasionally, an XDR routine must be  supplied  to  the  RPC
system,  even  when  no  data  is  passed  or required.  The
library provides such a routine:

        bool_t xdr_void();  /* always returns TRUE */


_4._5.  _C_o_n_s_t_r_u_c_t_e_d _D_a_t_a _T_y_p_e _F_i_l_t_e_r_s

Constructed or compound data type  primitives  require  more
parameters  and  perform more complicated functions then the
primitives discussed above.  This  section  includes  primi-
tives  for  strings,  arrays, unions, and pointers to struc-
tures.

Constructed data type primitives may use memory  management.
In  many  cases, memory is allocated when deserializing data
with _X_D_R__D_E_C_O_D_E Therefore,  the  XDR  package  must  provide
means  to  deallocate memory.  This is done by an XDR opera-
tion, _X_D_R__F_R_E_E To review, the three XDR  directional  opera-
tions are _X_D_R__E_N_C_O_D_E, _X_D_R__D_E_C_O_D_E and _X_D_R__F_R_E_E.









                           - 71 -


_4._5._1.  _S_t_r_i_n_g_s

In C, a string is defined as a sequence of bytes  terminated
by  a  null  byte,  which is not considered when calculating
string length.  However, when a string is passed or  manipu-
lated,  a  pointer  to  it  is employed.  Therefore, the XDR
library defines a string to be a _c_h_a_r and not a sequence  of
characters.   The  external  representation  of  a string is
drastically  different  from  its  internal  representation.
Externally,  strings  are  represented as sequences of ASCII
characters, while  internally,  they  are  represented  with
character  pointers.  Conversion between the two representa-
tions is accomplished with the routine _x_d_r__s_t_r_i_n_g.

        bool_t xdr_string(xdrs, sp, maxlength)
             XDR *xdrs;
             char **sp;
             u_int maxlength;

The first parameter _x_d_r_s is  the  XDR  stream  handle.   The
second  parameter _s_p is a pointer to a string (type _c_h_a_r The
third parameter _m_a_x_l_e_n_g_t_h specifies the  maximum  number  of
bytes allowed during encoding or decoding; its value is usu-
ally specified by  a  protocol.   For  example,  a  protocol
specification may say that a file name may be no longer than
255 characters.  The routine returns _F_A_L_S_E if the number  of
characters exceeds _m_a_x_l_e_n_g_t_h, and _T_R_U_E if it doesn't.

The behavior of _x_d_r__s_t_r_i_n_g is similar  to  the  behavior  of
other  routines  discussed  in  this section.  The direction
_X_D_R__E_N_C_O_D_E is  easiest  to  understand.   The  parameter  _s_p
points  to  a string of a certain length; if the string does
not exceed _m_a_x_l_e_n_g_t_h, the bytes are serialized.

The effect of deserializing a string is subtle.   First  the
length  of  the  incoming  string is determined; it must not
exceed _m_a_x_l_e_n_g_t_h.  Next _s_p is dereferenced; if the the value
is  _N_U_L_L,  then  a string of the appropriate length is allo-
cated and *_s_p is set to this string.  If the original  value
of *_s_p is non-null, then the XDR package assumes that a tar-
get area has been  allocated,  which  can  hold  strings  no
longer  than  _m_a_x_l_e_n_g_t_h.   In  either  case,  the  string is
decoded into the target area.  The routine  then  appends  a
null character to the string.

In the _X_D_R__F_R_E_E operation, the string is obtained  by  dere-
ferencing  _s_p.   If  the string is not _N_U_L_L, it is freed and
*_s_p is set to _N_U_L_L.  In this operation,  _x_d_r__s_t_r_i_n_g  ignores
the _m_a_x_l_e_n_g_t_h parameter.

_4._5._2.  _B_y_t_e _A_r_r_a_y_s

Often variable-length arrays  of  bytes  are  preferable  to
strings.   Byte  arrays differ from strings in the following









                           - 72 -


three ways: 1) the length of the array (the byte  count)  is
explicitly  located  in  an  unsigned  integer,  2) the byte
sequence is not terminated by a null character, and  3)  the
external  representation  of  the bytes is the same as their
internal representation.  The primitive  _x_d_r__b_y_t_e_s  converts
between  the  internal  and external representations of byte
arrays:

        bool_t xdr_bytes(xdrs, bpp, lp, maxlength)
            XDR *xdrs;
            char **bpp;
            u_int *lp;
            u_int maxlength;

The usage of the first, second  and  fourth  parameters  are
identical  to  the  first,  second  and  third parameters of
_x_d_r__s_t_r_i_n_g, respectively.  The length of the  byte  area  is
obtained by dereferencing _l_p when serializing; *_l_p is set to
the byte length when deserializing.

_4._5._3.  _A_r_r_a_y_s

The XDR library package provides a  primitive  for  handling
arrays  of arbitrary elements.  The _x_d_r__b_y_t_e_s routine treats
a subset of generic arrays, in which the size of array  ele-
ments is known to be 1, and the external description of each
element is built-in.  The generic array primitive, _x_d_r__a_r_r_a_y
requires parameters identical to those of _x_d_r__b_y_t_e_s plus two
more: the size of array elements, and an XDR routine to han-
dle  each of the elements.  This routine is called to encode
or decode each element of the array.

        bool_t
        xdr_array(xdrs, ap, lp, maxlength, elementsiz, xdr_element)
            XDR *xdrs;
            char **ap;
            u_int *lp;
            u_int maxlength;
            u_int elementsiz;
            bool_t (*xdr_element)();

The parameter _a_p is the address of the pointer to the array.
If  *_a_p  is  _N_U_L_L  when  the array is being deserialized, DR
allocates an array of the appropriate size and sets  *_a_p  to
that array.  The element count of the array is obtained from
*_l_p when the array is serialized; *_l_p is set  to  the  array
length  when  the  array is deserialized. The parameter _m_a_x_-
_l_e_n_g_t_h is the maximum number of elements that the  array  is
allowed to have; _e_l_e_m_e_n_t_s_i_z is the byte size of each element
of the array (the C function _s_i_z_e_o_f can be  used  to  obtain
this  value).   The routine _x_d_r__e_l_e_m_e_n_t is called to serial-
ize, deserialize, or free each element of the array.

Before  defining  more  constructed  data   types,   it   is









                           - 73 -


appropriate to present three examples.

_E_x_a_m_p_l_e _A:
A user on a networked machine can be identified by  (a)  the
machine name, such as _k_r_y_p_t_o_n: see the _g_e_t_h_o_s_t_n_a_m_e man page;
(b) the user's UID: see the _g_e_t_e_u_i_d man page;  and  (c)  the
group  numbers  to which the user belongs: see the _g_e_t_g_r_o_u_p_s
man page.  A structure with this information and its associ-
ated DR routine could be coded like this:

struct netuser {
    char    *nu_machinename;
    int     nu_uid;
    u_int   nu_glen;
    int     *nu_gids;
};
#define NLEN 255    /* machine names < 256 chars */
#define NGRPS 20    /* user can't be in > 20 groups */
bool_t
xdr_netuser(xdrs, nup)
    XDR *xdrs;
    struct netuser *nup;
{
    return(xdr_string(xdrs, &nup->nu_machinename, NLEN) &&
        xdr_int(xdrs, &nup->nu_uid) &&
        xdr_array(xdrs, &nup->nu_gids, &nup->nu_glen,
        NGRPS, sizeof (int), xdr_int));
}


_E_x_a_m_p_l_e _B:
A party of network users could be implemented as an array of
_n_e_t_u_s_e_r  structure.   The declaration and its associated XDR
routines are as follows:

struct party {
    u_int p_len;
    struct netuser *p_nusers;
};
#define PLEN 500    /* max number of users in a party */
bool_t
xdr_party(xdrs, pp)
    XDR *xdrs;
    struct party *pp;
{
    return(xdr_array(xdrs, &pp->p_nusers, &pp->p_len, PLEN,
        sizeof (struct netuser), xdr_netuser));
}


_E_x_a_m_p_l_e _C:
The well-known parameters to _m_a_i_n, _a_r_g_c and _a_r_g_v can be com-
bined  into  a  structure.  An array of these structures can









                           - 74 -


make up a history of commands.   The  declarations  and  XDR
routines might look like:

struct cmd {
    u_int c_argc;
    char **c_argv;
};
#define ALEN 1000   /* args cannot be > 1000 chars */
#define NARGC 100   /* commands cannot have > 100 args */

struct history {
    u_int h_len;
    struct cmd *h_cmds;
};
#define NCMDS 75    /* history is no more than 75 commands */

bool_t
xdr_wrap_string(xdrs, sp)
    XDR *xdrs;
    char **sp;
{
    return(xdr_string(xdrs, sp, ALEN));
}


bool_t
xdr_cmd(xdrs, cp)
    XDR *xdrs;
    struct cmd *cp;
{
    return(xdr_array(xdrs, &cp->c_argv, &cp->c_argc, NARGC,
        sizeof (char *), xdr_wrap_string));
}


bool_t
xdr_history(xdrs, hp)
    XDR *xdrs;
    struct history *hp;
{
    return(xdr_array(xdrs, &hp->h_cmds, &hp->h_len, NCMDS,
        sizeof (struct cmd), xdr_cmd));
}

The most confusing part of this example is that the  routine
_x_d_r__w_r_a_p__s_t_r_i_n_g is needed to package the _x_d_r__s_t_r_i_n_g routine,
because the implementation  of  _x_d_r__a_r_r_a_y  only  passes  two
parameters   to   the  array  element  description  routine;
_x_d_r__w_r_a_p__s_t_r_i_n_g supplies the third parameter to _x_d_r__s_t_r_i_n_g.

By now the recursive nature of the  XDR  library  should  be
obvious.  Let's continue with more constructed data types.











                           - 75 -


_4._5._4.  _O_p_a_q_u_e _D_a_t_a

In some protocols, handles  are  passed  from  a  server  to
client.   The client passes the handle back to the server at
some later time.  Handles are never  inspected  by  clients;
they  are  obtained  and submitted.  That is to say, handles
are opaque.  The primitive _x_d_r__o_p_a_q_u_e is used for describing
fixed sized, opaque bytes.

        bool_t xdr_opaque(xdrs, p, len)
            XDR *xdrs;
            char *p;
            u_int len;

The parameter _p is the location of the  bytes;  _l_e_n  is  the
number  of  bytes  in the opaque object.  By definition, the
actual data contained in the opaque object are  not  machine
portable.

_4._5._5.  _F_i_x_e_d _S_i_z_e_d _A_r_r_a_y_s

The  XDR  library  provides  a  primitive,  _x_d_r__v_e_c_t_o_r,  for
fixed-length arrays.

#define NLEN 255    /* machine names must be < 256 chars */
#define NGRPS 20    /* user belongs to exactly 20 groups */
struct netuser {
    char *nu_machinename;
    int nu_uid;
    int nu_gids[NGRPS];
};
bool_t
xdr_netuser(xdrs, nup)
    XDR *xdrs;
    struct netuser *nup;
{
    int i;
    if (!xdr_string(xdrs, &nup->nu_machinename, NLEN))
        return(FALSE);
    if (!xdr_int(xdrs, &nup->nu_uid))
        return(FALSE);
    if (!xdr_vector(xdrs, nup->nu_gids, NGRPS, sizeof(int),
        xdr_int)) {
            return(FALSE);
    }
    return(TRUE);
}














                           - 76 -


_4._5._6.  _D_i_s_c_r_i_m_i_n_a_t_e_d _U_n_i_o_n_s

The XDR library supports discriminated unions.   A  discrim-
inated  union  is a C union and an _e_n_u_m__t value that selects
an ``arm'' of the union.

        struct xdr_discrim {
            enum_t value;
            bool_t (*proc)();
        };
        bool_t xdr_union(xdrs, dscmp, unp, arms, defaultarm)
            XDR *xdrs;
            enum_t *dscmp;
            char *unp;
            struct xdr_discrim *arms;
            bool_t (*defaultarm)();  /* may equal NULL */

First the routine translates the discriminant of  the  union
located  at  *_d_s_c_m_p.   The  discriminant is always an _e_n_u_m__t
Next the union located at *_u_n_p is translated.  The parameter
_a_r_m_s  is  a  pointer  to an array of _x_d_r__d_i_s_c_r_i_m structures.
Each structure contains an order pair of  [_v_a_l_u_e,_p_r_o_c].   If
the  union's  discriminant  is equal to the associated _v_a_l_u_e
then the _p_r_o_c is called to translate the union.  The end  of
the  _x_d_r__d_i_s_c_r_i_m  structure array is denoted by a routine of
value _N_U_L_L (0).  If the discriminant is  not  found  in  the
_a_r_m_s array, then the _d_e_f_a_u_l_t_a_r_m procedure is called if it is
non-null; otherwise the routine returns _F_A_L_S_E.

_E_x_a_m_p_l_e _D: Suppose the type of a union may be integer, char-
acter  pointer  (a  string), or a _g_n_u_m_b_e_r_s structure.  Also,
assume the union and its current  type  are  declared  in  a
structure.  The declaration is:

enum utype { INTEGER=1, STRING=2, GNUMBERS=3 };
struct u_tag {
    enum utype utype;   /* the union's discriminant */
    union {
        int ival;
        char *pval;
        struct gnumbers gn;
    } uval;
};

The following constructs and XDR procedure (de)serialize the
discriminated union:
















                           - 77 -


struct xdr_discrim u_tag_arms[4] = {
    { INTEGER, xdr_int },
    { GNUMBERS, xdr_gnumbers }
    { STRING, xdr_wrap_string },
    { __dontcare__, NULL }
    /* always terminate arms with a NULL xdr_proc */
}
bool_t
xdr_u_tag(xdrs, utp)
    XDR *xdrs;
    struct u_tag *utp;
{
    return(xdr_union(xdrs, &utp->utype, &utp->uval,
        u_tag_arms, NULL));
}

The routine _x_d_r__g_n_u_m_b_e_r_s was presented above in the The  XDR
Library  section.   _x_d_r__w_r_a_p__s_t_r_i_n_g was presented in example
C.  The default _a_r_m parameter to _x_d_r__u_n_i_o_n (the last parame-
ter)  is  _N_U_L_L  in this example.  Therefore the value of the
union's discriminant may legally take on only values  listed
in  the  _u__t_a_g__a_r_m_s  array.   This example also demonstrates
that the elements of the arm's  array  do  not  need  to  be
sorted.

It is worth pointing out that the values of the discriminant
may  be  sparse, though in this example they are not.  It is
always good practice to assign explicitly integer values  to
each element of the discriminant's type.  This practice both
documents the external representation  of  the  discriminant
and  guarantees  that  different  C compilers emit identical
discriminant values.

Exercise: Implement _x_d_r__u_n_i_o_n using the other primitives  in
this section.

_4._5._7.  _P_o_i_n_t_e_r_s

In C it is often  convenient  to  put  pointers  to  another
structure  within  a structure.  The primitive _x_d_r__r_e_f_e_r_e_n_c_e
makes it easy to  serialize,  deserialize,  and  free  these
referenced structures.

        bool_t xdr_reference(xdrs, pp, size, proc)
            XDR *xdrs;
            char **pp;
            u_int ssize;
            bool_t (*proc)();


Parameter _p_p is the address of the pointer to the structure;
parameter  _s_s_i_z_e  is the size in bytes of the structure (use
the C function _s_i_z_e_o_f to obtain this value); and _p_r_o_c is the
XDR  routine  that  describes  the structure.  When decoding








                           - 78 -


data, storage is allocated if *_p_p is _N_U_L_L.

There is no need for  a  primitive  _x_d_r__s_t_r_u_c_t  to  describe
structures  within  structures,  because pointers are always
sufficient.

Exercise: Implement _x_d_r__r_e_f_e_r_e_n_c_e using _x_d_r__a_r_r_a_y.  Warning:
_x_d_r__r_e_f_e_r_e_n_c_e and _x_d_r__a_r_r_a_y are NOT interchangeable external
representations of data.

_E_x_a_m_p_l_e  _E:  Suppose  there  is  a  structure  containing  a
person's name and a pointer to a _g_n_u_m_b_e_r_s structure contain-
ing the person's gross assets  and  liabilities.   The  con-
struct is:

        struct pgn {
            char *name;
            struct gnumbers *gnp;
        };

The corresponding XDR routine for this structure is:

        bool_t
        xdr_pgn(xdrs, pp)
            XDR *xdrs;
            struct pgn *pp;
        {
            if (xdr_string(xdrs, &pp->name, NLEN) &&
              xdr_reference(xdrs, &pp->gnp,
              sizeof(struct gnumbers), xdr_gnumbers))
                return(TRUE);
            return(FALSE);
        }

_P_o_i_n_t_e_r _S_e_m_a_n_t_i_c_s _a_n_d _X_D_R

In many applications, C programmers attach double meaning to
the values of a pointer.  Typically the value _N_U_L_L (or zero)
means data is  not  needed,  yet  some  application-specific
interpretation  applies.   In  essence,  the C programmer is
encoding a discriminated union  efficiently  by  overloading
the interpretation of the value of a pointer.  For instance,
in example E a _N_U_L_L pointer value  for  _g_n_p  could  indicate
that  the person's assets and liabilities are unknown.  That
is, the pointer value encodes two things: whether or not the
data  is  known;  and if it is known, where it is located in
memory.  Linked lists are an extreme example of the  use  of
application-specific pointer interpretation.

The primitive _x_d_r__r_e_f_e_r_e_n_c_e cannot and does not  attach  any
special  meaning  to  a null-value pointer during serializa-
tion.  That is, passing an address of a pointer whose  value
is  _N_U_L_L  to  _x_d_r__r_e_f_e_r_e_n_c_e  when  serialing  data will most
likely cause a memory fault and, on the UNIX system, a  core









                           - 79 -


dump.

_x_d_r__p_o_i_n_t_e_r  correctly  handles  _N_U_L_L  pointers.   For  more
information about its use, see Linked Lists.

_E_x_e_r_c_i_s_e: After reading the section on Linked Lists,  return
here and extend example E so that it can correctly deal with
_N_U_L_L pointer values.

_E_x_e_r_c_i_s_e: Using the  _x_d_r__u_n_i_o_n  _x_d_r__r_e_f_e_r_e_n_c_e  and  _x_d_r__v_o_i_d
primitives,  implement  a generic pointer handling primitive
that implicitly deals with _N_U_L_L pointers.  That  is,  imple-
ment _x_d_r__p_o_i_n_t_e_r.

_4._6.  _N_o_n-_f_i_l_t_e_r _P_r_i_m_i_t_i_v_e_s

DR streams can be manipulated with the primitives  discussed
in this section.

        u_int xdr_getpos(xdrs)
            XDR *xdrs;
        bool_t xdr_setpos(xdrs, pos)
            XDR *xdrs;
            u_int pos;
        xdr_destroy(xdrs)
            XDR *xdrs;

The routine _x_d_r__g_e_t_p_o_s  returns  an  unsigned  integer  that
describes the current position in the data stream.  Warning:
In some XDR streams, the returned  value  of  _x_d_r__g_e_t_p_o_s  is
meaningless;  the  routine returns a -1 in this case (though
-1 should be a legitimate value).

The routine _x_d_r__s_e_t_p_o_s sets a stream position to  _p_o_s  Warn-
ing:  In some XDR streams, setting a position is impossible;
in such cases, _x_d_r__s_e_t_p_o_s will return _F_A_L_S_E.   This  routine
will  also  fail if the requested position is out-of-bounds.
The definition of bounds varies from stream to stream.

The _x_d_r__d_e_s_t_r_o_y primitive destroys the XDR stream.  Usage of
the stream after calling this routine is undefined.

_4._7.  _X_D_R _O_p_e_r_a_t_i_o_n _D_i_r_e_c_t_i_o_n_s

At times you may wish to optimize  XDR  routines  by  taking
advantage  of  the  direction  of the operation - _X_D_R__E_N_C_O_D_E
_X_D_R__D_E_C_O_D_E or _X_D_R__F_R_E_E The value _x_d_r_s->_x__o_p always  contains
the  direction  of  the  XDR operation.  Programmers are not
encouraged to take advantage of  this  information.   There-
fore,  no example is presented here.  However, an example in
Section 7 demonstrates  the  usefulness  of  the  _x_d_r_s->_x__o_p
field.










                           - 80 -


_4._8.  _X_D_R _S_t_r_e_a_m _A_c_c_e_s_s

An XDR stream is obtained by calling the  appropriate  crea-
tion  routine.   These creation routines take arguments that
are tailored to the specific properties of the stream.

Streams currently exist for (de)serialization of data to  or
from  standard I/O _F_I_L_E streams, TCP/IP connections and UNIX
files, and memory.  Section 5 documents the XDR  object  and
how to make new XDR streams when they are required.

_4._8._1.  _S_t_a_n_d_a_r_d _I/_O _S_t_r_e_a_m_s

DR streams can be  interfaced  to  standard  I/O  using  the
_x_d_r_s_t_d_i_o__c_r_e_a_t_e routine as follows:

        #include <stdio.h>
        #include <rpc/rpc.h>    /* xdr streams part of rpc */
        void
        xdrstdio_create(xdrs, fp, x_op)
            XDR *xdrs;
            FILE *fp;
            enum xdr_op x_op;

The  routine  _x_d_r_s_t_d_i_o__c_r_e_a_t_e  initializes  an  XDR   stream
pointed to by _x_d_r_s The XDR stream interfaces to the standard
I/O library.  Parameter _f_p is an open file, and _x__o_p  is  an
XDR direction.

_4._8._2.  _M_e_m_o_r_y _S_t_r_e_a_m_s

Memory streams allow the streaming of data into or out of  a
specified area of memory:

        #include <rpc/rpc.h>
        void
        xdrmem_create(xdrs, addr, len, x_op)
            XDR *xdrs;
            char *addr;
            u_int len;
            enum xdr_op x_op;

The routine _x_d_r_m_e_m__c_r_e_a_t_e initializes an XDR stream in local
memory.   The memory is pointed to by parameter _a_d_d_r parame-
ter _l_e_n is the length in bytes of the memory.   The  parame-
ters _x_d_r_s and _x__o_p are identical to the corresponding param-
eters of _x_d_r_s_t_d_i_o__c_r_e_a_t_e Currently, the  UDP/IP  implementa-
tion  of RPC uses _x_d_r_m_e_m__c_r_e_a_t_e Complete call or result mes-
sages are built in memory before calling the  _s_e_n_d_t_o  system
routine.












                           - 81 -


_4._8._3.  _R_e_c_o_r_d (_T_C_P/_I_P) _S_t_r_e_a_m_s

A record stream is an XDR stream built on top  of  a  record
marking  standard  that  is built on top of the UNIX file or
4.2 BSD connection interface.

        #include <rpc/rpc.h>    /* xdr streams part of rpc */
        xdrrec_create(xdrs,
          sendsize, recvsize, iohandle, readproc, writeproc)
            XDR *xdrs;
            u_int sendsize, recvsize;
            char *iohandle;
            int (*readproc)(), (*writeproc)();

The routine _x_d_r_r_e_c__c_r_e_a_t_e provides an XDR  stream  interface
that  allows  for a bidirectional, arbitrarily long sequence
of records.  The contents of the records  are  meant  to  be
data in XDR form.  The stream's primary use is for interfac-
ing RPC to TCP connections.  However,  it  can  be  used  to
stream data into or out of normal UNIX files.

The parameter _x_d_r_s is similar to the corresponding parameter
described  above.   The  stream  does its own data buffering
similar to that of standard I/O.   The  parameters  _s_e_n_d_s_i_z_e
and  _r_e_c_v_s_i_z_e  determine the size in bytes of the output and
input buffers, respectively; if their values are  zero  (0),
then  predetermined  defaults are used.  When a buffer needs
to be filled or flushed, the routine _r_e_a_d_p_r_o_c  or  _w_r_i_t_e_p_r_o_c
is  called,  respectively.   The usage and behavior of these
routines are similar to  the  UNIX  system  calls  _r_e_a_d  and
_w_r_i_t_e.   However,  the first parameter to each of these rou-
tines is the opaque parameter _i_o_h_a_n_d_l_e The other two parame-
ters _b_u_f and _n_b_y_t_e_s and the results (byte count) are identi-
cal to the system routines.  If _x_x_x is _r_e_a_d_p_r_o_c or _w_r_i_t_e_p_r_o_c
then it has the following form:

        /*
         * returns the actual number of bytes transferred.
         * -1 is an error
         */
        int
        xxx(iohandle, buf, len)
            char *iohandle;
            char *buf;
            int nbytes;

The XDR stream provides means for delimiting records in  the
byte  stream.   The  implementation  details  of  delimiting
records in a stream are discussed in appendix 1.  The primi-
tives that are specific to record streams are as follows:












                           - 82 -


        bool_t
        xdrrec_endofrecord(xdrs, flushnow)
            XDR *xdrs;
            bool_t flushnow;
        bool_t
        xdrrec_skiprecord(xdrs)
            XDR *xdrs;
        bool_t
        xdrrec_eof(xdrs)
            XDR *xdrs;

The routine _x_d_r_r_e_c__e_n_d_o_f_r_e_c_o_r_d causes the  current  outgoing
data to be marked as a record.  If the parameter _f_l_u_s_h_n_o_w is
_T_R_U_E, then the stream's _w_r_i_t_e_p_r_o_c will be called; otherwise,
_w_r_i_t_e_p_r_o_c  will  be  called  when the output buffer has been
filled.

The routine _x_d_r_r_e_c__s_k_i_p_r_e_c_o_r_d causes an input stream's posi-
tion  to  be moved past the current record boundary and onto
the beginning of the next record in the stream.

If there is no more data in the stream's input buffer,  then
the  routine  _x_d_r_r_e_c__e_o_f  returns  _T_R_U_E.  That is not to say
that there is no more data in the underlying  file  descrip-
tor.

_4._9.  _X_D_R _S_t_r_e_a_m _I_m_p_l_e_m_e_n_t_a_t_i_o_n

This section provides the  abstract  data  types  needed  to
implement new instances of XDR streams.

_4._9._1.  _T_h_e _X_D_R _O_b_j_e_c_t

The following structure defines  the  interface  to  an  XDR
stream:



























                           - 83 -


enum xdr_op { XDR_ENCODE=0, XDR_DECODE=1, XDR_FREE=2 };
typedef struct {
    enum xdr_op x_op;            /* operation; fast added param */
    struct xdr_ops {
        bool_t  (*x_getlong)();  /* get long from stream */
        bool_t  (*x_putlong)();  /* put long to stream */
        bool_t  (*x_getbytes)(); /* get bytes from stream */
        bool_t  (*x_putbytes)(); /* put bytes to stream */
        u_int   (*x_getpostn)(); /* return stream offset */
        bool_t  (*x_setpostn)(); /* reposition offset */
        caddr_t (*x_inline)();   /* ptr to buffered data */
        VOID    (*x_destroy)();  /* free private area */
    } *x_ops;
    caddr_t     x_public;        /* users' data */
    caddr_t     x_private;       /* pointer to private data */
    caddr_t     x_base;          /* private for position info */
    int         x_handy;         /* extra private word */
} XDR;

The _x__o_p field is the current operation being  performed  on
the  stream.  This field is important to the XDR primitives,
but should not affect a stream's implementation.  That is, a
stream's  implementation  should  not  depend on this value.
The fields _x__p_r_i_v_a_t_e _x__b_a_s_e and _x__h_a_n_d_y are private  to  the
particular  stream's  implementation.  The field _x__p_u_b_l_i_c is
for the XDR client and should  never  be  used  by  the  XDR
stream implementations or the XDR primitives.

Macros for accessing  operations _x__g_e_t_p_o_s_t_n  _x__s_e_t_p_o_s_t_n  and
_x__d_e_s_t_r_o_y  were  defined  in  Section  3.6.   The  operation
_x__i_n_l_i_n_e takes two parameters: an XDR  *,  and  an  unsigned
integer,  which  is  a  byte  count.   The routine returns a
pointer to a piece of the  stream's  internal  buffer.   The
caller  can  then  use  the  buffer segment for any purpose.
>From the stream's point of view, the bytes  in  the  buffer
segment  have  been consumed or put.  The routine may return
_N_U_L_L if it cannot return a buffer segment of  the  requested
size.  (The _x__i_n_l_i_n_e routine is for cycle squeezers.  Use of
the  resulting  buffer  is  not  data-portable.   Users  are
encouraged not to use this feature.)

The operations _x__g_e_t_b_y_t_e_s and _x__p_u_t_b_y_t_e_s blindly get and put
sequences  of  bytes  from or to the underlying stream; they
return _T_R_U_E if they are  successful,  and  _F_A_L_S_E  otherwise.
The routines have identical parameters (replace _x_x_x):

        bool_t
        xxxbytes(xdrs, buf, bytecount)
             XDR *xdrs;
             char *buf;
             u_int bytecount;

The operations _x__g_e_t_l_o_n_g and _x__p_u_t_l_o_n_g receive and put  long
numbers   from   and   to   the  data  stream.   It  is  the








                           - 84 -


responsibility of these routines to  translate  the  numbers
between the machine representation and the (standard) exter-
nal representation.  The UNIX primitives _h_t_o_n_l and _n_t_o_h_l can
be  helpful  in  accomplishing  this.  Section 6 defines the
standard representation of numbers.   The  higher-level  XDR
implementation   assumes   that  signed  and  unsigned  long
integers contain the same number of bits, and that  nonnega-
tive  integers have the same bit representations as unsigned
integers.  The routines return _T_R_U_E  if  they  succeed,  and
_F_A_L_S_E otherwise.  They have identical parameters:

        bool_t
        xxxlong(xdrs, lp)
             XDR *xdrs;
             long *lp;

Implementors of new XDR streams must make an  XDR  structure
(with  new  operation  routines) available to clients, using
some kind of create routine.

_5.  _A_d_v_a_n_c_e_d _T_o_p_i_c_s

This section describes techniques for  passing  data  struc-
tures  that are not covered in the preceding sections.  Such
structures include  linked  lists  (of  arbitrary  lengths).
Unlike the simpler examples covered in the earlier sections,
the following examples are written  using  both  the  XDR  C
library routines and the XDR data description language.  The
eXternal Data Representation Standard chapter of  this  _N_e_t_-
_w_o_r_k_i_n_g  _P_r_o_g_r_a_m_m_i_n_g  manual describes this language in com-
plete detail.

_5._1.  _L_i_n_k_e_d _L_i_s_t_s

The last example in the Pointers section presented a C  data
structure and its associated XDR routines for a individual's
gross assets and  liabilities.  The  example  is  duplicated
below:

struct gnumbers {
     long g_assets;
     long g_liabilities;
};
bool_t
xdr_gnumbers(xdrs, gp)
     XDR *xdrs;
     struct gnumbers *gp;
{
     if (xdr_long(xdrs, &(gp->g_assets)))
          return(xdr_long(xdrs, &(gp->g_liabilities)));
     return(FALSE);
}










                           - 85 -


Now assume that we wish to implement a linked list  of  such
information.  A  data structure could be constructed as fol-
lows:

struct gnumbers_node {
     struct gnumbers gn_numbers;
     struct gnumbers_node *gn_next;
};
typedef struct gnumbers_node *gnumbers_list;


The head of the linked list can be thought of  as  the  data
object;  that is, the head is not merely a convenient short-
hand for a structure.  Similarly the _g_n__n_e_x_t field  is  used
to indicate whether or not the object has terminated. Unfor-
tunately, if the object continues, the _g_n__n_e_x_t field is also
the  address of where it continues. The link addresses carry
no useful information when the object is serialized.  LP The
XDR data description of this linked list is described by the
recursive declaration of _g_n_u_m_b_e_r_s__l_i_s_t:

struct gnumbers {
     int g_assets;
     int g_liabilities;
};
struct gnumbers_node {
     gnumbers gn_numbers;
     gnumbers_list gn_next;
};
union gnumbers_list switch (bool more_data) {
case TRUE:
     gnumbers_node node;
case FALSE:
     void;
};


In this description, the boolean indicates whether there  is
more  data following it. If the boolean is _F_A_L_S_E, then it is
the last data field of the structure. If it is _T_R_U_E, then it
is  followed  by a gnumbers structure and (recursively) by a
_g_n_u_m_b_e_r_s__l_i_s_t.  Note that the C declaration has  no  boolean
explicitly  declared  in it (though the _g_n__n_e_x_t field impli-
citly carries the information), while the XDR data  descrip-
tion has no pointer explicitly declared in it.

Hints for writing the XDR routines for a _g_n_u_m_b_e_r_s__l_i_s_t  fol-
low  easily  from  the  XDR  description above. Note how the
primitive _x_d_r__p_o_i_n_t_e_r is used to  implement  the  XDR  union
above.











                           - 86 -


bool_t
xdr_gnumbers_node(xdrs, gn)
     XDR *xdrs;
     gnumbers_node *gn;
{
     return(xdr_gnumbers(xdrs, &gn->gn_numbers) &&
          xdr_gnumbers_list(xdrs, &gp->gn_next));
}
bool_t
xdr_gnumbers_list(xdrs, gnp)
     XDR *xdrs;
     gnumbers_list *gnp;
{
     return(xdr_pointer(xdrs, gnp,
          sizeof(struct gnumbers_node),
          xdr_gnumbers_node));
}


The unfortunate side effect of XDR'ing  a  list  with  these
routines  is that the C stack grows linearly with respect to
the number of node in the list.  This is due to  the  recur-
sion. The following routine collapses the above two mutually
recursive into a single, non-recursive one.






































                           - 87 -


bool_t
xdr_gnumbers_list(xdrs, gnp)
     XDR *xdrs;
     gnumbers_list *gnp;
{
     bool_t more_data;
     gnumbers_list *nextp;
     for (;;) {
          more_data = (*gnp != NULL);
          if (!xdr_bool(xdrs, &more_data)) {
               return(FALSE);
          }
          if (! more_data) {
               break;
          }
          if (xdrs->x_op == XDR_FREE) {
               nextp = &(*gnp)->gn_next;
          }
          if (!xdr_reference(xdrs, gnp,
               sizeof(struct gnumbers_node), xdr_gnumbers)) {

          return(FALSE);
          }
          gnp = (xdrs->x_op == XDR_FREE) ?
               nextp : &(*gnp)->gn_next;
     }
     *gnp = NULL;
     return(TRUE);
}


The first task is to find out whether there is more data  or
not,  so  that  this  boolean information can be serialized.
Notice that this statement is unnecessary in the  _X_D_R__D_E_C_O_D_E
case,  since  the  value  of more_data is not known until we
deserialize it in the next statement.

The next statement XDR's the  more_data  field  of  the  XDR
union. Then if there is truly no more data, we set this last
pointer to _N_U_L_L to indicate the end of the list, and  return
_T_R_U_E  because  we are done. Note that setting the pointer to
_N_U_L_L is only important in the _X_D_R__D_E_C_O_D_E case, since  it  is
already _N_U_L_L in the _X_D_R__E_N_C_O_D_E and DR_FREE cases.

Next, if the direction is _X_D_R__F_R_E_E, the value  of  _n_e_x_t_p  is
set  to  indicate  the  location  of the next pointer in the
list. We do this now because we need to dereference  gnp  to
find  the  location  of the next item in the list, and after
the next statement the pointer _g_n_p will be freed up  and  no
longer  valid.   We can't do this for all directions though,
because in the _X_D_R__D_E_C_O_D_E direction the value of  _g_n_p  won't
be set until the next statement.










                           - 88 -


Next, we XDR the  data  in  the  node  using  the  primitive
_x_d_r__r_e_f_e_r_e_n_c_e.   _x_d_r__r_e_f_e_r_e_n_c_e  is like _x_d_r__p_o_i_n_t_e_r which we
used before, but it does not send over the boolean  indicat-
ing  whether  there  is  more  data.  We  use  it instead of
_x_d_r__p_o_i_n_t_e_r because we have already XDR'd  this  information
ourselves.  Notice  that  the  xdr routine passed is not the
same type as an element in the list. The routine  passed  is
_x_d_r__g_n_u_m_b_e_r_s,  for XDR'ing gnumbers, but each element in the
list is actually  of  type  _g_n_u_m_b_e_r_s__n_o_d_e.   We  don't  pass
_x_d_r__g_n_u_m_b_e_r_s__n_o_d_e  because  it is recursive, and instead use
_x_d_r__g_n_u_m_b_e_r_s which XDR's  all  of  the  non-recursive  part.
Note  that this trick will work only if the _g_n__n_u_m_b_e_r_s field
is the first item in each element, so that  their  addresses
are identical when passed to _x_d_r__r_e_f_e_r_e_n_c_e.

Finally, we update _g_n_p to point to  the  next  item  in  the
list.  If the direction is _X_D_R__F_R_E_E, we set it to the previ-
ously saved value, otherwise we can dereference _g_n_p  to  get
the  proper  value.   Though  harder  to understand than the
recursive version, this  non-recursive  routine  will  never
cause  the  C  stack to blow up. It will also run more effi-
ciently since a lot of  procedure  call  overhead  has  been
removed.  Most  lists  are  small though (in the hundreds of
items or less) and the recursive version  should  be  suffi-
cient for them.

_e_X_t_e_r_n_a_l _D_a_t_a _R_e_p_r_e_s_e_n_t_a_t_i_o_n _S_t_a_n_d_a_r_d:  _P_r_o_t_o_c_o_l  _S_p_e_c_i_f_i_c_a_-
_t_i_o_n


_1.  _S_t_a_t_u_s _o_f _t_h_i_s _S_t_a_n_d_a_r_d

Note: This chapter specifies a protocol that  Sun  Microsys-
tems,  Inc.,  and  others are using.  It has been designated
RFC1014 by the ARPA Network Information Center.

_2.  _I_n_t_r_o_d_u_c_t_i_o_n

DR is a standard for the description and encoding  of  data.
It  is  useful  for transferring data between different com-
puter architectures, and has been used to  communicate  data
between  such  diverse machines as the Sun Workstation, VAX,
IBM-PC, and Cray.  DR fits into the ISO presentation  layer,
and  is  roughly analogous in purpose to X.409, ISO Abstract
Syntax Notation.  The major difference between these two  is
that  XDR  uses  implicit  typing, while X.409 uses explicit
typing.

DR uses a language to describe data formats.   The  language
can only be used only to describe data; it is not a program-
ming language.  This language allows one to describe  intri-
cate  data  formats  in a concise manner. The alternative of
using  graphical   representations   (itself   an   informal
language)  quickly  becomes incomprehensible when faced with









                           - 89 -


complexity.  The XDR language itself is  similar  to  the  C
language [1], just as Courier [4] is similar to Mesa. Proto-
cols such as Sun RPC (Remote Procedure  Call)  and  the  NFS
(Network  File  System)  use  XDR  to describe the format of
their data.

The XDR standard makes the following assumption: that  bytes
(or  octets)  are  portable, where a byte is defined to be 8
bits of data.  A given hardware  device  should  encode  the
bytes  onto  the  various  media  in  such  a way that other
hardware devices may decode the bytes without loss of  mean-
ing.  For example, the Ethernet standard suggests that bytes
be encoded in "little-endian" style [2], or  least  signifi-
cant bit first.

_2._1.  _B_a_s_i_c _B_l_o_c_k _S_i_z_e

The representation of all items requires a multiple of  four
bytes  (or  32  bits)  of  data.   The  bytes are numbered 0
through n-1.  The bytes are read or  written  to  some  byte
stream  such that byte m always precedes byte m+1.  If the n
bytes needed to contain the data are not a multiple of four,
then  the  n  bytes are followed by enough (0 to 3) residual
zero bytes, r, to make the total byte count a multiple of 4.

We include the familiar graphic box notation  for  illustra-
tion  and comparison.  In most illustrations, each box (del-
imited by a plus sign at the 4 corners and vertical bars and
dashes)  depicts  a byte.  Ellipses (...) between boxes show
zero or more additional bytes where required.

A Block

+--------+--------+...+--------+--------+...+--------+
| byte 0 | byte 1 |...|byte n-1|    0   |...|    0   |
+--------+--------+...+--------+--------+...+--------+
|<-----------n bytes---------->|<------r bytes------>|
|<-----------n+r (where (n+r) mod 4 = 0)>----------->|



_3.  _X_D_R _D_a_t_a _T_y_p_e_s

Each of the sections  that  follow  describes  a  data  type
defined  in the DR standard, shows how it is declared in the
language, and includes a graphic illustration of its  encod-
ing.

For each data type in the language we show a  general  para-
digm declaration.  Note that angle brackets (< and >) denote
variable length sequences of data and square brackets ([ and
])  denote fixed-length sequences of data.  "n", "m" and "r"
denote integers.  For the full  language  specification  and
more  formal  definitions  of terms such as "identifier" and









                           - 90 -


"declaration", refer  to  _T_h_e  _X_D_R  _L_a_n_g_u_a_g_e  _S_p_e_c_i_f_i_c_a_t_i_o_n,
below.

For some data types, more specific examples are included.  A
more  extensive example of a data description is in _A_n _E_x_a_m_-
_p_l_e _o_f _a_n _X_D_R _D_a_t_a _D_e_s_c_r_i_p_t_i_o_n, below.

_3._1.  _I_n_t_e_g_e_r

An XDR signed integer is a  32-bit  datum  that  encodes  an
integer  in the range [-2147483648,2147483647].  The integer
is represented in two's complement notation.  The  most  and
least significant bytes are 0 and 3, respectively.  Integers
are declared as follows:

Integer

(MSB)                   (LSB)
+-------+-------+-------+-------+
|byte 0 |byte 1 |byte 2 |byte 3 |
+-------+-------+-------+-------+
<------------32 bits------------>


_3._2.  _U_n_s_i_g_n_e_d _I_n_t_e_g_e_r

An XDR unsigned integer is a 32-bit  datum  that  encodes  a
nonnegative  integer  in  the  range  [0,4294967295].  It is
represented by an unsigned  binary  number  whose  most  and
least  significant  bytes  are  0  and  3, respectively.  An
unsigned integer is declared as follows:

Unsigned Integer

(MSB)                   (LSB)
+-------+-------+-------+-------+
|byte 0 |byte 1 |byte 2 |byte 3 |
+-------+-------+-------+-------+
<------------32 bits------------>


_3._3.  _E_n_u_m_e_r_a_t_i_o_n

Enumerations  have  the  same   representation   as   signed
integers.   Enumerations are handy for describing subsets of
the integers.  Enumerated data is declared as follows:

        enum { name-identifier = constant, ... } identifier;

For example, the three colors red, yellow, and blue could be
described by an enumerated type:

        enum { RED = 2, YELLOW = 3, BLUE = 5 } colors;










                           - 91 -


It is an error to encode as an enum any other  integer  than
those  that have been given assignments in the enum declara-
tion.

_3._4.  _B_o_o_l_e_a_n

Booleans are important enough and occur frequently enough to
warrant  their  own explicit type in the standard.  Booleans
are declared as follows:

        bool identifier;

This is equivalent to:

        enum { FALSE = 0, TRUE = 1 } identifier;


_3._5.  _H_y_p_e_r _I_n_t_e_g_e_r _a_n_d _U_n_s_i_g_n_e_d _H_y_p_e_r _I_n_t_e_g_e_r

The standard also defines  64-bit  (8-byte)  numbers  called
hyper integer and unsigned hyper integer.  Their representa-
tions are the obvious extensions  of  integer  and  unsigned
integer  defined  above.  They are represented in two's com-
plement notation.  The most and least significant bytes  are
0 and 7, respectively.  Their declarations:

Hyper Integer
Unsigned Hyper Integer

(MSB)                                                   (LSB)
+-------+-------+-------+-------+-------+-------+-------+-------+
|byte 0 |byte 1 |byte 2 |byte 3 |byte 4 |byte 5 |byte 6 |byte 7 |
+-------+-------+-------+-------+-------+-------+-------+-------+
<----------------------------64 bits---------------------------->


_3._6.  _F_l_o_a_t_i_n_g-_p_o_i_n_t

The standard defines the floating-point  data  type  "float"
(32  bits  or 4 bytes).  The encoding used is the IEEE stan-
dard for normalized single-precision floating-point  numbers
[3].   The  following  three  fields  describe  the  single-
precision floating-point number:

     S:   The sign of the number.  Values 0 and  1 represent
          positive and negative, respectively.  One bit.

     E:   The exponent of the number, base 2.  8   bits  are
          devoted  to this field.  The exponent is biased by
          127.

     F:   The fractional  part  of  the  number's  mantissa,
          base 2.   23 bits are devoted to this field.










                           - 92 -


Therefore, the floating-point number is described by:

        (-1)**S * 2**(E-Bias) * 1.F

It is declared as follows:

Single-Precision Floating-Point

+-------+-------+-------+-------+
|byte 0 |byte 1 |byte 2 |byte 3 |
S|   E   |           F          |
+-------+-------+-------+-------+
1|<- 8 ->|<-------23 bits------>|
<------------32 bits------------>

Just as the most and least significant bytes of a number are
0  and  3,  the most and least significant bits of a single-
precision floating- point number are 0 and 31.   The  begin-
ning  bit  (and most significant bit) offsets of S, E, and F
are 0, 1, and 9,  respectively.   Note  that  these  numbers
refer  to the mathematical positions of the bits, and NOT to
their actual physical locations (which vary from  medium  to
medium).

The IEEE specifications should be consulted  concerning  the
encoding  for  signed  zero, signed infinity (overflow), and
denormalized numbers (underflow)  [3].   According  to  IEEE
specifications, the "NaN" (not a number) is system dependent
and should not be used externally.

_3._7.  _D_o_u_b_l_e-_p_r_e_c_i_s_i_o_n _F_l_o_a_t_i_n_g-_p_o_i_n_t

The standard defines the encoding for  the  double-precision
floating-  point  data  type  "double" (64 bits or 8 bytes).
The encoding  used  is  the  IEEE  standard  for  normalized
double-precision  floating-point  numbers [3].  The standard
encodes the  following  three  fields,  which  describe  the
double-precision floating-point number:

     S:   The  sign  of  the  number.   Values   0   and   1
          represent  positive  and  negative,  respectively.
          One bit.

     E:   The exponent of the number, base 2.  11  bits  are
          devoted  to this field.  The exponent is biased by
          1023.

     F:   The fractional part  of  the  number's   mantissa,
          base 2.   52 bits are devoted to this field.

Therefore, the floating-point number is described by:

        (-1)**S * 2**(E-Bias) * 1.F










                           - 93 -


It is declared as follows:

Double-Precision Floating-Point

+------+------+------+------+------+------+------+------+
|byte 0|byte 1|byte 2|byte 3|byte 4|byte 5|byte 6|byte 7|
S|    E   |                    F                        |
+------+------+------+------+------+------+------+------+
1|<--11-->|<-----------------52 bits------------------->|
<-----------------------64 bits------------------------->

Just as the most and least significant bytes of a number are
0  and  3,  the most and least significant bits of a double-
precision floating- point number are 0 and 63.   The  begin-
ning  bit (and most significant bit) offsets of S, E , and F
are 0, 1, and 12, respectively.   Note  that  these  numbers
refer  to the mathematical positions of the bits, and NOT to
their actual physical locations (which vary from  medium  to
medium).

The IEEE specifications should be consulted  concerning  the
encoding  for  signed  zero, signed infinity (overflow), and
denormalized numbers (underflow)  [3].   According  to  IEEE
specifications, the "NaN" (not a number) is system dependent
and should not be used externally.

_3._8.  _F_i_x_e_d-_l_e_n_g_t_h _O_p_a_q_u_e _D_a_t_a

At times, fixed-length uninterpreted data needs to be passed
among  machines.   This  data  is  called  "opaque"  and  is
declared as follows:

        opaque identifier[n];

where the constant n is the (static) number of bytes  neces-
sary  to contain the opaque data.  If n is not a multiple of
four, then the n bytes are followed by enough (0 to 3) resi-
dual  zero  bytes,  r,  to  make the total byte count of the
opaque object a multiple of four.

Fixed-Length Opaque

0        1     ...
+--------+--------+...+--------+--------+...+--------+
| byte 0 | byte 1 |...|byte n-1|    0   |...|    0   |
+--------+--------+...+--------+--------+...+--------+
|<-----------n bytes---------->|<------r bytes------>|
|<-----------n+r (where (n+r) mod 4 = 0)------------>|


_3._9.  _V_a_r_i_a_b_l_e-_l_e_n_g_t_h _O_p_a_q_u_e _D_a_t_a

The standard also  provides  for  variable-length  (counted)
opaque  data, defined as a sequence of n (numbered 0 through









                           - 94 -


n-1) arbitrary bytes to  be  the  number  n  encoded  as  an
unsigned integer (as described below), and followed by the n
bytes of the sequence.

Byte m of the sequence  always  precedes  byte  m+1  of  the
sequence,  and  byte  0  of  the sequence always follows the
sequence's length (count).  enough (0 to  3)  residual  zero
bytes,  r,  to make the total byte count a multiple of four.
Variable-length opaque data is  declared  in  the  following
way:

        opaque identifier<m>;

or

        opaque identifier<>;

The constant m denotes an upper bound of the number of bytes
that the sequence may contain.  If m is not specified, as in
the second declaration, it is assumed to be (2**32) - 1, the
maximum length.  The constant m would normally be found in a
protocol specification.  For example, a filing protocol  may
state  that the maximum data transfer size is 8192 bytes, as
follows:

        opaque filedata<8192>;

This can be illustrated as follows:

Variable-Length Opaque

0     1     2     3     4     5   ...
+-----+-----+-----+-----+-----+-----+...+-----+-----+...+-----+
|        length n       |byte0|byte1|...| n-1 |  0  |...|  0  |
+-----+-----+-----+-----+-----+-----+...+-----+-----+...+-----+
|<-------4 bytes------->|<------n bytes------>|<---r bytes--->|
|<----n+r (where (n+r) mod 4 = 0)---->|


It   is  an error  to  encode  a  length  greater  than  the
maximum described in the specification.

_3._1_0.  _S_t_r_i_n_g

The standard defines a string of n (numbered 0 through  n-1)
ASCII  bytes  to  be  the  number  n  encoded as an unsigned
integer (as described above), and followed by the n bytes of
the  string.   Byte m of the string always precedes byte m+1
of the string, and byte 0 of the string always  follows  the
string's length.  If n is not a multiple of four, then the n
bytes are followed by enough (0 to 3) residual  zero  bytes,
r, to make the total byte count a multiple of four.  Counted
byte strings are declared as follows:










                           - 95 -


        string object<m>;

or

        string object<>;

The constant m denotes an upper bound of the number of bytes
that a string may contain.  If m is not specified, as in the
second declaration, it is assumed to be  (2**32)  -  1,  the
maximum length.  The constant m would normally be found in a
protocol specification.  For example, a filing protocol  may
state  that  a file name can be no longer than 255 bytes, as
follows:

        string filename<255>;

Which can be illustrated as:

A String

0     1     2     3     4     5   ...
+-----+-----+-----+-----+-----+-----+...+-----+-----+...+-----+
|        length n       |byte0|byte1|...| n-1 |  0  |...|  0  |
+-----+-----+-----+-----+-----+-----+...+-----+-----+...+-----+
|<-------4 bytes------->|<------n bytes------>|<---r bytes--->|
|<----n+r (where (n+r) mod 4 = 0)---->|


It   is an  error  to  encode  a length greater  than    the
maximum described in the specification.

_3._1_1.  _F_i_x_e_d-_l_e_n_g_t_h _A_r_r_a_y

Declarations for fixed-length arrays of homogeneous elements
are in the following form:

        type-name identifier[n];

Fixed-length arrays of elements numbered 0 through  n-1  are
encoded  by  individually encoding the elements of the array
in their natural order, 0 through n-1.  Each element's  size
is  a multiple of four bytes. Though all elements are of the
same type, the elements may have different sizes.  For exam-
ple, in a fixed-length array of strings, all elements are of
type "string", yet each element will vary in its length.

Fixed-Length Array

+---+---+---+---+---+---+---+---+...+---+---+---+---+
|   element 0   |   element 1   |...|  element n-1  |
+---+---+---+---+---+---+---+---+...+---+---+---+---+
|<--------------------n elements------------------->|











                           - 96 -


_3._1_2.  _V_a_r_i_a_b_l_e-_l_e_n_g_t_h _A_r_r_a_y

Counted arrays provide the ability to encode variable-length
arrays of homogeneous elements.  The array is encoded as the
element count n (an unsigned integer) followed by the encod-
ing of each of the array's elements, starting with element 0
and progressing through element n- 1.  The  declaration  for
variable-length arrays follows this form:

        type-name identifier<m>;

or

        type-name identifier<>;

The constant m  specifies  the  maximum  acceptable  element
count of an array; if  m is not specified, as  in the second
declaration, it is assumed to be (2**32) - 1.

Counted Array

0  1  2  3
+--+--+--+--+--+--+--+--+--+--+--+--+...+--+--+--+--+
|     n     | element 0 | element 1 |...|element n-1|
+--+--+--+--+--+--+--+--+--+--+--+--+...+--+--+--+--+
|<-4 bytes->|<--------------n elements------------->|

It is  an error to  encode  a  value of n that   is  greater
than the maximum described in the specification.

_3._1_3.  _S_t_r_u_c_t_u_r_e

Structures are declared as follows:

        struct {
             component-declaration-A;
             component-declaration-B;
             ...
        } identifier;

The components of the structure are encoded in the order  of
their  declaration  in the structure.  Each component's size
is a multiple of four bytes, though the  components  may  be
different sizes.

Structure

+-------------+-------------+...
| component A | component B |...
+-------------+-------------+...













                           - 97 -


_3._1_4.  _D_i_s_c_r_i_m_i_n_a_t_e_d _U_n_i_o_n

A discriminated union is a type composed of  a  discriminant
followed  by a type selected from a set of prearranged types
according to the value of the  discriminant.   The  type  of
discriminant   is   either  "int",  "unsigned  int",  or  an
enumerated type, such as "bool".  The  component  types  are
called "arms" of the union, and are preceded by the value of
the discriminant which  implies  their  encoding.   Discrim-
inated unions are declared as follows:

        union switch (discriminant-declaration) {
             case discriminant-value-A:
             arm-declaration-A;
             case discriminant-value-B:
             arm-declaration-B;
             ...
             default: default-declaration;
        } identifier;

Each "case" keyword is followed by  a  legal  value  of  the
discriminant.   The  default  arm is optional.  If it is not
specified, then a valid encoding of the union cannot take on
unspecified  discriminant  values.   The size of the implied
arm is always a multiple of four bytes.

The discriminated union is encoded as its discriminant  fol-
lowed by the encoding of the implied arm.

Discriminated Union

0   1   2   3
+---+---+---+---+---+---+---+---+
|  discriminant |  implied arm  |
+---+---+---+---+---+---+---+---+
|<---4 bytes--->|


_3._1_5.  _V_o_i_d

An XDR void is a 0-byte  quantity.   Voids  are  useful  for
describing  operations that take no data as input or no data
as output. They are also useful in unions, where  some  arms
may contain data and others do not.  The declaration is sim-
ply as follows:

        void;

Voids are illustrated as follows:














                           - 98 -


Void

  ++
  ||
  ++
--><-- 0 bytes


_3._1_6.  _C_o_n_s_t_a_n_t

The data declaration for a constant follows this form:

        const name-identifier = n;

"const" is used to define a symbolic name for a constant; it
does  not  declare  any  data.  The symbolic constant may be
used anywhere a regular constant may be used.  For  example,
the  following  defines  a symbolic constant DOZEN, equal to
12.

        const DOZEN = 12;


_3._1_7.  _T_y_p_e_d_e_f

"typedef" does not declare any data either,  but  serves  to
define new identifiers for declaring data. The syntax is:

        typedef declaration;

The new type name is  actually  the  variable  name  in  the
declaration part of the typedef.  For example, the following
defines a new type called "eggbox" using  an  existing  type
called "egg":

        typedef egg eggbox[DOZEN];

Variables declared using the new type  name  have  the  same
type  as  the new type name would have in the typedef, if it
was considered a variable.  For example, the  following  two
declarations   are  equivalent  in  declaring  the  variable
"fresheggs":

        eggbox  fresheggs;
        egg     fresheggs[DOZEN];

When a typedef involves a struct, enum, or union definition,
there  is  another  (preferred)  syntax  that may be used to
define the same type.  In general, a typedef of the  follow-
ing form:

        typedef <<struct, union, or enum definition>> identifier;

may be converted to the alternative  form  by  removing  the









                           - 99 -


"typedef"   part   and  placing  the  identifier  after  the
"struct", "union", or "enum" keyword, instead of at the end.
For  example,  here  are  the  two  ways  to define the type
"bool":

        typedef enum {    /* using typedef */
             FALSE = 0,
             TRUE = 1
             } bool;

        enum bool {       /* preferred alternative */
             FALSE = 0,
             TRUE = 1
             };

The reason this syntax is preferred is one does not have  to
wait  until  the end of a declaration to figure out the name
of the new type.

_3._1_8.  _O_p_t_i_o_n_a_l-_d_a_t_a

Optional-data is one kind of union that occurs so frequently
that  we  give  it a special syntax of its own for declaring
it.  It is declared as follows:

        type-name *identifier;

This is equivalent to the following union:

        union switch (bool opted) {
             case TRUE:
             type-name element;
             case FALSE:
             void;
        } identifier;

It is also equivalent to the following variable-length array
declaration, since the boolean "opted" can be interpreted as
the length of the array:

        type-name identifier<1>;

Optional-data is not so interesting in  itself,  but  it  is
very useful for describing recursive data-structures such as
linked-lists and trees.  For example, the following  defines
a  type  "stringlist" that encodes lists of arbitrary length
strings:

        struct *stringlist {
             string item<>;
             stringlist next;
        };

It could have been equivalently declared  as  the  following









                          - 100 -


union:

        union stringlist switch (bool opted) {
             case TRUE:
                  struct {
                       string item<>;
                       stringlist next;
                  } element;
             case FALSE:
                  void;
        };

or as a variable-length array:

        struct stringlist<1> {
             string item<>;
             stringlist next;
        };

Both of these declarations  obscure  the  intention  of  the
stringlist  type,  so  the optional-data declaration is pre-
ferred over both of them.  The optional-data type also has a
close  correlation  to  how  recursive  data  structures are
represented in high-level languages such as Pascal or  C  by
use  of pointers. In fact, the syntax is the same as that of
the C language for pointers.

_3._1_9.  _A_r_e_a_s _f_o_r _F_u_t_u_r_e _E_n_h_a_n_c_e_m_e_n_t

The XDR standard lacks representations for  bit  fields  and
bitmaps, since the standard is based on bytes.  Also missing
are packed (or binary-coded) decimals.

The intent of the XDR standard was  not  to  describe  every
kind of data that people have ever sent or will ever want to
send from machine to machine. Rather, it only describes  the
most  commonly  used data-types of high-level languages such
as Pascal  or  C  so  that  applications  written  in  these
languages  will  be  able  to  communicate  easily over some
medium.

One could imagine  extensions  to  XDR  that  would  let  it
describe  almost  any  existing  protocol, such as TCP.  The
minimum necessary for this are support for  different  block
sizes and byte-orders.  The XDR discussed here could then be
considered the 4-byte big-endian member of a larger XDR fam-
ily.

_4.  _D_i_s_c_u_s_s_i_o_n














                          - 101 -


_4._1.  _W_h_y _a _L_a_n_g_u_a_g_e _f_o_r _D_e_s_c_r_i_b_i_n_g _D_a_t_a?

There  are  many  advantages  in  using  a  data-description
language  such  as  XDR  versus using  diagrams.   Languages
are  more  formal than diagrams   and   lead  to less  ambi-
guous    descriptions   of  data.  Languages are also easier
to understand and allow  one  to  think  of  other    issues
instead  of  the   low-level details of bit-encoding.  Also,
there is  a close analogy  between the  types  of XDR and  a
high-level  language    such   as  C    or    Pascal.   This
makes   the implementation  of  XDR  encoding  and  decoding
modules an easier task.  Finally, the language specification
itself  is an ASCII string that can be passed from   machine
to machine  to perform  on-the-fly data interpretation.

_4._2.  _W_h_y _O_n_l_y _o_n_e _B_y_t_e-_O_r_d_e_r _f_o_r _a_n _X_D_R _U_n_i_t?

Supporting two byte-orderings requires a higher level proto-
col for determining in which byte-order the data is encoded.
Since XDR is not a protocol, this can't be done.  The advan-
tage  of  this,  though,  is  that data in XDR format can be
written to a magnetic tape, for  example,  and  any  machine
will be able to interpret it, since no higher level protocol
is necessary for determining the byte-order.

_4._3.  _W_h_y _d_o_e_s _X_D_R _u_s_e _B_i_g-_E_n_d_i_a_n _B_y_t_e-_O_r_d_e_r?

Yes, it is unfair, but having only one byte-order means  you
have  to be unfair to somebody.  Many architectures, such as
the Motorola 68000  and  IBM  370,  support  the  big-endian
byte-order.

_4._4.  _W_h_y _i_s _t_h_e _X_D_R _U_n_i_t _F_o_u_r _B_y_t_e_s _W_i_d_e?

There is a tradeoff in choosing the XDR unit size.  Choosing
a  small  size such as two makes the encoded data small, but
causes alignment problems for machines that  aren't  aligned
on  these  boundaries.  A large size such as eight means the
data will be aligned on virtually every machine, but  causes
the  encoded  data  to  grow  too  big.   We chose four as a
compromise.  Four is big enough to  support  most  architec-
tures  efficiently,  except  for  rare  machines such as the
eight-byte aligned Cray.  Four is also small enough to  keep
the encoded data restricted to a reasonable size.

_4._5.  _W_h_y _m_u_s_t _V_a_r_i_a_b_l_e-_L_e_n_g_t_h _D_a_t_a _b_e _P_a_d_d_e_d _w_i_t_h _Z_e_r_o_s?

It is desirable that the same  data  encode  into  the  same
thing  on all machines, so that encoded data can be meaning-
fully compared or checksummed.  Forcing the padded bytes  to
be zero ensures this.












                          - 102 -


_4._6.  _W_h_y _i_s _t_h_e_r_e _N_o _E_x_p_l_i_c_i_t _D_a_t_a-_T_y_p_i_n_g?

Data-typing has a relatively high cost for what small advan-
tages it may have.  One cost is the expansion of data due to
the inserted type fields.  Another  is  the  added  cost  of
interpreting  these type fields and acting accordingly.  And
most protocols already know what type they expect, so  data-
typing  supplies  only  redundant information.  However, one
can still get the benefits of data-typing using XDR. One way
is  to  encode  two  things: first a string which is the XDR
data description of the encoded data, and then  the  encoded
data  itself.   Another  way is to assign a value to all the
types in XDR, and then define a universal type  which  takes
this value as its discriminant and for each value, describes
the corresponding data type.

_5.  _T_h_e _X_D_R _L_a_n_g_u_a_g_e _S_p_e_c_i_f_i_c_a_t_i_o_n


_5._1.  _N_o_t_a_t_i_o_n_a_l _C_o_n_v_e_n_t_i_o_n_s

This specification  uses an extended Backus-Naur Form  nota-
tion  for  describing  the  XDR language.   Here is  a brief
description  of the notation:

1.   The characters |, (, ), [, ],  , and * are special.

2.   Terminal symbols are  strings of any   characters  sur-
     rounded by double quotes.

3.   Non-terminal symbols are strings of non-special charac-
     ters.

4.   Alternative items  are  separated  by  a  vertical  bar
     ("|").

5.   Optional items are enclosed in brackets.

6.   Items  are  grouped  together  by  enclosing  them   in
     parentheses.

7.   A * following an item means  0 or more  occurrences  of
     that item.

For example,  consider  the  following pattern:

"a " "very" (", " " very")* [" cold " "and"]  " rainy " ("day" | "night")


An infinite  number of  strings match  this pattern.  A  few
of them are:












                          - 103 -


        "a very rainy day"
        "a very, very rainy day"
        "a very cold and  rainy day"
        "a very, very, very cold and  rainy night"


_5._2.  _L_e_x_i_c_a_l _N_o_t_e_s

1.   Comments begin with '/*' and terminate with '*/'.

2.   White space serves to separate items and  is  otherwise
     ignored.

3.   An identifier is a  letter  followed  by   an  optional
     sequence  of  letters,  digits  or underbar ('_').  The
     case of identifiers is not ignored.

4.   A  constant is  a  sequence  of  one  or  more  decimal
     digits, optionally preceded by a minus-sign ('-').

_5._3.  _S_y_n_t_a_x _I_n_f_o_r_m_a_t_i_o_n

        declaration:
             type-specifier identifier
             | type-specifier identifier "[" value "]"
             | type-specifier identifier "<" [ value ] ">"
             | "opaque" identifier "[" value "]"
             | "opaque" identifier "<" [ value ] ">"
             | "string" identifier "<" [ value ] ">"
             | type-specifier "*" identifier
             | "void"


        value:
             constant
             | identifier

        type-specifier:
               [ "unsigned" ] "int"
             | [ "unsigned" ] "hyper"
             | "float"
             | "double"
             | "bool"
             | enum-type-spec
             | struct-type-spec
             | union-type-spec
             | identifier
















                          - 104 -


        enum-type-spec:
             "enum" enum-body

        enum-body:
             "{"
             ( identifier "=" value )
             ( "," identifier "=" value )*
             "}"


        struct-type-spec:
             "struct" struct-body

        struct-body:
             "{"
             ( declaration ";" )
             ( declaration ";" )*
             "}"


        union-type-spec:
             "union" union-body

        union-body:
             "switch" "(" declaration ")" "{"
             ( "case" value ":" declaration ";" )
             ( "case" value ":" declaration ";" )*
             [ "default" ":" declaration ";" ]
             "}"

        constant-def:
             "const" identifier "=" constant ";"


        type-def:
             "typedef" declaration ";"
             | "enum" identifier enum-body ";"
             | "struct" identifier struct-body ";"
             | "union" identifier union-body ";"

        definition:
             type-def
             | constant-def

        specification:
             definition *


_5._3._1.  _S_y_n_t_a_x _N_o_t_e_s


1.   The following are keywords and cannot be used as  iden-
     tifiers:  "bool", "case", "const", "default", "double",
     "enum", "float", "hyper", "opaque", "string", "struct",









                          - 105 -


     "switch", "typedef", "union", "unsigned" and "void".

2.   Only unsigned constants may be used as size  specifica-
     tions  for  arrays.   If an identifier is used, it must
     have been declared previously as an  unsigned  constant
     in a "const" definition.

3.   Constant and type identifiers within  the  scope  of  a
     specification  are  in  the same name space and must be
     declared uniquely within this scope.

4.   Similarly, variable names must  be unique  within   the
     scope   of struct and union declarations. Nested struct
     and union declarations create new scopes.

5.   The discriminant of a union must  be  of  a  type  that
     evaluates  to  an  integer.  That  is, "int", "unsigned
     int", "bool", an enumerated type or any typedefed  type
     that  evaluates  to  one  of these is legal.  Also, the
     case values must be one of  the  legal  values  of  the
     discriminant.   Finally, a case value may not be speci-
     fied more  than  once  within  the  scope  of  a  union
     declaration.

_6.  _A_n _E_x_a_m_p_l_e _o_f _a_n _X_D_R _D_a_t_a _D_e_s_c_r_i_p_t_i_o_n

Here is a short XDR data description of  a  thing  called  a
"file",  which  might  be  used  to  transfer files from one
machine to another.


































                          - 106 -



const MAXUSERNAME = 32;     /* max length of a user name */
const MAXFILELEN = 65535;   /* max length of a file      */
const MAXNAMELEN = 255;     /* max length of a file name */

/*
 * Types of files:
 */

enum filekind {
     TEXT = 0,       /* ascii data */
     DATA = 1,       /* raw data   */
     EXEC = 2        /* executable */
};

/*
 * File information, per kind of file:
 */

union filetype switch (filekind kind) {
     case TEXT:
          void;                           /* no extra information */
     case DATA:
          string creator<MAXNAMELEN>;     /* data creator         */
     case EXEC:
          string interpretor<MAXNAMELEN>; /* program interpretor  */
};

/*
 * A complete file:
 */

struct file {
     string filename<MAXNAMELEN>; /* name of file */
     filetype type;               /* info about file */
     string owner<MAXUSERNAME>;   /* owner of file   */
     opaque data<MAXFILELEN>;     /* file data       */
};


Suppose now that there is  a user named  "john" who wants to
store  his  lisp program "sillyprog" that contains just  the
data "(quit)".  His file would be encoded as follows:




















                          - 107 -


______________________________________________________________
 Offset   Hex Bytes     ASCII   Description
______________________________________________________________
      0   00 00 00 09    ....   Length of filename = 9
      4   73 69 6c 6c    sill   Filename characters
      8   79 70 72 6f    ypro    ... and more characters ...
     12   67 00 00 00    g...    ... and 3 zero-bytes of fill
     16   00 00 00 02    ....   Filekind is EXEC = 2
     20   00 00 00 04    ....   Length of interpretor = 4
     24   6c 69 73 70    lisp   Interpretor characters
     28   00 00 00 04    ....   Length of owner = 4
     32   6a 6f 68 6e    john   Owner characters
     36   00 00 00 06    ....   Length of file data = 6
     40   28 71 75 69    (qui   File data bytes ...
     44   74 29 00 00    t)..    ... and 2 zero-bytes of fill
______________________________________________________________
||||||||||||||












                                                             ||||||||||||||















_7.  _R_e_f_e_r_e_n_c_e_s

[1]  Brian W. Kernighan & Dennis M. Ritchie, "The C Program-
ming  Language", Bell Laboratories, Murray Hill, New Jersey,
1978.

[2]  Danny Cohen, "On Holy Wars and a Plea for Peace",  IEEE
Computer, October 1981.

[3]  "IEEE Standard for Binary  Floating-Point  Arithmetic",
ANSI/IEEE  Standard  754-1985,  Institute  of Electrical and
Electronics Engineers, August 1985.

[4]  "Courier: The Remote Procedure  Call  Protocol",  XEROX
Corporation, XSIS 038112, December 1981.

_R_e_m_o_t_e _P_r_o_c_e_d_u_r_e _C_a_l_l_s: _P_r_o_t_o_c_o_l _S_p_e_c_i_f_i_c_a_t_i_o_n


_1.  _S_t_a_t_u_s _o_f _t_h_i_s _M_e_m_o

Note: This chapter specifies a protocol that  Sun  Microsys-
tems,  Inc., and others are using.  It has been submitted to
the ARPA-Internet for  consideration  as  an  RFC.   Certain
details  may  change as a result of comments made during the
review of this draft standard.


_2.  _I_n_t_r_o_d_u_c_t_i_o_n

This chapter specifies  a  message protocol  used in  imple-
menting  Sun's  Remote  Procedure  Call (RPC) package.  (The
message  protocol  is  specified  with  the  eXternal   Data
Representation   (XDR)  language.   See  the  eXternal  Data
Representation Standard for the details.   Here,  we  assume
that  the  reader is familiar with XDR and do not attempt to
justify RPC or  its uses).  The paper by Birrell and  Nelson
[1]   is  recommended  as  an   excellent background to  and








                          - 108 -


justification of RPC.

_2._1.  _T_e_r_m_i_n_o_l_o_g_y

This chapter discusses  servers,  services,  programs,  pro-
cedures,  clients,  and  versions.   A  server is a piece of
software where network services are implemented.  A  network
service  is  a collection of one or more remote programs.  A
remote program implements one or more remote procedures; the
procedures,  their parameters, and results are documented in
the specific program's protocol specification (see the  Port
Mapper  Program  Protocol,  below, for an example).  Network
clients are pieces of software  that  initiate  remote  pro-
cedure  calls  to  services.  A server may support more than
one version of a remote program in order to be forward  com-
patible with changing protocols.

For example, a network file service may be composed  of  two
programs.  One program may deal with high-level applications
such as file system access control and locking.   The  other
may  deal  with  low-level  file IO and have procedures like
"read" and "write".  A client machine of  the  network  file
service  would  call  the procedures associated with the two
programs of the service on behalf of some user on the client
machine.

_2._2.  _T_h_e _R_P_C _M_o_d_e_l

The remote procedure call model is similar to the local pro-
cedure  call  model.   In  the local case, the caller places
arguments to a procedure  in  some  well-specified  location
(such  as  a result register).  It then transfers control to
the procedure, and eventually gains back control.   At  that
point,  the  results of the procedure are extracted from the
well-specified location, and the caller continues execution.

The remote procedure call is similar, in that one thread  of
control  logically  winds  through  two processes-one is the
caller's process, the other is a server's process.  That is,
the  caller  process sends a call message to the server pro-
cess and waits (blocks) for a reply message.  The call  mes-
sage   contains  the  procedure's  parameters,  among  other
things.  The reply message contains the procedure's results,
among other things.  Once the reply message is received, the
results of the procedure are extracted, and caller's  execu-
tion is resumed.

On the server  side,  a  process  is  dormant  awaiting  the
arrival  of  a  call  message.  When one arrives, the server
process extracts the procedure's  parameters,  computes  the
results,  sends  a  reply  message, and then awaits the next
call message.

Note that in this model, only one of the  two  processes  is









                          - 109 -


active at any given time.  However, this model is only given
as an example.  The RPC protocol makes  no  restrictions  on
the  concurrency model implemented, and others are possible.
For example, an implementation may choose to have RPC  calls
be asynchronous, so that the client may do useful work while
waiting for the reply from the server.  Another  possibility
is  to  have the server create a task to process an incoming
request, so that the server can be  free  to  receive  other
requests.

_2._3.  _T_r_a_n_s_p_o_r_t_s _a_n_d _S_e_m_a_n_t_i_c_s

The RPC protocol  is  independent  of  transport  protocols.
That  is, RPC does not care how a message is passed from one
process to another.  The protocol deals only with specifica-
tion and interpretation of messages.

It is important to point out that RPC does not try to imple-
ment  any  kind of reliability and that the application must
be aware of the type of transport protocol  underneath  RPC.
If  it  knows  it  is running on top of a reliable transport
such as TCP/IP[6], then most of the work is already done for
it.   On  the  other  hand,  if  it  is running on top of an
unreliable transport such as UDP/IP[7], it must implement is
own retransmission and time-out policy as the RPC layer does
not provide this service.

Because of transport independence, the RPC protocol does not
attach  specific semantics to the remote procedures or their
execution.  Semantics can be inferred from  (but  should  be
explicitly  specified by) the underlying transport protocol.
For example, consider RPC running on top  of  an  unreliable
transport such as UDP/IP.  If an application retransmits RPC
messages after short time-outs, the only thing it can  infer
if  it  receives no reply is that the procedure was executed
zero or more times.  If it does receive a reply, then it can
infer that the procedure was executed at least once.

A server may wish to remember  previously  granted  requests
from  a  client and not regrant them in order to insure some
degree of execute-at-most-once semantics.  A server  can  do
this by taking advantage of the transaction ID that is pack-
aged with every RPC request.  The main use of this  transac-
tion  is  by  the  client  RPC  layer in matching replies to
requests.  However, a client application may choose to reuse
its  previous  transaction ID when retransmitting a request.
The server application, knowing this  fact,  may  choose  to
remember  this  ID  after granting a request and not regrant
requests with the same ID in order to achieve some degree of
execute-at-most-once  semantics.   The server is not allowed
to examine this ID in any other way except  as  a  test  for
equality.

On the other hand, if using a  reliable  transport  such  as









                          - 110 -


TCP/IP,  the application can infer from a reply message that
the procedure was executed exactly once, but if it  receives
no  reply message, it cannot assume the remote procedure was
not executed.  Note that even if a connection-oriented  pro-
tocol like TCP is used, an application still needs time-outs
and reconnection to handle server crashes.

There  are  other  possibilities  for   transports   besides
datagram-  or connection-oriented protocols.  For example, a
request-reply protocol such as VMTP[2] is perhaps  the  most
natural transport for RPC.

_N_O_T_E:  _A_t _S_u_n, _R_P_C _i_s _c_u_r_r_e_n_t_l_y _i_m_p_l_e_m_e_n_t_e_d _o_n _t_o_p  _o_f  _b_o_t_h
_T_C_P/_I_P _a_n_d _U_D_P/_I_P _t_r_a_n_s_p_o_r_t_s.


_2._4.  _B_i_n_d_i_n_g _a_n_d _R_e_n_d_e_z_v_o_u_s _I_n_d_e_p_e_n_d_e_n_c_e

The act of binding a client to a service is NOT part of  the
remote  procedure  call  specification.   This important and
necessary function is left up to some higher-level software.
(The software may use RPC itself-see the Port Mapper Program
Protocol, below).

Implementors should think of the RPC protocol as  the  jump-
subroutine  instruction  ("JSR")  of  a  network; the loader
(binder) makes JSR useful, and the loader itself uses JSR to
accomplish  its  task.  Likewise, the network makes RPC use-
ful, using RPC to accomplish this task.

_2._5.  _A_u_t_h_e_n_t_i_c_a_t_i_o_n

The RPC protocol provides the fields necessary for a  client
to  identify  itself  to a service and vice-versa.  Security
and access control mechanisms can be built  on  top  of  the
message  authentication.   Several  different authentication
protocols can be supported.  A field in the RPC header indi-
cates  which  protocol  is  being used.  More information on
specific  authentication  protocols  can  be  found  in  the
Authentication Protocols, below.

_3.  _R_P_C _P_r_o_t_o_c_o_l _R_e_q_u_i_r_e_m_e_n_t_s

The RPC protocol must provide for the following:

1.   Unique specification of a procedure to be called.

2.   Provisions for matching response  messages  to  request
     messages.

3.   Provisions for authenticating the caller to service and
     vice-versa.

Besides  these  requirements,  features  that   detect   the









                          - 111 -


following are worth supporting because of protocol roll-over
errors,  implementation  bugs,  user  error,   and   network
administration:

1.   RPC protocol mismatches.

2.   Remote program protocol version mismatches.

3.   Protocol  errors  (such  as   misspecification   of   a
     procedure's parameters).

4.   Reasons why remote authentication failed.

5.   Any other reasons why the  desired  procedure  was  not
     called.

_3._1.  _P_r_o_g_r_a_m_s _a_n_d _P_r_o_c_e_d_u_r_e_s

The RPC call message has three unsigned fields:  remote pro-
gram  number, remote program version number, and remote pro-
cedure number.  The three fields uniquely identify the  pro-
cedure  to  be  called.  Program numbers are administered by
some central authority (like Sun).  Once an implementor  has
a  program  number, he can implement his remote program; the
first implementation would  most  likely  have  the  version
number of 1.  Because most new protocols evolve into better,
stable, and mature protocols, a version field  of  the  call
message  identifies which version of the protocol the caller
is using.  Version numbers make speaking old and new  proto-
cols through the same server process possible.

The procedure number identifies the procedure to be  called.
These  numbers are documented in the specific program's pro-
tocol specification.  For example, a file service's protocol
specification  may  state  that  its  procedure  number 5 is
"read" and procedure number 12 is "write".

Just as remote program protocols  may  change  over  several
versions, the actual RPC message protocol could also change.
Therefore, the call message also has in it the  RPC  version
number,  which is always equal to two for the version of RPC
described here.

The reply message to a request  message  has enough   infor-
mation to distinguish the following error conditions:

1.   The remote implementation of RPC  does  speak  protocol
     version  2.   The lowest and highest supported RPC ver-
     sion numbers are returned.

2.   The remote program is not available on the remote  sys-
     tem.











                          - 112 -


3.   The remote program does not support the requested  ver-
     sion  number.   The lowest and highest supported remote
     program version numbers are returned.

4.   The requested procedure number does not  exist.   (This
     is  usually  a  caller  side  protocol  or  programming
     error.)

5.   The parameters to the remote  procedure  appear  to  be
     garbage  from the server's point of view.  (Again, this
     is usually caused by a disagreement about the  protocol
     between client and service.)

_3._2.  _A_u_t_h_e_n_t_i_c_a_t_i_o_n

Provisions for  authentication  of  caller  to  service  and
vice-versa  are provided as a part of the RPC protocol.  The
call message has two authentication fields, the  credentials
and  verifier.   The  reply  message  has one authentication
field, the response verifier.  The RPC  protocol  specifica-
tion  defines  all  three  fields to be the following opaque
type:

        enum auth_flavor {
            AUTH_NULL        = 0,
            AUTH_UNIX        = 1,
            AUTH_SHORT       = 2,
            /* and more to be defined */
        };

        struct opaque_auth {
            auth_flavor flavor;
            opaque body<400>;
        };


In  simple  English,  any  _o_p_a_q_u_e__a_u_t_h   structure   is   an
_a_u_t_h__f_l_a_v_o_r  enumeration followed by bytes which are  opaque
to the RPC protocol implementation.

The interpretation and  semantics   of  the  data  contained
within  the authentication   fields  is specified  by  indi-
vidual,   independent  authentication   protocol  specifica-
tions.    (See  Authentication Protocols, below, for defini-
tions of the various authentication protocols.)

If authentication parameters were   rejected, the   response
message contains information stating why they were rejected.

_3._3.  _P_r_o_g_r_a_m _N_u_m_b_e_r _A_s_s_i_g_n_m_e_n_t

Program numbers  are  given  out  in  groups  of  _0_x_2_0_0_0_0_0_0_0
(decimal 536870912) according to the following chart:










                          - 113 -


_______________________________________
 Program Numbers       Description
_______________________________________
        0 - 1fffffff   Defined by Sun
 20000000 - 3fffffff   Defined by user
 40000000 - 5fffffff      Transient
 60000000 - 7fffffff      Reserved
 80000000 - 9fffffff      Reserved
 a0000000 - bfffffff      Reserved
 c0000000 - dfffffff      Reserved
 e0000000 - ffffffff      Reserved
_______________________________________
|||||||||||








                                      |||||||||||











The first group is a range of numbers  administered  by  Sun
Microsystems  and  should  be  identical for all sites.  The
second range is for applications peculiar  to  a  particular
site.   This  range  is intended primarily for debugging new
programs.  When a site develops an application that might be
of  general  interest,  that  application should be given an
assigned number in the first range.  The third group is  for
applications that generate program numbers dynamically.  The
final groups are reserved for future use, and should not  be
used.

_3._4.  _O_t_h_e_r _U_s_e_s _o_f _t_h_e _R_P_C _P_r_o_t_o_c_o_l

The intended use of this protocol is for calling remote pro-
cedures.   That  is,  each  call  message  is matched with a
response  message.   However,  the  protocol  itself  is   a
message-passing  protocol  with which other (non-RPC) proto-
cols can be implemented.  Sun  currently  uses,  or  perhaps
abuses,  the  RPC  message  protocol  for  the following two
(non-RPC) protocols:  batching (or pipelining) and broadcast
RPC.   These  two  protocols  are  discussed but not defined
below.

_3._4._1.  _B_a_t_c_h_i_n_g

Batching allows  a  client  to  send  an  arbitrarily  large
sequence  of  call  messages to a server; batching typically
uses reliable byte stream protocols (like  TCP/IP)  for  its
transport.   In the case of batching, the client never waits
for a reply from the server, and the server  does  not  send
replies  to  batch  requests.   A sequence of batch calls is
usually terminated by a legitimate RPC in order to flush the
pipeline (with positive acknowledgement).

_3._4._2.  _B_r_o_a_d_c_a_s_t _R_P_C

In broadcast RPC-based protocols, the client sends a  broad-
cast  packet  to the network and waits for numerous replies.
Broadcast RPC uses unreliable, packet-based protocols  (like
UDP/IP)  as  its transports.  Servers that support broadcast
protocols only respond  when  the  request  is  successfully









                          - 114 -


processed,  and are silent in the face of errors.  Broadcast
RPC uses the Port Mapper RPC service to achieve  its  seman-
tics.  See the Port Mapper Program Protocol, below, for more
information.



























































                          - 115 -



_4.  _T_h_e _R_P_C _M_e_s_s_a_g_e _P_r_o_t_o_c_o_l

This section defines the RPC message  protocol  in  the  XDR
data  description  language.   The  message  is defined in a
top-down style.

enum msg_type {
     CALL  = 0,
     REPLY = 1
};

/*
* A reply to a call message can take on two forms:
* The message was either accepted or rejected.
*/
enum reply_stat {
     MSG_ACCEPTED = 0,
     MSG_DENIED   = 1
};

/*
* Given that a call message was accepted,  the following is the
* status of an attempt to call a remote procedure.
*/
enum accept_stat {
     SUCCESS       = 0, /* RPC executed successfully       */
     PROG_UNAVAIL  = 1, /* remote hasn't exported program  */
     PROG_MISMATCH = 2, /* remote can't support version #  */
     PROC_UNAVAIL  = 3, /* program can't support procedure */
     GARBAGE_ARGS  = 4  /* procedure can't decode params   */
};


/*
* Reasons why a call message was rejected:
*/
enum reject_stat {
     RPC_MISMATCH = 0, /* RPC version number != 2          */
     AUTH_ERROR = 1    /* remote can't authenticate caller */
};

/*
* Why authentication failed:
*/
enum auth_stat {
     AUTH_BADCRED      = 1,  /* bad credentials (seal broken) */
     AUTH_REJECTEDCRED = 2,  /* client must begin new session */
     AUTH_BADVERF      = 3,  /* bad verifier (seal broken)    */
     AUTH_REJECTEDVERF = 4,  /* verifier expired or replayed  */
     AUTH_TOOWEAK      = 5   /* rejected for security reasons */
};











                          - 116 -


/*
* The  RPC  message:
* All   messages  start with   a transaction  identifier,  xid,
* followed  by a  two-armed  discriminated union.   The union's
* discriminant is a  msg_type which switches to  one of the two
* types   of the message.   The xid  of a REPLY  message always
* matches  that of the initiating CALL   message.   NB: The xid
* field is only  used for clients  matching reply messages with
* call messages  or for servers detecting  retransmissions; the
* service side  cannot treat this id  as any type   of sequence
* number.
*/
struct rpc_msg {
     unsigned int xid;
     union switch (msg_type mtype) {
          case CALL:
               call_body cbody;
          case REPLY:
               reply_body rbody;
     } body;
};


/*
* Body of an RPC request call:
* In version 2 of the  RPC protocol specification, rpcvers must
* be equal to 2.  The  fields prog,  vers, and proc specify the
* remote program, its version number, and the  procedure within
* the remote program to be called.  After these  fields are two
* authentication  parameters: cred (authentication credentials)
* and verf  (authentication verifier).  The  two authentication
* parameters are   followed by  the  parameters  to  the remote
* procedure,  which  are specified  by  the  specific   program
* protocol.
*/
struct call_body {
     unsigned int rpcvers;  /* must be equal to two (2) */
     unsigned int prog;
     unsigned int vers;
     unsigned int proc;
     opaque_auth cred;
     opaque_auth verf;
     /* procedure specific parameters start here */
};



















                          - 117 -


/*
* Body of a reply to an RPC request:
* The call message was either accepted or rejected.
*/
union reply_body switch (reply_stat stat) {
     case MSG_ACCEPTED:
          accepted_reply areply;
     case MSG_DENIED:
          rejected_reply rreply;
} reply;


/*
* Reply to   an RPC request  that  was accepted  by the server:
* there could be an error even though the request was accepted.
* The first field is an authentication verifier that the server
* generates in order to  validate itself  to the caller.  It is
* followed by    a  union whose     discriminant  is   an  enum
* accept_stat.  The  SUCCESS  arm of    the union  is  protocol
* specific.  The PROG_UNAVAIL, PROC_UNAVAIL, and GARBAGE_ARGP
* arms of the union are void.   The PROG_MISMATCH arm specifies
* the lowest and highest version numbers of the  remote program
* supported by the server.
*/
struct accepted_reply {
     opaque_auth verf;
     union switch (accept_stat stat) {
          case SUCCESS:
               opaque results[0];
               /* procedure-specific results start here */
          case PROG_MISMATCH:
               struct {
                    unsigned int low;
                    unsigned int high;
               } mismatch_info;
          default:
               /*
               * Void.  Cases include PROG_UNAVAIL, PROC_UNAVAIL,
               * and GARBAGE_ARGS.
               */
               void;
     } reply_data;
};




















                          - 118 -


/*
* Reply to an RPC request that was rejected by the server:
* The request  can   be rejected for   two reasons:  either the
* server   is not  running a   compatible  version  of the  RPC
* protocol    (RPC_MISMATCH), or    the  server   refuses    to
* authenticate the  caller  (AUTH_ERROR).  In  case of  an  RPC
* version mismatch,  the server returns the  lowest and highest
* supported    RPC  version    numbers.  In   case   of refused
* authentication, failure status is returned.
*/
union rejected_reply switch (reject_stat stat) {
     case RPC_MISMATCH:
          struct {
               unsigned int low;
               unsigned int high;
          } mismatch_info;
     case AUTH_ERROR:
          auth_stat stat;
};


_5.  _A_u_t_h_e_n_t_i_c_a_t_i_o_n _P_r_o_t_o_c_o_l_s

As previously stated, authentication parameters are  opaque,
but  open-ended  to the rest of the RPC protocol.  This sec-
tion defines some "flavors" of authentication implemented at
(and  supported by) Sun.  Other sites are free to invent new
authentication types, with the same rules of  flavor  number
assignment as there is for program number assignment.

_5._1.  _N_u_l_l _A_u_t_h_e_n_t_i_c_a_t_i_o_n

Often calls must be made where the caller does not know  who
he  is  or  the  server does not care who the caller is.  In
this  case,  the  flavor  value  (the  discriminant  of  the
opaque_auth's  union)  of  the  RPC  message's  credentials,
verifier, and response verifier is _A_U_T_H__N_U_L_L.  The  bytes of
the  opaque_auth's  body   are undefined.  It is recommended
that the opaque length be zero.

_5._2.  _U_N_I_X _A_u_t_h_e_n_t_i_c_a_t_i_o_n

The caller of a remote procedure may wish to  identify  him-
self  as  he  is identified on a UNIX system.  The  value of
the credential's discriminant of an  RPC  call   message  is
_A_U_T_H__U_N_I_X.  the credential's opaque body encode the the fol-
lowing structure:
















                          - 119 -


        struct auth_unix {
             unsigned int stamp;
             string machinename<255>;
             unsigned int uid;
             unsigned int gid;
             unsigned int gids<10>;
        };

The _s_t_a_m_p is an  arbitrary    ID which the   caller  machine
may generate.  The _m_a_c_h_i_n_e_n_a_m_e is the  name of the  caller's
machine (like  "krypton").  The _u_i_d is  the caller's  effec-
tive  user   ID.   The _g_i_d is  the caller's effective  group
ID.  The _g_i_d_s is  a counted array of  groups  which  contain
the  caller  as   a  member.   The verifier accompanying the
credentials  should  be  of _A_U_T_H__N_U_L_L (defined above).

The value of the  discriminant  of   the  response  verifier
received  in  the   reply  message  from  the    server  may
be _A_U_T_H__N_U_L_L or _A_U_T_H__S_H_O_R_T.  In  the  case   of  _A_U_T_H__S_H_O_R_T,
the bytes of the response verifier's string encode an opaque
structure.  This new opaque structure may now be  passed  to
the  server instead of the original _A_U_T_H__U_N_I_X flavor creden-
tials.  The server keeps a cache which maps shorthand opaque
structures  (passed  back  by  way  of  an  _A_U_T_H__S_H_O_R_T style
response  verifier)  to  the  original  credentials  of  the
caller.   The  caller  can save network bandwidth and server
cpu cycles by using the new credentials.

The server may flush the shorthand opaque structure  at  any
time.   If  this  happens, the remote procedure call message
will be rejected due to an authentication error.  The reason
for  the  failure will be _A_U_T_H__R_E_J_E_C_T_E_D_C_R_E_D.  At this point,
the caller may wish to try the original _A_U_T_H__U_N_I_X  style  of
credentials.





























                          - 120 -



_6.  _R_e_c_o_r_d _M_a_r_k_i_n_g _S_t_a_n_d_a_r_d

When RPC messages are passed on top of a byte stream  proto-
col  (like  TCP/IP), it is necessary, or at least desirable,
to delimit one message from another in order to  detect  and
possibly  recover from user protocol errors.  This is called
record marking (RM).  Sun uses this RM/TCP/IP transport  for
passing  RPC  messages on TCP streams.  One RPC message fits
into one RM record.

A record is composed of one or  more  record  fragments.   A
record  fragment  is  a  four-byte  header  followed by 0 to
(2**31) - 1 bytes of fragment data.  The bytes encode an un-
signed binary number; as with DR integers, the byte order is
from highest to lowest.  The  number  encodes  two  values-a
boolean  which  indicates  whether  the fragment is the last
fragment of the record (bit value 1 implies the fragment  is
the  last fragment) and a 31-bit unsigned binary value which
is the length in bytes of the fragment's data.  The  boolean
value  is the highest-order bit of the header; the length is
the 31 low-order bits.  (Note that this record specification
is NOT in XDR standard form!)








































                          - 121 -



_7.  _T_h_e _R_P_C _L_a_n_g_u_a_g_e

Just as there was a need to describe the XDR data-types in a
formal  language,  there  is  also need to describe the pro-
cedures that operate on these XDR  data-types  in  a  formal
language as well.  We use the RPC Language for this purpose.
It is an extension to the XDR language.  The following exam-
ple is used to describe the essence of the language.

_7._1.  _A_n _E_x_a_m_p_l_e _S_e_r_v_i_c_e _D_e_s_c_r_i_b_e_d _i_n _t_h_e _R_P_C _L_a_n_g_u_a_g_e

Here is an example of the specification  of  a  simple  ping
program.

/*
* Simple ping program
*/
program PING_PROG {
     /* Latest and greatest version */
     version PING_VERS_PINGBACK {
     void
     PINGPROC_NULL(void) = 0;

     /*
     * Ping the caller, return the round-trip time
     * (in microseconds). Returns -1 if the operation
     * timed out.
     */
     int
     PINGPROC_PINGBACK(void) = 1;
} = 2;

/*
* Original version
*/
version PING_VERS_ORIG {
     void
     PINGPROC_NULL(void) = 0;
     } = 1;
} = 1;

const PING_VERS = 2;      /* latest version */


The first version described is _P_I_N_G__V_E_R_S__P_I_N_G_B_A_C_K with   two
procedures,     _P_I_N_G_P_R_O_C__N_U_L_L     and     _P_I_N_G_P_R_O_C__P_I_N_G_B_A_C_K.
_P_I_N_G_P_R_O_C__N_U_L_L takes no arguments and returns no results, but
it  is useful for computing round-trip times from the client
to the server and back again.  By convention, procedure 0 of
any  RPC  protocol should have the same semantics, and never
require any kind of authentication.  The second procedure is
used  for  the  client  to have the server do a reverse ping
operation back to the client, and it returns the  amount  of









                          - 122 -


time  (in  microseconds)  that the operation used.  The next
version, _P_I_N_G__V_E_R_S__O_R_I_G, is the original version of the pro-
tocol  and  it does not contain _P_I_N_G_P_R_O_C__P_I_N_G_B_A_C_K procedure.
It  is useful for compatibility  with old client   programs,
and as  this program matures it may be dropped from the pro-
tocol entirely.

_7._2.  _T_h_e _R_P_C _L_a_n_g_u_a_g_e _S_p_e_c_i_f_i_c_a_t_i_o_n

The  RPC language is identical to  the XDR language,  except
for the added definition of a _p_r_o_g_r_a_m-_d_e_f described below.

        program-def:
             "program" identifier "{"
                  version-def
                  version-def *
             "}" "=" constant ";"

        version-def:
             "version" identifier "{"
                  procedure-def
                  procedure-def *
             "}" "=" constant ";"

        procedure-def:
             type-specifier identifier "(" type-specifier ")"
             "=" constant ";"


_7._3.  _S_y_n_t_a_x _N_o_t_e_s

1.   The following keywords  are  added   and    cannot   be
     used   as identifiers: "program" and "version";

2.   A version name cannot occur more than once  within  the
     scope of a program definition. Nor can a version number
     occur more than once within  the  scope  of  a  program
     definition.

3.   A procedure name cannot occur  more  than  once  within
     the  scope of a version definition. Nor can a procedure
     number occur more than once within the scope of version
     definition.

4.   Program identifiers are in the same name space as  con-
     stant and type identifiers.

5.   Only unsigned constants can  be assigned  to  programs,
     versions and procedures.

_8.  _P_o_r_t _M_a_p_p_e_r _P_r_o_g_r_a_m _P_r_o_t_o_c_o_l

The port mapper program maps RPC program and version numbers
to  transport-specific  port  numbers.   This  program makes









                          - 123 -


dynamic binding of remote programs possible.

This is desirable because the range of reserved port numbers
is very small and the number of potential remote programs is
very large.  By running only the port mapper on  a  reserved
port,  the  port  numbers  of  other  remote programs can be
ascertained by querying the port mapper.

The port mapper also aids in broadcast  RPC.   A  given  RPC
program  will usually have different port number bindings on
different machines, so there is no way to directly broadcast
to  all  of  these programs.  The port mapper, however, does
have a fixed port number.  So, to broadcast to a given  pro-
gram,  the  client  actually  sends  its message to the port
mapper located at the broadcast address.  Each  port  mapper
that  picks  up  the  broadcast then calls the local service
specified by the client.  When  the  port  mapper  gets  the
reply  from the local service, it sends the reply on back to
the client.












































                          - 124 -



_8._1.  _P_o_r_t _M_a_p_p_e_r _P_r_o_t_o_c_o_l _S_p_e_c_i_f_i_c_a_t_i_o_n (_i_n _R_P_C _L_a_n_g_u_a_g_e)

const PMAP_PORT = 111;      /* portmapper port number */

/*
* _A _m_a_p_p_i_n_g _o_f (_p_r_o_g_r_a_m, _v_e_r_s_i_o_n, _p_r_o_t_o_c_o_l) _t_o _p_o_r_t _n_u_m_b_e_r
*/
_s_t_r_u_c_t _m_a_p_p_i_n_g {
     _u_n_s_i_g_n_e_d _i_n_t _p_r_o_g;
     _u_n_s_i_g_n_e_d _i_n_t _v_e_r_s;
     _u_n_s_i_g_n_e_d _i_n_t _p_r_o_t;
     _u_n_s_i_g_n_e_d _i_n_t _p_o_r_t;
};

/*
* _S_u_p_p_o_r_t_e_d _v_a_l_u_e_s _f_o_r _t_h_e "_p_r_o_t" _f_i_e_l_d
*/
_c_o_n_s_t _I_P_P_R_O_T_O__T_C_P = _6;      /* _p_r_o_t_o_c_o_l _n_u_m_b_e_r _f_o_r _T_C_P/_I_P */
const IPPROTO_UDP = 17;     /* protocol number for UDP/IP */

/*
* _A _l_i_s_t _o_f _m_a_p_p_i_n_g_s
*/
_s_t_r_u_c_t *_p_m_a_p_l_i_s_t {
     _m_a_p_p_i_n_g _m_a_p;
     _p_m_a_p_l_i_s_t _n_e_x_t;
};


/*
* Arguments to callit
*/
struct call_args {
     unsigned int prog;
     unsigned int vers;
     unsigned int proc;
     opaque args<>;
};

/*
* Results of callit
*/
struct call_result {
     unsigned int port;
     opaque res<>;
};
















                          - 125 -


/*
* Port mapper procedures
*/
program PMAP_PROG {
     version PMAP_VERS {
          void
          PMAPPROC_NULL(void)         = 0;

          bool
          PMAPPROC_SET(mapping)       = 1;

          bool
          PMAPPROC_UNSET(mapping)     = 2;

          unsigned int
          PMAPPROC_GETPORT(mapping)   = 3;

          pmaplist
          PMAPPROC_DUMP(void)         = 4;

          call_result
          PMAPPROC_CALLIT(call_args)  = 5;
     } = 2;
} = 100000;


_8._2.  _P_o_r_t _M_a_p_p_e_r _O_p_e_r_a_t_i_o_n

The portmapper  program  currently  supports  two  protocols
(UDP/IP and TCP/IP).  The portmapper is contacted by talking
to it on assigned port number 111 (SUNRPC [8]) on either  of
these  protocols.  The following is a description of each of
the portmapper procedures:

PMAPPROC_NULL:This procedure does no work.   By  convention,
     procedure  zero of any protocol takes no parameters and
     returns no results.

PMAPPROC_SET:When a program first  becomes  available  on  a
     machine,  it registers itself with the port mapper pro-
     gram on the same machine.  The program passes its  pro-
     gram  number  "prog",  version number "vers", transport
     protocol number "prot", and the port "port" on which it
     awaits   service  request.   The  procedure  returns  a
     boolean response whose value is _T_R_U_E if  the  procedure
     successfully  established  the mapping and _F_A_L_S_E other-
     wise.  The procedure refuses to establish a mapping  if
     one already exists for the tuple "(prog, vers, prot)".

PMAPPROC_UNSET:When a program becomes unavailable, it should
     unregister  itself  with the port mapper program on the
     same machine.  The parameters and results have meanings
     identical  to  those of _P_M_A_P_P_R_O_C__S_E_T.  The protocol and
     port number fields of the argument are ignored.









                          - 126 -


PMAPPROC_GETPORT:Given  a  program  number  "prog",  version
     number  "vers",  and  transport protocol number "prot",
     this procedure returns the port  number  on  which  the
     program  is  awaiting  call  requests.  A port value of
     zeros means the program has not been  registered.   The
     "port" field of the argument is ignored.

PMAPPROC_DUMP:This procedure enumerates all entries  in  the
     port mapper's database.  The procedure takes no parame-
     ters and returns a list of program, version,  protocol,
     and port values.

PMAPPROC_CALLIT:This  procedure  allows  a  caller  to  call
     another  remote  procedure  on the same machine without
     knowing the remote  procedure's  port  number.   It  is
     intended  for supporting broadcasts to arbitrary remote
     programs via the well-known port  mapper's  port.   The
     parameters  "prog",  "vers",  "proc",  and the bytes of
     "args" are the program  number,  version  number,  pro-
     cedure number, and parameters of the remote procedure.

_N_o_t_e:

     1.   This procedure only sends a response if  the  pro-
          cedure was successfully executed and is silent (no
          response) otherwise.

     2.   The port mapper communicates with the remote  pro-
          gram using UDP/IP only.

The procedure returns the remote program's port number,  and
the  bytes  of  results  are  the results of the remote pro-
cedure.






























                          - 127 -


_9.  _R_e_f_e_r_e_n_c_e_s

[1]  Birrell, Andrew D. & Nelson, Bruce  Jay;  "Implementing
Remote Procedure Calls"; XEROX CSL-83-7, October 1983.

[2]  Cheriton, D.;  "VMTP:   Versatile  Message  Transaction
Protocol",  Preliminary  Version  0.3;  Stanford University,
January 1987.

[3]  Diffie & Hellman;  "Net  Directions  in  Cryptography";
IEEE  Transactions  on  Information  Theory  IT-22, November
1976.

[4]  Harrenstien, K.; "Time Server",  RFC  738;  Information
Sciences Institute, October 1977.

[5]  National Bureau of Standards;  "Data  Encryption  Stan-
dard";  Federal Information Processing Standards Publication
46, January 1977.

[6]  Postel, J.;  "Transmission  Control  Protocol  -  DARPA
Internet  Program Protocol Specification", RFC 793; Informa-
tion Sciences Institute, September 1981.

[7]  Postel, J.; "User Datagram Protocol", RFC 768; Informa-
tion Sciences Institute, August 1980.

[8]  Reynolds, J.  & Postel,  J.;  "Assigned  Numbers",  RFC
923; Information Sciences Institute, October 1984.

_N_e_t_w_o_r_k _F_i_l_e _S_y_s_t_e_m: _V_e_r_s_i_o_n _2 _P_r_o_t_o_c_o_l _S_p_e_c_i_f_i_c_a_t_i_o_n


_1.  _S_t_a_t_u_s _o_f _t_h_i_s _S_t_a_n_d_a_r_d

Note: This chapter specifies a protocol that  Sun  Microsys-
tems,  Inc., and others are using.  It specifies it in stan-
dard ARPA RFC form.

_2.  _I_n_t_r_o_d_u_c_t_i_o_n

The Sun Network Filesystem  (NFS)  protocol  provides  tran-
sparent  remote access to shared filesystems over local area
networks.  The NFS  protocol  is  designed  to  be  machine,
operating system, network architecture, and transport proto-
col independent.  This independence is achieved through  the
use  of  Remote Procedure Call (RPC) primitives built on top
of an eXternal Data Representation  (XDR).   Implementations
exist  for a variety of machines, from personal computers to
supercomputers.

The supporting mount protocol allows the server to hand  out
remote access privileges to a restricted set of clients.  It
performs the operating system-specific functions that allow,









                          - 128 -


for  example, to attach remote directory trees to some local
file system.

_2._1.  _R_e_m_o_t_e _P_r_o_c_e_d_u_r_e _C_a_l_l

Sun's  remote  procedure  call  specification   provides   a
procedure-  oriented  interface  to  remote  services.  Each
server supplies a program that is a set of procedures.   NFS
is  one  such  "program".   The combination of host address,
program number, and procedure number  specifies  one  remote
service procedure.  RPC does not depend on services provided
by specific protocols, so it can be used with any underlying
transport  protocol.  See the Remote Procedure Calls: Proto-
col Specification chapter of this manual.

_2._2.  _E_x_t_e_r_n_a_l _D_a_t_a _R_e_p_r_e_s_e_n_t_a_t_i_o_n

The eXternal Data Representation (XDR) standard  provides  a
common  way  of representing a set of data types over a net-
work.  The NFS Protocol Specification is written  using  the
RPC data description language. For more information, see the
eXternal Data Representation Standard:  Protocol  Specifica-
tion  chapter  of this manual.  Sun provides implementations
of XDR and RPC,  but NFS does not require  their  use.   Any
software that provides equivalent functionality can be used,
and if the encoding is exactly the same it can  interoperate
with other implementations of NFS.

_2._3.  _S_t_a_t_e_l_e_s_s _S_e_r_v_e_r_s

The NFS protocol is stateless.  That is, a server  does  not
need  to  maintain  any extra state information about any of
its clients  in  order  to  function  correctly.   Stateless
servers  have  a distinct advantage over stateful servers in
the event of a failure.  With stateless  servers,  a  client
need only retry a request until the server responds; it does
not even need to know that the server has  crashed,  or  the
network  temporarily  went  down.   The client of a stateful
server, on the other hand, needs to either detect  a  server
crash  and rebuild the server's state when it comes back up,
or cause client operations to fail.

This may not sound like an important issue, but  it  affects
the  protocol  in  some unexpected ways.  We feel that it is
worth a bit of extra complexity in the protocol to  be  able
to write very simple servers that do not require fancy crash
recovery.

On the other hand, NFS deals with objects such as files  and
directories  that inherently have state -- what good would a
file be if it did not keep its contents intact?  The goal is
to  not  introduce  any  extra state in the protocol itself.
Another way to simplify recovery  is  by  making  operations
"idempotent" whenever possible (so that they can potentially









                          - 129 -


be repeated).

_3.  _N_F_S _P_r_o_t_o_c_o_l _D_e_f_i_n_i_t_i_o_n

Servers have been known to change over time, and so can  the
protocol  that  they  use.  So RPC provides a version number
with each RPC request. This RFC describes version two of the
NFS protocol.  Even in the second version, there are various
obsolete procedures and parameters, which will be removed in
later versions. An RFC for version three of the NFS protocol
is currently under preparation.

_3._1.  _F_i_l_e _S_y_s_t_e_m _M_o_d_e_l

NFS assumes a file system that is hierarchical, with  direc-
tories  as  all but the bottom-level files.  Each entry in a
directory (file, directory,  device,  etc.)   has  a  string
name.   Different operating systems may have restrictions on
the depth of the tree or the names used, as  well  as  using
different  syntax  to represent the "pathname", which is the
concatenation of all the "components"  (directory  and  file
names)  in  the name.  A "file system" is a tree on a single
server (usually a single disk or physical partition) with  a
specified  "root".  Some operating systems provide a "mount"
operation to make all file systems appear as a single  tree,
while others maintain a "forest" of file systems.  Files are
unstructured streams of uninterpreted bytes.  Version  3  of
NFS uses a slightly more general file system model.

NFS looks up one component of a pathname at a time.  It  may
not be obvious why it does not just take the whole pathname,
traipse down the directories, and return a file handle  when
it  is done.  There are several good reasons not to do this.
First, pathnames need separators between the directory  com-
ponents,  and  different  operating  systems  use  different
separators.  We could define  a  Network  Standard  Pathname
Representation,  but  then  every  pathname would have to be
parsed and converted at each end.   Other  issues  are  dis-
cussed in NFS Implementation Issues below.

Although files and directories are similar objects  in  many
ways,  different procedures are used to read directories and
files.   This  provides  a  network  standard   format   for
representing  directories.  The same argument as above could
have been used to justify a procedure that returns only  one
directory  entry  per  call.   The  problem  is  efficiency.
Directories can contain many entries, and a remote  call  to
return each would be just too slow.

_3._2.  _R_P_C _I_n_f_o_r_m_a_t_i_o_n

AuthenticationThe   NFS  service uses  _A_U_T_H__U_N_I_X,  _A_U_T_H__D_E_S,
     or  _A_U_T_H__S_H_O_R_T  style  authentication,  except  in  the
     NULL procedure where _A_U_T_H__N_O_N_E is also allowed.









                          - 130 -


Transport ProtocolsNFS  currently  is  supported  on  UDP/IP
     only.

Port NumberThe NFS protocol  currently  uses  the  UDP  port
     number  2049.  This is not an officially assigned port,
     so  later versions of the protocol use  the  ``Portmap-
     ping'' facility of RPC.

_3._3.  _S_i_z_e_s _o_f _X_D_R _S_t_r_u_c_t_u_r_e_s

These are the sizes, given in decimal bytes, of various  XDR
structures used in the protocol:

        /* The maximum number of bytes of data in a READ or WRITE request  */
        const MAXDATA = 8192;

        /* The maximum number of bytes in a pathname argument */
        const MAXPATHLEN = 1024;

        /* The maximum number of bytes in a file name argument */
        const MAXNAMLEN = 255;

        /* The size in bytes of the opaque "cookie" passed by READDIR */
        const COOKIESIZE  = 4;

        /* The size in bytes of the opaque file handle */
        const FHSIZE = 32;


_3._4.  _B_a_s_i_c _D_a_t_a _T_y_p_e_s

The following XDR  definitions  are  basic   structures  and
types used in other structures described further on.






























                          - 131 -



_3._4._1.  _s_t_a_t

        enum stat {
             NFS_OK = 0,
             NFSERR_PERM=1,
             NFSERR_NOENT=2,
             NFSERR_IO=5,
             NFSERR_NXIO=6,
             NFSERR_ACCES=13,
             NFSERR_EXIST=17,
             NFSERR_NODEV=19,
             NFSERR_NOTDIR=20,
             NFSERR_ISDIR=21,
             NFSERR_FBIG=27,
             NFSERR_NOSPC=28,
             NFSERR_ROFS=30,
             NFSERR_NAMETOOLONG=63,
             NFSERR_NOTEMPTY=66,
             NFSERR_DQUOT=69,
             NFSERR_STALE=70,
             NFSERR_WFLUSH=99
        };


The _s_t_a_t type  is returned with every  procedure's  results.
A  value  of  _N_F_S__O_K indicates that the  call completed suc-
cessfully and the  results are  valid.  The   other   values
indicate   some kind of error  occurred on the  server  side
during the servicing   of the procedure.  The  error  values
are derived from UNIX error numbers.

NFSERR_PERM:Not owner.  The caller  does  not  have  correct
     ownership to perform the requested operation.

NFSERR_NOENT:No such  file  or  directory.     The  file  or
     directory specified does not exist.

NFSERR_IO:Some sort of hard  error occurred when the  opera-
     tion  was in progress.  This could be a disk error, for
     example.

NFSERR_NXIO:No such device or address.

NFSERR_ACCES:Permission   denied.   The   caller  does   not
     have  the  correct  permission to perform the requested
     operation.

NFSERR_EXIST:File  exists.   The  file   specified   already
     exists.

NFSERR_NODEV:No such device.











                          - 132 -


NFSERR_NOTDIR:Not   a  directory.    The  caller   specified
     a non-directory in a directory operation.

NFSERR_ISDIR:Is a directory.  The caller specified  a direc-
     tory in a non- directory operation.

NFSERR_FBIG:File too large.   The  operation caused  a  file
     to grow beyond the server's limit.

NFSERR_NOSPC:No  space  left  on   device.    The  operation
     caused the server's filesystem to reach its limit.

NFSERR_ROFS:Read-only  filesystem.   Write  attempted  on  a
     read-only filesystem.

NFSERR_NAMETOOLONG:File name   too   long.  The  file   name
     in  an operation was too long.

NFSERR_NOTEMPTY:Directory    not   empty.    Attempted    to
     remove  a directory that was not empty.

NFSERR_DQUOT:Disk quota exceeded.  The client's disk   quota
     on the server has been exceeded.

NFSERR_STALE:The  "fhandle" given  in    the  arguments  was
     invalid.   That  is,  the file referred to by that file
     handle no longer exists,  or  access  to  it  has  been
     revoked.

NFSERR_WFLUSH:The server's  write cache  used  in  the  _W_R_I_-
     _T_E_C_A_C_H_E call got flushed to disk.


_3._4._2.  _f_t_y_p_e

        enum ftype {
             NFNON = 0,
             NFREG = 1,
             NFDIR = 2,
             NFBLK = 3,
             NFCHR = 4,
             NFLNK = 5
        };

The enumeration _f_t_y_p_e gives the type of a  file.   The  type
_N_F_N_O_N  indicates  a non-file, _N_F_R_E_G is a regular file, _N_F_D_I_R
is a directory, _N_F_B_L_K is a block-special device, _N_F_C_H_R is  a
character-special device, and _N_F_L_N_K is a symbolic link.

_3._4._3.  _f_h_a_n_d_l_e

        typedef opaque fhandle[FHSIZE];

The _f_h_a_n_d_l_e is the file handle passed between the server and









                          - 133 -


the  client. All file operations are done using file handles
to refer to a file or directory.  The file handle  can  con-
tain whatever information the server needs to distinguish an
individual file.

_3._4._4.  _t_i_m_e_v_a_l

        struct timeval {
             unsigned int seconds;
             unsigned int useconds;
        };

The  _t_i_m_e_v_a_l  structure  is  the  number  of   seconds   and
microseconds  since midnight January 1, 1970, Greenwich Mean
Time.  It is used to pass time and date information.

_3._4._5.  _f_a_t_t_r

        struct fattr {
             ftype        type;
             unsigned int mode;
             unsigned int nlink;
             unsigned int uid;
             unsigned int gid;
             unsigned int size;
             unsigned int blocksize;
             unsigned int rdev;
             unsigned int blocks;
             unsigned int fsid;
             unsigned int fileid;
             timeval      atime;
             timeval      mtime;
             timeval      ctime;
        };

The _f_a_t_t_r structure  contains  the  attributes  of  a  file;
"type"  is  the  type  of the file; "nlink" is the number of
hard links to the file (the number of  different  names  for
the  same  file); "uid" is the user identification number of
the owner of the file; "gid"  is  the  group  identification
number of the group of the file; "size" is the size in bytes
of the file; "blocksize" is the size in bytes of a block  of
the  file;  "rdev" is the device number of the file if it is
type _N_F_C_H_R or _N_F_B_L_K; "blocks" is the number  of  blocks  the
file  takes up on disk; "fsid" is the file system identifier
for the filesystem containing the file; "fileid" is a number
that  uniquely  identifies  the  file within its filesystem;
"atime" is the time when the  file  was  last  accessed  for
either read or write; "mtime" is the time when the file data
was last modified (written); and "ctime" is  the  time  when
the  status  of  the  file was last changed.  Writing to the
file also changes "ctime" if the size of the file changes.

"mode" is the access mode encoded as a set of bits.   Notice









                          - 134 -


that the file type is specified both in the mode bits and in
the file type.  This is really a bug  in  the  protocol  and
will  be  fixed  in future versions.  The descriptions given
below specify the bit positions using octal numbers.

____________________________________________________________________________
   Bit                               Description
____________________________________________________________________________
 0040000   This is a directory; "type" field should be NFDIR.
 0020000   This is a character special file; "type" field should be NFCHR.
 0060000   This is a block special file; "type" field should be NFBLK.
 0100000   This is a regular file; "type" field should be NFREG.
 0120000   This is a symbolic link file;  "type" field should be NFLNK.
 0140000   This is a named socket; "type" field should be NFNON.
 0004000   Set user id on execution.
 0002000   Set group id on execution.
 0001000   Save swapped text even after use.
 0000400   Read permission for owner.
 0000200   Write permission for owner.
 0000100   Execute and search permission for owner.
 0000040   Read permission for group.
 0000020   Write permission for group.
 0000010   Execute and search permission for group.
 0000004   Read permission for others.
 0000002   Write permission for others.
 0000001   Execute and search permission for others.
____________________________________________________________________________
||||||||||||||||||||


















                                                                           ||||||||||||||||||||




















Notes:

     The bits are  the same as the mode   bits returned   by
     the  _s_t_a_t(2)  system call in the UNIX system.  The file
     type is  specified  both in the mode  bits  and in  the
     file type.   This   is fixed  in future versions.

     The "rdev" field in  the  attributes  structure  is  an
     operating  system  specific device specifier.  It  will
     be  removed and generalized in the next revision of the
     protocol.


_3._4._6.  _s_a_t_t_r

        struct sattr {
             unsigned int mode;
             unsigned int uid;
             unsigned int gid;
             unsigned int size;
             timeval      atime;
             timeval      mtime;
        };

The _s_a_t_t_r structure contains the file attributes  which  can
be  set  from  the  client.   The fields are the same as for
_f_a_t_t_r above.  A "size" of zero  means  the  file  should  be
truncated.   A  value of -1 indicates a field that should be








                          - 135 -


ignored.


_3._4._7.  _f_i_l_e_n_a_m_e

        typedef string filename<MAXNAMLEN>;

The type _f_i_l_e_n_a_m_e is used for  passing file names  or  path-
name components.


_3._4._8.  _p_a_t_h

        typedef string path<MAXPATHLEN>;

The type _p_a_t_h is a pathname.  The server considers it  as  a
string with no internal structure,  but to the client  it is
the name of a node in a filesystem tree.


_3._4._9.  _a_t_t_r_s_t_a_t

        union attrstat switch (stat status) {
             case NFS_OK:
                  fattr attributes;
             default:
                  void;
        };

The _a_t_t_r_s_t_a_t structure is a  common  procedure  result.   It
contains  a   "status"  and,  if  the call   succeeded,   it
also contains  the attributes  of  the  file  on  which  the
operation was done.


_3._4._1_0.  _d_i_r_o_p_a_r_g_s

        struct diropargs {
             fhandle  dir;
             filename name;
        };

The _d_i_r_o_p_a_r_g_s structure is used  in  directory   operations.
The  "fhandle"  "dir" is the directory in  which to find the
file "name".  A directory operation  is  one  in  which  the
directory is affected.

















                          - 136 -



_3._4._1_1.  _d_i_r_o_p_r_e_s

        union diropres switch (stat status) {
             case NFS_OK:
                  struct {
                       fhandle file;
                       fattr   attributes;
                  } diropok;
             default:
                  void;
        };

The results of a directory operation   are  returned   in  a
_d_i_r_o_p_r_e_s  structure.  If the call succeeded, a new file han-
dle "file" and the "attributes" associated  with  that  file
are  returned along with the "status".

_3._5.  _S_e_r_v_e_r _P_r_o_c_e_d_u_r_e_s

The  protocol definition  is given as    a   set   of   pro-
cedures  with arguments  and results defined using the   RPC
language.   A brief description of the function of each pro-
cedure  should provide enough information to allow implemen-
tation.

All of  the procedures  in   the NFS  protocol  are  assumed
to   be  synchronous.    When  a  procedure   returns to the
client, the client can assume that the  operation  has  com-
pleted  and  any data associated with the request is  now on
stable storage.  For  example, a client _W_R_I_T_E request    may
cause   the    server   to  update  data  blocks, filesystem
information blocks (such as  indirect   blocks),   and  file
attribute   information  (size   and   modify  times).  When
the _W_R_I_T_E returns to the client, it  can  assume   that  the
write   is  safe,  even in case of  a server  crash, and  it
can discard the  data written.  This  is  a  very  important
part   of  the  statelessness  of the server.  If the server
waited to flush data from remote requests, the client  would
have  to   save those requests so that  it could resend them
in case of a server crash.






















                          - 137 -



/*
* Remote file service routines
*/
program NFS_PROGRAM {
     version NFS_VERSION {
          void        NFSPROC_NULL(void)              = 0;
          attrstat    NFSPROC_GETATTR(fhandle)        = 1;
          attrstat    NFSPROC_SETATTR(sattrargs)      = 2;
          void        NFSPROC_ROOT(void)              = 3;
          diropres    NFSPROC_LOOKUP(diropargs)       = 4;
          readlinkres NFSPROC_READLINK(fhandle)       = 5;
          readres     NFSPROC_READ(readargs)          = 6;
          void        NFSPROC_WRITECACHE(void)        = 7;
          attrstat    NFSPROC_WRITE(writeargs)        = 8;
          diropres    NFSPROC_CREATE(createargs)      = 9;
          stat        NFSPROC_REMOVE(diropargs)       = 10;
          stat        NFSPROC_RENAME(renameargs)      = 11;
          stat        NFSPROC_LINK(linkargs)          = 12;
          stat        NFSPROC_SYMLINK(symlinkargs)    = 13;
          diropres    NFSPROC_MKDIR(createargs)       = 14;
          stat        NFSPROC_RMDIR(diropargs)        = 15;
          readdirres  NFSPROC_READDIR(readdirargs)     = 16;
          statfsres   NFSPROC_STATFS(fhandle)         = 17;
     } = 2;
} = 100003;


_3._5._1.  _D_o _N_o_t_h_i_n_g

        void
        NFSPROC_NULL(void) = 0;

This procedure does no work.   It is made available  in  all
RPC services to allow server response testing and timing.

_3._5._2.  _G_e_t _F_i_l_e _A_t_t_r_i_b_u_t_e_s

        attrstat
        NFSPROC_GETATTR (fhandle) = 1;

If the reply  status is _N_F_S__O_K, then  the  reply  attributes
contains  the  attributes  for  the  file given by the input
fhandle.



















                          - 138 -



_3._5._3.  _S_e_t _F_i_l_e _A_t_t_r_i_b_u_t_e_s

        struct sattrargs {
             fhandle file;
             sattr attributes;
             };

        attrstat
        NFSPROC_SETATTR (sattrargs) = 2;

The  "attributes" argument  contains fields which are either
-1  or  are  the  new value for  the  attributes of  "file".
If the reply status is _N_F_S__O_K, then  the   reply  attributes
have  the  attributes of the file after the "SETATTR" opera-
tion has completed.

Note: The use of -1 to indicate an unused field  in  "attri-
butes" is changed in the next version of the protocol.

_3._5._4.  _G_e_t _F_i_l_e_s_y_s_t_e_m _R_o_o_t

        void
        NFSPROC_ROOT(void) = 3;

Obsolete.  This  procedure   is  no  longer  used    because
finding the root file handle of a filesystem requires moving
pathnames between client  and server.  To  do  this right we
would  have  to define a network  stan- dard  representation
of   pathnames.   Instead,  the  function   of   looking  up
the    root   file handle  is  done  by the _M_N_T_P_R_O_C__M_N_T pro-
cedure.    (See the  Mount  Protocol  Definition  below  for
details).

_3._5._5.  _L_o_o_k _U_p _F_i_l_e _N_a_m_e

        diropres
        NFSPROC_LOOKUP(diropargs) = 4;

If  the reply "status"  is _N_F_S__O_K, then  the  reply   "file"
and  reply  "attributes"  are the file handle and attributes
for the file "name" in the directory given by "dir"  in  the
argument.




















                          - 139 -



_3._5._6.  _R_e_a_d _F_r_o_m _S_y_m_b_o_l_i_c _L_i_n_k

        union readlinkres switch (stat status) {
             case NFS_OK:
                  path data;
             default:
                  void;
        };

        readlinkres
        NFSPROC_READLINK(fhandle) = 5;

If "status" has the value _N_F_S__O_K, then the reply  "data"  is
the  data in the symbolic link given by the file referred to
by the fhandle argument.

Note:   since    NFS  always   parses  pathnames     on  the
client,  the  pathname  in  a symbolic  link may  mean some-
thing  different (or be meaningless) on a  different  client
or on the server if  a different pathname syntax is used.

_3._5._7.  _R_e_a_d _F_r_o_m _F_i_l_e

        struct readargs {
             fhandle file;
             unsigned offset;
             unsigned count;
             unsigned totalcount;
        };

        union readres switch (stat status) {
             case NFS_OK:
                  fattr attributes;
                  nfsdata data;
             default:
                  void;
        };

        readres
        NFSPROC_READ(readargs) = 6;

Returns  up  to  "count" bytes of   "data"  from   the  file
given by "file", starting at "offset" bytes from  the begin-
ning of the file.  The first byte of the file is  at  offset
zero.   The  file  attributes after the read takes place are
returned in "attributes".

Note: The  argument "totalcount" is  unused, and is  removed
in the next protocol revision.













                          - 140 -



_3._5._8.  _W_r_i_t_e _t_o _C_a_c_h_e

        void
        NFSPROC_WRITECACHE(void) = 7;

To be used in the next protocol revision.

_3._5._9.  _W_r_i_t_e _t_o _F_i_l_e

        struct writeargs {
             fhandle file;
             unsigned beginoffset;
             unsigned offset;
             unsigned totalcount;
             nfsdata data;
        };

        attrstat
        NFSPROC_WRITE(writeargs) = 8;

Writes   "data" beginning  "offset"  bytes  from the  begin-
ning  of "file".  The first byte  of  the file is at  offset
zero.  If  the reply "status" is  NFS_OK,  then   the  reply
"attributes"  contains the attributes  of the file after the
write has  completed.  The write operation is atomic.   Data
from  this   call  to _W_R_I_T_E will not be mixed with data from
another client's calls.

Note:  The  arguments  "beginoffset"  and  "totalcount"  are
ignored and are removed in the next protocol revision.

_3._5._1_0.  _C_r_e_a_t_e _F_i_l_e

        struct createargs {
             diropargs where;
             sattr attributes;
        };

        diropres
        NFSPROC_CREATE(createargs) = 9;

The file "name" is  created   in  the  directory  given   by
"dir".   The initial  attributes of the  new file  are given
by "attributes".  A reply "status"  of NFS_OK indicates that
the   file  was  created,  and  reply  "file"    and   reply
"attributes"  are    its file handle and  attributes.    Any
other  reply  "status"  means that  the operation failed and
no file was created.

Note: This  routine should pass  an exclusive  create  flag,
meaning "create the file only if it is not already there".











                          - 141 -



_3._5._1_1.  _R_e_m_o_v_e _F_i_l_e

        stat
        NFSPROC_REMOVE(diropargs) = 10;

The file "name" is  removed from  the  directory   given  by
"dir".    A  reply  of  NFS_OK means the directory entry was
removed.

Note: possibly non-idempotent operation.

_3._5._1_2.  _R_e_n_a_m_e _F_i_l_e

        struct renameargs {
             diropargs from;
             diropargs to;
        };

        stat
        NFSPROC_RENAME(renameargs) = 11;

The existing file "from.name" in   the  directory  given  by
"from.dir" is renamed to "to.name" in the directory given by
"to.dir".  If the reply  is _N_F_S__O_K, the file  was   renamed.
The  RENAME  operation is atomic on the server; it cannot be
interrupted in the middle.

Note: possibly non-idempotent operation.

_3._5._1_3.  _C_r_e_a_t_e _L_i_n_k _t_o _F_i_l_e

        struct linkargs {
             fhandle from;
             diropargs to;
        };

        stat
        NFSPROC_LINK(linkargs) = 12;

Creates the  file "to.name"  in the  directory   given    by
"to.dir",  which  is  a hard link to the existing file given
by "from".  If the  return  value  is  _N_F_S__O_K,  a  link  was
created.  Any other return value indicates an error, and the
link was not created.

A hard link should have the property that changes  to either
of  the  linked  files  are reflected in both files.  When a
hard link is made to a  file, the attributes  for  the  file
should   have   a value for "nlink" that is one greater than
the value before the link.

Note: possibly non-idempotent operation.










                          - 142 -



_3._5._1_4.  _C_r_e_a_t_e _S_y_m_b_o_l_i_c _L_i_n_k

        struct symlinkargs {
             diropargs from;
             path to;
             sattr attributes;
        };

        stat
        NFSPROC_SYMLINK(symlinkargs) = 13;

Creates the  file "from.name"  with   ftype  _N_F_L_N_K  in   the
directory  given by "from.dir".   The new file contains  the
pathname "to" and has initial attributes  given  by  "attri-
butes".  If  the return value is _N_F_S__O_K, a link was created.
Any other return value indicates an error, and the link  was
not created.

A symbolic  link is  a pointer to another file.    The  name
given  in  "to"  is   not  interpreted  by  the server, only
stored in  the  newly created file.  When the client  refer-
ences  a  file  that is a symbolic link, the contents of the
symbolic  link are normally transparently reinterpreted   as
a  pathname   to  substitute.   A _R_E_A_D_L_I_N_K operation returns
the data to the client for interpretation.

Note:  On UNIX servers the attributes are never used,  since
symbolic links always have mode 0777.

_3._5._1_5.  _C_r_e_a_t_e _D_i_r_e_c_t_o_r_y

        diropres
        NFSPROC_MKDIR (createargs) = 14;

The new directory "where.name" is created in  the  directory
given  by  "where.dir".   The  initial attributes of the new
directory are given by "attributes".  A  reply  "status"  of
NFS_OK  indicates  that  the  new directory was created, and
reply "file" and  reply "attributes" are  its  file   handle
and  attributes.  Any  other  reply "status"  means that the
operation failed and no directory was created.

Note: possibly non-idempotent operation.

_3._5._1_6.  _R_e_m_o_v_e _D_i_r_e_c_t_o_r_y

        stat
        NFSPROC_RMDIR(diropargs) = 15;

The existing empty directory "name" in the  directory  given
by  "dir" is removed.  If the reply is _N_F_S__O_K, the directory
was removed.










                          - 143 -


Note: possibly non-idempotent operation.

_3._5._1_7.  _R_e_a_d _F_r_o_m _D_i_r_e_c_t_o_r_y

        struct readdirargs {
             fhandle dir;
             nfscookie cookie;
             unsigned count;
        };

        struct entry {
             unsigned fileid;
             filename name;
             nfscookie cookie;
             entry *nextentry;
        };

        union readdirres switch (stat status) {
             case NFS_OK:
                  struct {
                       entry *entries;
                       bool eof;
                  } readdirok;
             default:
                  void;
        };

        readdirres
        NFSPROC_READDIR (readdirargs) = 16;

Returns a variable number of   directory  entries,   with  a
total  size of up to "count" bytes, from the directory given
by "dir".  If the returned  value of  "status"   is  _N_F_S__O_K,
then   it   is followed  by a variable  number  of "entry"s.
Each "entry"  contains   a  "fileid"  which  consists  of  a
unique  number   to identify the  file within  a filesystem,
the  "name" of the  file,  and  a  "cookie"  which    is  an
opaque  pointer  to  the next entry in  the  directory.  The
cookie is used   in  the  next  _R_E_A_D_D_I_R  call  to  get  more
entries   starting  at a given point in  the directory.  The
special cookie zero (all  bits zero) can be used to get  the
entries  starting   at the  beginning of the directory.  The
"fileid" field should be the same number as the "fileid"  in
the the  attributes of the  file.  (See the Basic Data Types
section.) The "eof" flag  has a value of _T_R_U_E if  there  are
no more entries in the directory.

















                          - 144 -



_3._5._1_8.  _G_e_t _F_i_l_e_s_y_s_t_e_m _A_t_t_r_i_b_u_t_e_s

        union statfsres (stat status) {
             case NFS_OK:
                  struct {
                       unsigned tsize;
                       unsigned bsize;
                       unsigned blocks;
                       unsigned bfree;
                       unsigned bavail;
                  } info;
             default:
                  void;
        };

        statfsres
        NFSPROC_STATFS(fhandle) = 17;

If the  reply "status"  is _N_F_S__O_K, then  the   reply  "info"
gives  the  attributes for the filesystem that contains file
referred to by the input fhandle.  The attribute fields con-
tain the following values:

tsize:The optimum transfer size  of  the  server  in  bytes.
     This  is the number  of bytes the server  would like to
     have in the data part of READ and WRITE requests.

bsize:The block size in bytes of the filesystem.

blocks:The total number of "bsize" blocks on the filesystem.

bfree:The number of free "bsize" blocks on the filesystem.

bavail:The number of   "bsize"  blocks   available  to  non-
     privileged users.

Note: This call does not  work well  if  a   filesystem  has
variable size blocks.

_4.  _N_F_S _I_m_p_l_e_m_e_n_t_a_t_i_o_n _I_s_s_u_e_s

The NFS protocol is designed to be operating system indepen-
dent, but since this version was designed in a UNIX environ-
ment, many operations have semantics similar to  the  opera-
tions  of the UNIX file system.  This section discusses some
of the implementation-specific semantic issues.

_4._1.  _S_e_r_v_e_r/_C_l_i_e_n_t _R_e_l_a_t_i_o_n_s_h_i_p

The NFS protocol is designed to allow servers to be as  sim-
ple  and  general  as possible.  Sometimes the simplicity of
the server can be a problem, if the client wants  to  imple-
ment complicated filesystem semantics.









                          - 145 -


For example, some operating systems allow  removal  of  open
files.   A  process  can  open a file and, while it is open,
remove it from the directory.  The  file  can  be  read  and
written  as  long  as the process keeps it open, even though
the file has no name in the filesystem.   It  is  impossible
for  a  stateless  server to implement these semantics.  The
client can do some tricks  such  as  renaming  the  file  on
remove,  and only removing it on close.  We believe that the
server provides enough functionality to implement most  file
system semantics on the client.

Every NFS client can  also  potentially  be  a  server,  and
remote  and  local  mounted filesystems can be freely inter-
mixed.  This leads  to  some  interesting  problems  when  a
client  travels down the directory tree of a remote filesys-
tem and reaches the mount point on the  server  for  another
remote filesystem.  Allowing the server to follow the second
remote mount would require loop  detection,  server  lookup,
and  user  revalidation.   Instead,  we  decided  not to let
clients cross a server's mount point.  When a client does  a
LOOKUP  on  a  directory  on  which the server has mounted a
filesystem, the client sees the underlying directory instead
of  the  mounted  directory.   A client can do remote mounts
that  match  the  server's  mount  points  to  maintain  the
server's view.


_4._2.  _P_a_t_h_n_a_m_e _I_n_t_e_r_p_r_e_t_a_t_i_o_n

There are a few complications to the rule that pathnames are
always  parsed  on  the client.  For example, symbolic links
could have different interpretations on  different  clients.
Another  common  problem for non-UNIX implementations is the
special interpretation of the pathname  ".."   to  mean  the
parent  of a given directory.  The next revision of the pro-
tocol uses an explicit flag to indicate the parent instead.

_4._3.  _P_e_r_m_i_s_s_i_o_n _I_s_s_u_e_s

The NFS protocol, strictly speaking,  does  not  define  the
permission  checking  used   by  servers.   However,   it is
expected that a server will do normal operating system  per-
mission checking using _A_U_T_H__U_N_I_X style authentication as the
basis of its protection  mechanism.   The  server  gets  the
client's  effective  "uid",  effective  "gid", and groups on
each call and uses them  to  check  permission.   There  are
various  problems with this method that can been resolved in
interesting ways.

Using "uid" and "gid" implies that  the  client  and  server
share  the  same  "uid"  list.  Every server and client pair
must have the same mapping from user to "uid" and from group
to  "gid".   Since  every  client can also be a server, this
tends to imply  that  the  whole  network  shares  the  same









                          - 146 -


"uid/gid"  space.   _A_U_T_H__D_E_S  (and the  next revision of the
NFS protocol) uses string  names  instead  of  numbers,  but
there are still complex problems to be solved.

Another problem arises due  to  the  usually  stateful  open
operation.   Most operating systems check permission at open
time, and then check that the file is open on each read  and
write  request.   With  stateless servers, the server has no
idea that the file is open and must do  permission  checking
on  each read and write call.  On a local filesystem, a user
can open a file and then change the permissions so  that  no
one  is allowed to touch it, but will still be able to write
to the file because it is open.  On a remote filesystem,  by
contrast, the write would fail.  To get around this problem,
the server's permission checking algorithm should allow  the
owner  of  a  file to access it regardless of the permission
setting.

A similar problem has to do with paging in from a file  over
the  network.   The operating system usually checks for exe-
cute permission before opening a file for demand paging, and
then reads blocks from the open file.  The file may not have
read permission, but after it is opened it  doesn't  matter.
An  NFS  server can not tell the difference between a normal
file read and a demand page-in read.  To make this work, the
server  allows  reading  of  files if the "uid" given in the
call has execute or read permission on the file.

In most operating systems, a particular user (on the user ID
zero)  has access to all files no matter what permission and
ownership they have.  This "super-user" permission  may  not
be  allowed  on  the  server,  since  anyone  who can become
super-user on their workstation could  gain  access  to  all
remote  files.  The UNIX server by default maps user id 0 to
-2 before doing its access checking.  This works except  for
NFS  root  filesystems,  where  super-user  access cannot be
avoided.

_4._4.  _S_e_t_t_i_n_g _R_P_C _P_a_r_a_m_e_t_e_r_s

Various file system parameters and options should be set  at
mount time.  The mount protocol is described in the appendix
below.  For example, "Soft" mounts as well as "Hard"  mounts
are usually both provided.  Soft mounted file systems return
errors when RPC operations fail (after  a  given  number  of
optional  retransmissions),  while hard mounted file systems
continue to retransmit forever.   Clients  and  servers  may
need to keep caches of recent operations to help avoid prob-
lems with non-idempotent operations.

_5.  _M_o_u_n_t _P_r_o_t_o_c_o_l _D_e_f_i_n_i_t_i_o_n












                          - 147 -


_5._1.  _I_n_t_r_o_d_u_c_t_i_o_n

The mount protocol is separate from, but related to, the NFS
protocol.  It provides operating system specific services to
get the NFS off the ground -- looking up server path  names,
validating  user  identity, and checking access permissions.
Clients use the mount protocol to get the first file handle,
which allows them entry into a remote filesystem.

The mount protocol is kept separate from the NFS protocol to
make  it  easy to plug in new access checking and validation
methods without changing the NFS server protocol.

Notice that the protocol definition implies stateful servers
because  the  server  maintains  a  list  of  client's mount
requests.  The mount list information is  not  critical  for
the  correct functioning of either the client or the server.
It is intended for advisory use only, for example,  to  warn
possible clients when a server is going down.

Version one of the mount protocol is used with  version  two
of the NFS protocol.  The only connecting point is the _f_h_a_n_-
_d_l_e structure, which is the same for both protocols.

_5._2.  _R_P_C _I_n_f_o_r_m_a_t_i_o_n

AuthenticationThe mount service uses _A_U_T_H__U_N_I_X and  _A_U_T_H__D_E_S
     style authentication only.

Transport ProtocolsThe mount service is currently  supported
     on UDP/IP only.

Port NumberConsult the server's    portmapper, described  in
     the  Remote Procedure Calls: Protocol Specification, to
     find  the  port number on which the  mount  service  is
     registered.

_5._3.  _S_i_z_e_s _o_f _X_D_R _S_t_r_u_c_t_u_r_e_s

These  are  the sizes,    given   in   decimal    bytes,  of
various XDR structures used in the protocol:

        /* The maximum number of bytes in a pathname argument */
        const MNTPATHLEN = 1024;

        /* The maximum number of bytes in a name argument */
        const MNTNAMLEN = 255;

        /* The size in bytes of the opaque file handle */
        const FHSIZE = 32;













                          - 148 -


_5._4.  _B_a_s_i_c _D_a_t_a _T_y_p_e_s

This section presents the data  types used  by   the   mount
protocol.   In many cases they are similar to the types used
in NFS.

_5._4._1.  _f_h_a_n_d_l_e

        typedef opaque fhandle[FHSIZE];

The type _f_h_a_n_d_l_e is the file handle that the  server  passes
to  the  client.   All  file operations are done  using file
handles  to refer to a  file  or directory.   The  file han-
dle   can   contain whatever information the server needs to
distinguish an individual file.

This  is the  same as the "fhandle" XDR definition  in  ver-
sion  2  of  the  NFS protocol;  see Basic Data Types in the
definition of the NFS protocol, above.

_5._4._2.  _f_h_s_t_a_t_u_s

        union fhstatus switch (unsigned status) {
             case 0:
                  fhandle directory;
             default:
                  void;
        };

The type _f_h_s_t_a_t_u_s is a union.  If  a  "status"  of  zero  is
returned,  the   call completed   successfully, and  a  file
handle    for    the  "directory"   follows.   A    non-zero
status  indicates   some   sort  of error.  In this case the
status is a UNIX error number.

_5._4._3.  _d_i_r_p_a_t_h

        typedef string dirpath<MNTPATHLEN>;

The type _d_i_r_p_a_t_h is a server pathname of a directory.

_5._4._4.  _n_a_m_e

        typedef string name<MNTNAMLEN>;

The type _n_a_m_e is an arbitrary string used for various names.

_5._5.  _S_e_r_v_e_r _P_r_o_c_e_d_u_r_e_s

The following sections define the RPC  procedures   supplied
by a mount server.












                          - 149 -


/*
* Protocol description for the mount program
*/

program MOUNTPROG {
/*
* Version 1 of the mount protocol used with
* version 2 of the NFS protocol.
*/
     version MOUNTVERS {
          void        MOUNTPROC_NULL(void)    = 0;
          fhstatus    MOUNTPROC_MNT(dirpath)  = 1;
          mountlist   MOUNTPROC_DUMP(void)    = 2;
          void        MOUNTPROC_UMNT(dirpath) = 3;
          void        MOUNTPROC_UMNTALL(void) = 4;
          exportlist  MOUNTPROC_EXPORT(void)  = 5;
     } = 1;
} = 100005;


_5._5._1.  _D_o _N_o_t_h_i_n_g

        void
        MNTPROC_NULL(void) = 0;

This  procedure does no work.  It   is  made   available  in
all   RPC services to allow server response testing and tim-
ing.

_5._5._2.  _A_d_d _M_o_u_n_t _E_n_t_r_y

        fhstatus
        MNTPROC_MNT(dirpath) = 1;

If the reply "status" is 0, then the reply "directory"  con-
tains  the  file  handle  for the directory "dirname".  This
file handle may be used in the NFS protocol.  This procedure
also  adds  a  new  entry  to the mount list for this client
mounting "dirname".

_5._5._3.  _R_e_t_u_r_n _M_o_u_n_t _E_n_t_r_i_e_s

        struct *mountlist {
             name      hostname;
             dirpath   directory;
             mountlist nextentry;
        };

        mountlist
        MNTPROC_DUMP(void) = 2;

Returns  the list  of   remote  mounted  filesystems.    The
"mountlist"  contains  one  entry  for  each  "hostname" and
"directory" pair.









                          - 150 -



_5._5._4.  _R_e_m_o_v_e _M_o_u_n_t _E_n_t_r_y

        void
        MNTPROC_UMNT(dirpath) = 3;

Removes the mount list entry for the input "dirpath".

_5._5._5.  _R_e_m_o_v_e _A_l_l _M_o_u_n_t _E_n_t_r_i_e_s

        void
        MNTPROC_UMNTALL(void) = 4;

Removes all of the mount list entries for this client.

_5._5._6.  _R_e_t_u_r_n _E_x_p_o_r_t _L_i_s_t

        struct *groups {
             name grname;
             groups grnext;
        };

        struct *exportlist {
             dirpath filesys;
             groups groups;
             exportlist next;
        };

        exportlist
        MNTPROC_EXPORT(void) = 5;

Returns a variable number  of  export  list  entries.   Each
entry  contains  a filesystem name and a list of groups that
are allowed  to  import  it.   The  filesystem  name  is  in
"filesys", and the group name is in the list "groups".

Note:  The exportlist should contain more information  about
the status of the filesystem, such as a read-only flag.






















